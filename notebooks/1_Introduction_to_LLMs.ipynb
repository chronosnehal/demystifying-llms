{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f51fe5e-bdf1-430c-bd30-077f397c235f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# üìñ Section 1: Introduction to Large Language Models (LLMs)\n",
    "\n",
    "Large Language Models (LLMs) like OpenAI‚Äôs GPT-4 and Azure OpenAI‚Äôs GPT-35-turbo are redefining how humans interact with machines. They can generate text, translate languages, summarize documents, write code, and even solve problems.  \n",
    "\n",
    "In this notebook, we‚Äôll explore:  \n",
    "‚úÖ What LLMs are  \n",
    "‚úÖ Their capabilities with real examples  \n",
    "‚úÖ Why they matter in modern AI  "
   ]
  },
  {
   "cell_type": "code",
   "id": "abb6f5e2-f6cd-49fc-89f9-7072a7a2c85c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T03:01:01.745600Z",
     "start_time": "2025-12-16T03:01:01.069441Z"
    }
   },
   "source": [
    "# =============================\n",
    "# üìì SECTION 1: INTRODUCTION TO LLMs\n",
    "# =============================\n",
    "\n",
    "%run ./utils_llm_connector.ipynb\n",
    "\n",
    "# Create an instance of the connector\n",
    "connector = LLMConnector()\n",
    "\n",
    "# Confirm LLM is ready\n",
    "print(\"üì° LLM Connector initialized.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîë LLM Configuration Check:\n",
      "‚úÖ OpenAI API Details: FOUND\n",
      "‚úÖ Connected to OpenAI (model: gpt-4o)\n",
      "üì° LLM Connector initialized.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "f61dbd9e-01d8-4193-82bc-81ea039d8e1a",
   "metadata": {},
   "source": [
    "## üîç What is a Large Language Model (LLM)?\n",
    "\n",
    "A **Large Language Model (LLM)** is a type of artificial intelligence system trained on massive amounts of text data from books, websites, articles, code repositories, and more. Through this training, it learns:\n",
    "\n",
    "- **Patterns** in language structure and grammar\n",
    "- **Relationships** between words, phrases, and concepts\n",
    "- **Context** understanding across sentences and paragraphs\n",
    "- **Semantic meaning** beyond just word matching\n",
    "\n",
    "### Key Characteristics\n",
    "\n",
    "1. **Scale**: \"Large\" refers to the billions (or even trillions) of parameters the model contains\n",
    "2. **Language**: Trained primarily on text data to understand and generate human language\n",
    "3. **Generalization**: Can perform many different tasks without task-specific training\n",
    "4. **Context Awareness**: Understands context from previous parts of the conversation\n",
    "\n",
    "### Simple Analogy\n",
    "\n",
    "Think of an LLM as a **super-intelligent autocomplete system**‚Äîbut one that:\n",
    "- Can hold multi-turn conversations\n",
    "- Understands context and nuance\n",
    "- Can write essays, code, or poetry\n",
    "- Learns from patterns in millions of documents\n",
    "\n",
    "Let's ask an LLM to explain itself in simple terms:"
   ]
  },
  {
   "cell_type": "code",
   "id": "5fffdb2e-d5ce-4df7-997e-a0310f5c9aca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T03:01:08.823104Z",
     "start_time": "2025-12-16T03:01:01.748701Z"
    }
   },
   "source": [
    "# Prompt: Explain LLMs simply\n",
    "prompt = (\n",
    "    \"In very simple terms, explain what a Large Language Model (LLM) is, \"\n",
    "    \"how it works, and give an analogy a non-technical person can understand.\"\n",
    ")\n",
    "\n",
    "response = connector.get_completion(prompt)\n",
    "# Extract and display the content nicely\n",
    "if hasattr(response, 'content'):\n",
    "    print(response.content)\n",
    "elif isinstance(response, dict):\n",
    "    print(response.get('content', response))\n",
    "else:\n",
    "    print(response)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Large Language Model (LLM) is a type of artificial intelligence designed to understand and generate human-like text. It works by predicting what words or phrases should come next in a given piece of text based on the patterns it has learned from a vast amount of text data.\n",
      "\n",
      "**How it works:**\n",
      "\n",
      "1. **Training:** The model is trained on a large dataset containing examples of text from books, articles, websites, and more. During training, it learns the rules and patterns of language, such as grammar, vocabulary, and the context in which words are used.\n",
      "\n",
      "2. **Prediction:** Once trained, the model can generate text by predicting the next word in a sentence or responding to prompts. It uses the patterns it learned during training to make these predictions.\n",
      "\n",
      "**Analogy:**\n",
      "\n",
      "Imagine a massive library where a librarian has read millions of books. This librarian doesn't memorize every book word for word, but instead learns a lot about different topics, writing styles, and how words are typically used together. When you ask the librarian a question or give them a sentence to complete, they can use their vast knowledge to give you a coherent and relevant answer or continuation, much like how an LLM uses its training to predict and generate text.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "cf9042e3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üß† How Do LLMs Work? (High-Level Overview)\n",
    "\n",
    "At a fundamental level, LLMs work through a process called **next-token prediction**:\n",
    "\n",
    "1. **Training Phase**: The model reads billions of text examples and learns to predict the next word/token in a sequence\n",
    "2. **Inference Phase**: When you give it a prompt, it predicts what comes next, word by word, based on:\n",
    "   - The input prompt\n",
    "   - Patterns learned during training\n",
    "   - Context from previous tokens\n",
    "\n",
    "### The Magic: Emergent Capabilities\n",
    "\n",
    "Through training on vast amounts of text, LLMs develop **emergent capabilities**‚Äîabilities that weren't explicitly programmed but arise from the scale and diversity of training data:\n",
    "\n",
    "- **Reasoning**: Can solve problems step-by-step\n",
    "- **Code Generation**: Understands programming patterns\n",
    "- **Translation**: Learns language mappings from multilingual data\n",
    "- **Summarization**: Identifies key information patterns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e8f01f-723f-47a5-a568-2ee2f06a22fd",
   "metadata": {},
   "source": [
    "### üìù Real-world Analogies for LLMs\n",
    "\n",
    "Here are 5 analogies to help understand LLMs:  \n",
    "\n",
    "1. üß† **LLM as a Brain**: Like a brain trained on the entire internet, predicting what words come next.  \n",
    "2. üéπ **LLM as a Pianist**: A pianist who‚Äôs practiced every song ever and can improvise new ones.  \n",
    "3. üç≥ **LLM as a Chef**: A chef who can create new recipes after tasting millions of dishes.  \n",
    "4. üìö **LLM as an Encyclopedia**: A dynamic encyclopedia that writes new articles from what it knows.  \n",
    "5. üó∫Ô∏è **LLM as a Map**: Predicts the next step in a journey based on past travels.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3f16aa-c499-4329-b61c-66b8ce1dda8f",
   "metadata": {},
   "source": [
    "## üöÄ Capabilities of LLMs\n",
    "\n",
    "LLMs are powerful because they can perform a wide variety of language-related tasks. Let's explore the main capabilities with hands-on examples:\n",
    "\n",
    "### Core Capabilities\n",
    "\n",
    "1. ‚úçÔ∏è **Text Generation**: Write articles, poems, stories, or code\n",
    "2. üåê **Language Translation**: Translate between hundreds of languages\n",
    "3. üìñ **Summarization**: Condense long documents into key points\n",
    "4. ü§ñ **Question Answering**: Act as a virtual assistant answering queries\n",
    "5. üß† **Reasoning**: Solve problems, brainstorm, and plan\n",
    "6. üíª **Code Generation**: Write, explain, and debug code\n",
    "7. üìù **Content Editing**: Rewrite, improve, or adapt text\n",
    "8. üéØ **Classification**: Categorize and tag content\n",
    "\n",
    "Let's see what an LLM says about its own capabilities:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f594ca",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Hands-on Example 1: Text Generation\n",
    "\n",
    "Let's see an LLM generate text in different styles:\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "a3605e09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T03:01:15.284081Z",
     "start_time": "2025-12-16T03:01:08.863752Z"
    }
   },
   "source": [
    "# Example 1: Creative Writing\n",
    "print(\"=\" * 60)\n",
    "print(\"üìù Example 1: Creative Writing\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "prompt_creative = \"Write a short story (3-4 sentences) about a robot learning to paint.\"\n",
    "response_creative = connector.get_completion(prompt_creative)\n",
    "if hasattr(response_creative, 'content'):\n",
    "    print(response_creative.content)\n",
    "elif isinstance(response_creative, dict):\n",
    "    print(response_creative.get('content', response_creative))\n",
    "else:\n",
    "    print(response_creative)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìß Example 2: Professional Email\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "prompt_email = (\n",
    "    \"Write a professional email to a colleague requesting feedback \"\n",
    "    \"on a project proposal. Keep it concise and friendly.\"\n",
    ")\n",
    "response_email = connector.get_completion(prompt_email)\n",
    "if hasattr(response_email, 'content'):\n",
    "    print(response_email.content)\n",
    "elif isinstance(response_email, dict):\n",
    "    print(response_email.get('content', response_email))\n",
    "else:\n",
    "    print(response_email)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üìù Example 1: Creative Writing\n",
      "============================================================\n",
      "In a small, sunlit studio nestled between bustling city streets, a robot named Aria stood before a canvas, her mechanical fingers delicately gripping a paintbrush. Programmed with algorithms for creativity, she dipped the brush into vibrant blues and greens, mimicking the strokes of the great masters she had studied. As each stroke came to life, Aria discovered an unexpected sensation‚Äîan echo of emotion‚Äîemanating from the abstract forms she created. Her creators watched in awe, realizing that in teaching Aria to paint, they had unlocked a new dimension of her existence, blurring the lines between machine and artist.\n",
      "\n",
      "============================================================\n",
      "üìß Example 2: Professional Email\n",
      "============================================================\n",
      "Subject: Request for Feedback on Project Proposal\n",
      "\n",
      "Hi [Colleague's Name],\n",
      "\n",
      "I hope this message finds you well. I am reaching out to kindly request your feedback on a project proposal I‚Äôve been working on, titled \"[Project Title].\" Your insights would be invaluable, and I believe your perspective could greatly enhance the final version.\n",
      "\n",
      "Could you please take a moment to review the attached document and share your thoughts? Any suggestions or comments you might have would be greatly appreciated.\n",
      "\n",
      "Thank you in advance for your time and support.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "[Your Name]  \n",
      "[Your Position]  \n",
      "[Your Contact Information]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "107c9fb0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üåê Hands-on Example 2: Language Translation\n",
    "\n",
    "LLMs excel at translating between languages. Let's try it:\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "58635537",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T03:01:17.201984Z",
     "start_time": "2025-12-16T03:01:15.298286Z"
    }
   },
   "source": [
    "# Translation Examples\n",
    "translations = [\n",
    "    (\"English to Spanish\", \"Hello, how are you today?\", \"Spanish\"),\n",
    "    (\"English to French\", \"The weather is beautiful today.\", \"French\"),\n",
    "    (\"English to German\", \"I am learning about artificial intelligence.\", \"German\")\n",
    "]\n",
    "\n",
    "for lang_pair, text, target_lang in translations:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"üåê {lang_pair}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Original (English): {text}\")\n",
    "    \n",
    "    prompt_translate = f\"Translate the following English text to {target_lang}: '{text}'\"\n",
    "    response = connector.get_completion(prompt_translate)\n",
    "    \n",
    "    if hasattr(response, 'content'):\n",
    "        print(f\"Translation ({target_lang}): {response.content}\")\n",
    "    elif isinstance(response, dict):\n",
    "        print(f\"Translation ({target_lang}): {response.get('content', response)}\")\n",
    "    else:\n",
    "        print(f\"Translation ({target_lang}): {response}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üåê English to Spanish\n",
      "============================================================\n",
      "Original (English): Hello, how are you today?\n",
      "Translation (Spanish): Hola, ¬øc√≥mo est√°s hoy?\n",
      "\n",
      "============================================================\n",
      "üåê English to French\n",
      "============================================================\n",
      "Original (English): The weather is beautiful today.\n",
      "Translation (French): Le temps est magnifique aujourd'hui.\n",
      "\n",
      "============================================================\n",
      "üåê English to German\n",
      "============================================================\n",
      "Original (English): I am learning about artificial intelligence.\n",
      "Translation (German): Ich lerne √ºber k√ºnstliche Intelligenz.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "f573e845",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìñ Hands-on Example 3: Summarization\n",
    "\n",
    "LLMs can condense long text into concise summaries:\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "00d7a0f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T03:01:18.857909Z",
     "start_time": "2025-12-16T03:01:17.208477Z"
    }
   },
   "source": [
    "# Long text to summarize\n",
    "long_text = \"\"\"\n",
    "Artificial Intelligence (AI) has transformed numerous industries over the past decade. \n",
    "Machine learning algorithms can now recognize images, understand speech, and even drive cars. \n",
    "Large Language Models represent the latest breakthrough, enabling machines to understand \n",
    "and generate human-like text. These models are trained on vast amounts of data, learning \n",
    "patterns and relationships in language. They can answer questions, write essays, translate \n",
    "languages, and even write code. The applications are endless: from customer service chatbots \n",
    "to content creation tools, from educational assistants to research aids. However, with \n",
    "great power comes great responsibility. We must consider ethical implications, bias in \n",
    "training data, and the potential for misuse. As we continue to develop these technologies, \n",
    "it's crucial to ensure they benefit humanity while minimizing harm.\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üìñ Original Text (Long)\")\n",
    "print(\"=\" * 60)\n",
    "print(long_text)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìù Summary (Generated by LLM)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "prompt_summarize = f\"Summarize the following text in 2-3 sentences:\\n\\n{long_text}\"\n",
    "response_summary = connector.get_completion(prompt_summarize)\n",
    "\n",
    "if hasattr(response_summary, 'content'):\n",
    "    print(response_summary.content)\n",
    "elif isinstance(response_summary, dict):\n",
    "    print(response_summary.get('content', response_summary))\n",
    "else:\n",
    "    print(response_summary)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üìñ Original Text (Long)\n",
      "============================================================\n",
      "\n",
      "Artificial Intelligence (AI) has transformed numerous industries over the past decade. \n",
      "Machine learning algorithms can now recognize images, understand speech, and even drive cars. \n",
      "Large Language Models represent the latest breakthrough, enabling machines to understand \n",
      "and generate human-like text. These models are trained on vast amounts of data, learning \n",
      "patterns and relationships in language. They can answer questions, write essays, translate \n",
      "languages, and even write code. The applications are endless: from customer service chatbots \n",
      "to content creation tools, from educational assistants to research aids. However, with \n",
      "great power comes great responsibility. We must consider ethical implications, bias in \n",
      "training data, and the potential for misuse. As we continue to develop these technologies, \n",
      "it's crucial to ensure they benefit humanity while minimizing harm.\n",
      "\n",
      "\n",
      "============================================================\n",
      "üìù Summary (Generated by LLM)\n",
      "============================================================\n",
      "Artificial Intelligence has significantly advanced various fields, with machine learning algorithms now capable of recognizing images, understanding speech, and driving cars. Large Language Models, the latest breakthrough, enable machines to comprehend and generate human-like text, offering applications ranging from customer service to content creation. However, as these technologies evolve, addressing ethical concerns, data bias, and potential misuse is vital to ensure they are beneficial and minimize harm.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "e06819f3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üíª Hands-on Example 4: Code Generation\n",
    "\n",
    "LLMs can understand and generate code in multiple programming languages:\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "1d5c6124",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T03:01:29.329553Z",
     "start_time": "2025-12-16T03:01:18.866400Z"
    }
   },
   "source": [
    "# Code Generation Example\n",
    "print(\"=\" * 60)\n",
    "print(\"üíª Code Generation: Python Function\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "prompt_code = (\n",
    "    \"Write a Python function that calculates the factorial of a number. \"\n",
    "    \"Include a docstring and handle edge cases.\"\n",
    ")\n",
    "\n",
    "response_code = connector.get_completion(prompt_code)\n",
    "\n",
    "if hasattr(response_code, 'content'):\n",
    "    print(response_code.content)\n",
    "elif isinstance(response_code, dict):\n",
    "    print(response_code.get('content', response_code))\n",
    "else:\n",
    "    print(response_code)\n",
    "\n",
    "# You can even ask the LLM to explain code\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìö Code Explanation\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "code_to_explain = \"\"\"\n",
    "def fibonacci(n):\n",
    "    if n <= 1:\n",
    "        return n\n",
    "    return fibonacci(n-1) + fibonacci(n-2)\n",
    "\"\"\"\n",
    "\n",
    "prompt_explain = f\"Explain what this Python function does:\\n\\n{code_to_explain}\"\n",
    "response_explain = connector.get_completion(prompt_explain)\n",
    "\n",
    "if hasattr(response_explain, 'content'):\n",
    "    print(response_explain.content)\n",
    "elif isinstance(response_explain, dict):\n",
    "    print(response_explain.get('content', response_explain))\n",
    "else:\n",
    "    print(response_explain)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üíª Code Generation: Python Function\n",
      "============================================================\n",
      "Certainly! Below is a Python function that calculates the factorial of a number. The function includes a docstring explaining its purpose, parameters, and return value. It also handles edge cases such as negative numbers and non-integer inputs.\n",
      "\n",
      "```python\n",
      "def factorial(n):\n",
      "    \"\"\"\n",
      "    Calculate the factorial of a given non-negative integer.\n",
      "    \n",
      "    The factorial of a non-negative integer n is the product of all positive integers less than or equal to n.\n",
      "    It is denoted by n! and is defined as:\n",
      "    - n! = n * (n-1) * (n-2) * ... * 1 for n > 0\n",
      "    - 0! = 1 by definition\n",
      "\n",
      "    Parameters:\n",
      "    n (int): A non-negative integer whose factorial is to be computed.\n",
      "\n",
      "    Returns:\n",
      "    int: The factorial of the number n.\n",
      "\n",
      "    Raises:\n",
      "    ValueError: If n is a negative integer.\n",
      "    TypeError: If n is not an integer.\n",
      "    \"\"\"\n",
      "    if not isinstance(n, int):\n",
      "        raise TypeError(\"The input must be an integer.\")\n",
      "    if n < 0:\n",
      "        raise ValueError(\"Factorial is not defined for negative numbers.\")\n",
      "    \n",
      "    if n == 0:\n",
      "        return 1\n",
      "    result = 1\n",
      "    for i in range(2, n + 1):\n",
      "        result *= i\n",
      "    return result\n",
      "\n",
      "# Example usage:\n",
      "# print(factorial(5))  # Output: 120\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "- **Docstring**: The function's purpose, parameters, return value, and exceptions are detailed in the docstring.\n",
      "- **Input Validation**: The function checks if the input `n` is an integer and raises a `TypeError` if it isn't. It also raises a `ValueError` if `n` is negative, since factorials are only defined for non-negative integers.\n",
      "- **Edge Cases**: The function handles the edge case where `n` is 0 by returning 1, as 0! is defined to be 1.\n",
      "- **Loop**: For values of `n` greater than 0, the function uses a loop to multiply the integers from 2 to `n` to compute the factorial.\n",
      "\n",
      "============================================================\n",
      "üìö Code Explanation\n",
      "============================================================\n",
      "The provided Python function `fibonacci(n)` is a recursive implementation of the Fibonacci sequence. Here's a breakdown of what it does:\n",
      "\n",
      "1. **Base Case**: The function first checks if `n` is less than or equal to 1. If this condition is true, it returns `n`. This serves as the base case for the recursion:\n",
      "   - If `n` is 0, it returns 0.\n",
      "   - If `n` is 1, it returns 1.\n",
      "\n",
      "2. **Recursive Case**: If `n` is greater than 1, the function makes two recursive calls:\n",
      "   - It calls itself with `n-1` (`fibonacci(n-1)`).\n",
      "   - It calls itself with `n-2` (`fibonacci(n-2)`).\n",
      "\n",
      "   The results of these two recursive calls are then added together and returned. This follows the definition of the Fibonacci sequence, where each number is the sum of the two preceding ones:\n",
      "   - Fibonacci(0) = 0\n",
      "   - Fibonacci(1) = 1\n",
      "   - Fibonacci(n) = Fibonacci(n-1) + Fibonacci(n-2) for n > 1\n",
      "\n",
      "In summary, this function calculates the `n`th Fibonacci number using a recursive approach. However, it's important to note that this implementation is not the most efficient for large values of `n` due to its exponential time complexity, as it recalculates the same Fibonacci numbers multiple times. For larger values of `n`, iterative methods or memoization are preferred to improve performance.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "751a9d5e-cb84-42ed-aadd-ad21bb88ae2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T03:01:36.129147Z",
     "start_time": "2025-12-16T03:01:29.345276Z"
    }
   },
   "source": [
    "# Prompt: List LLM capabilities with real-life examples\n",
    "prompt = (\n",
    "    \"List and explain 5 major capabilities of Large Language Models (LLMs) \"\n",
    "    \"with a simple real-life example for each.\"\n",
    ")\n",
    "\n",
    "response = connector.get_completion(prompt)\n",
    "# Extract and display the content nicely\n",
    "if hasattr(response, 'content'):\n",
    "    print(response.content)\n",
    "elif isinstance(response, dict):\n",
    "    print(response.get('content', response))\n",
    "else:\n",
    "    print(response)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large Language Models (LLMs) have several key capabilities that make them versatile tools across various applications. Here are five major capabilities, each with a real-life example:\n",
      "\n",
      "1. **Text Generation:**\n",
      "   - **Capability:** LLMs can generate coherent and contextually relevant text based on a given prompt.\n",
      "   - **Example:** A content creator uses an LLM to draft a blog post on sustainable living. By providing a prompt like \"Write an introduction to sustainable living,\" the LLM generates a well-structured introduction that the creator can use as a starting point or inspiration.\n",
      "\n",
      "2. **Language Translation:**\n",
      "   - **Capability:** LLMs can translate text between multiple languages while maintaining the context and meaning.\n",
      "   - **Example:** A traveler uses an LLM-based translation app to communicate with locals in a foreign country. They type a sentence in English, and the app translates it into the local language, enabling easier and more accurate communication.\n",
      "\n",
      "3. **Summarization:**\n",
      "   - **Capability:** LLMs can condense long pieces of text into shorter summaries without losing essential information.\n",
      "   - **Example:** A student uses an LLM to summarize a lengthy research article for a class presentation. By inputting the article, the model provides a concise summary highlighting key findings and concepts, saving the student time and effort.\n",
      "\n",
      "4. **Question Answering:**\n",
      "   - **Capability:** LLMs can understand and answer questions posed in natural language by extracting relevant information from large datasets.\n",
      "   - **Example:** During a virtual assistant session, a user asks, \"What are the benefits of regular exercise?\" The LLM processes the query and provides an informative response citing various health benefits, such as improved cardiovascular health and stress reduction.\n",
      "\n",
      "5. **Sentiment Analysis:**\n",
      "   - **Capability:** LLMs can analyze text to determine the sentiment or emotional tone, such as positive, negative, or neutral.\n",
      "   - **Example:** A company uses an LLM to analyze customer reviews of a new product. By processing these reviews, the model identifies common sentiments and feedback trends, helping the company understand customer satisfaction and areas for improvement.\n",
      "\n",
      "These capabilities demonstrate how LLMs can be applied in practical scenarios, making them valuable tools for individuals and businesses alike.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "08230203",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Hands-on Example 1: Text Generation\n",
    "\n",
    "Let's see an LLM generate text in different styles:\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "c2f332dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T03:01:41.217274Z",
     "start_time": "2025-12-16T03:01:36.144173Z"
    }
   },
   "source": [
    "# Example 1: Creative Writing\n",
    "print(\"=\" * 60)\n",
    "print(\"üìù Example 1: Creative Writing\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "prompt_creative = \"Write a short story (3-4 sentences) about a robot learning to paint.\"\n",
    "response_creative = connector.get_completion(prompt_creative)\n",
    "if hasattr(response_creative, 'content'):\n",
    "    print(response_creative.content)\n",
    "elif isinstance(response_creative, dict):\n",
    "    print(response_creative.get('content', response_creative))\n",
    "else:\n",
    "    print(response_creative)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìß Example 2: Professional Email\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "prompt_email = (\n",
    "    \"Write a professional email to a colleague requesting feedback \"\n",
    "    \"on a project proposal. Keep it concise and friendly.\"\n",
    ")\n",
    "response_email = connector.get_completion(prompt_email)\n",
    "if hasattr(response_email, 'content'):\n",
    "    print(response_email.content)\n",
    "elif isinstance(response_email, dict):\n",
    "    print(response_email.get('content', response_email))\n",
    "else:\n",
    "    print(response_email)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üìù Example 1: Creative Writing\n",
      "============================================================\n",
      "In a quiet corner of the bustling city, a robot named Arlo discovered an old set of paintbrushes and a canvas in a dusty attic. Intrigued by the vibrant colors and the gentle strokes depicted in a forgotten painting, Arlo decided to learn the art of painting. Day by day, it meticulously studied the play of light and shadow, replicating the swirling skies and blooming fields of its surroundings. With each brushstroke, Arlo not only captured the world's beauty but also found its own unique expression, blending logic with creativity in a symphony of colors.\n",
      "\n",
      "============================================================\n",
      "üìß Example 2: Professional Email\n",
      "============================================================\n",
      "Subject: Request for Feedback on Project Proposal\n",
      "\n",
      "Hi [Colleague's Name],\n",
      "\n",
      "I hope this message finds you well. I‚Äôm reaching out to seek your feedback on a project proposal I‚Äôve been working on, titled ‚Äú[Project Title].‚Äù Your insights would be invaluable, and I‚Äôd greatly appreciate any suggestions or thoughts you might have.\n",
      "\n",
      "I‚Äôve attached the proposal document for your review. If possible, could you please share your feedback by [specific date]? Let me know if you have any questions or need further information.\n",
      "\n",
      "Thank you so much for your time and support.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "[Your Name]  \n",
      "[Your Position]  \n",
      "[Your Contact Information]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "f6b40f8a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üåê Hands-on Example 2: Language Translation\n",
    "\n",
    "LLMs excel at translating between languages. Let's try it:\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "d2614f0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T03:01:43.491145Z",
     "start_time": "2025-12-16T03:01:41.227971Z"
    }
   },
   "source": [
    "# Translation Examples\n",
    "translations = [\n",
    "    (\"English to Spanish\", \"Hello, how are you today?\", \"Spanish\"),\n",
    "    (\"English to French\", \"The weather is beautiful today.\", \"French\"),\n",
    "    (\"English to German\", \"I am learning about artificial intelligence.\", \"German\")\n",
    "]\n",
    "\n",
    "for lang_pair, text, target_lang in translations:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"üåê {lang_pair}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Original (English): {text}\")\n",
    "    \n",
    "    prompt_translate = f\"Translate the following English text to {target_lang}: '{text}'\"\n",
    "    response = connector.get_completion(prompt_translate)\n",
    "    \n",
    "    if hasattr(response, 'content'):\n",
    "        print(f\"Translation ({target_lang}): {response.content}\")\n",
    "    elif isinstance(response, dict):\n",
    "        print(f\"Translation ({target_lang}): {response.get('content', response)}\")\n",
    "    else:\n",
    "        print(f\"Translation ({target_lang}): {response}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üåê English to Spanish\n",
      "============================================================\n",
      "Original (English): Hello, how are you today?\n",
      "Translation (Spanish): Hola, ¬øc√≥mo est√°s hoy?\n",
      "\n",
      "============================================================\n",
      "üåê English to French\n",
      "============================================================\n",
      "Original (English): The weather is beautiful today.\n",
      "Translation (French): Le temps est magnifique aujourd'hui.\n",
      "\n",
      "============================================================\n",
      "üåê English to German\n",
      "============================================================\n",
      "Original (English): I am learning about artificial intelligence.\n",
      "Translation (German): 'Ich lerne √ºber k√ºnstliche Intelligenz.'\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "d2dc8003",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìñ Hands-on Example 3: Summarization\n",
    "\n",
    "LLMs can condense long text into concise summaries:\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "a3263803",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T03:01:45.298020Z",
     "start_time": "2025-12-16T03:01:43.501153Z"
    }
   },
   "source": [
    "# Long text to summarize\n",
    "long_text = \"\"\"\n",
    "Artificial Intelligence (AI) has transformed numerous industries over the past decade. \n",
    "Machine learning algorithms can now recognize images, understand speech, and even drive cars. \n",
    "Large Language Models represent the latest breakthrough, enabling machines to understand \n",
    "and generate human-like text. These models are trained on vast amounts of data, learning \n",
    "patterns and relationships in language. They can answer questions, write essays, translate \n",
    "languages, and even write code. The applications are endless: from customer service chatbots \n",
    "to content creation tools, from educational assistants to research aids. However, with \n",
    "great power comes great responsibility. We must consider ethical implications, bias in \n",
    "training data, and the potential for misuse. As we continue to develop these technologies, \n",
    "it's crucial to ensure they benefit humanity while minimizing harm.\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üìñ Original Text (Long)\")\n",
    "print(\"=\" * 60)\n",
    "print(long_text)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìù Summary (Generated by LLM)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "prompt_summarize = f\"Summarize the following text in 2-3 sentences:\\n\\n{long_text}\"\n",
    "response_summary = connector.get_completion(prompt_summarize)\n",
    "\n",
    "if hasattr(response_summary, 'content'):\n",
    "    print(response_summary.content)\n",
    "elif isinstance(response_summary, dict):\n",
    "    print(response_summary.get('content', response_summary))\n",
    "else:\n",
    "    print(response_summary)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üìñ Original Text (Long)\n",
      "============================================================\n",
      "\n",
      "Artificial Intelligence (AI) has transformed numerous industries over the past decade. \n",
      "Machine learning algorithms can now recognize images, understand speech, and even drive cars. \n",
      "Large Language Models represent the latest breakthrough, enabling machines to understand \n",
      "and generate human-like text. These models are trained on vast amounts of data, learning \n",
      "patterns and relationships in language. They can answer questions, write essays, translate \n",
      "languages, and even write code. The applications are endless: from customer service chatbots \n",
      "to content creation tools, from educational assistants to research aids. However, with \n",
      "great power comes great responsibility. We must consider ethical implications, bias in \n",
      "training data, and the potential for misuse. As we continue to develop these technologies, \n",
      "it's crucial to ensure they benefit humanity while minimizing harm.\n",
      "\n",
      "\n",
      "============================================================\n",
      "üìù Summary (Generated by LLM)\n",
      "============================================================\n",
      "Artificial Intelligence has significantly transformed various industries, with advancements like machine learning algorithms enabling capabilities such as image recognition, speech understanding, and autonomous driving. Large Language Models represent a recent breakthrough, allowing machines to comprehend and generate human-like text, with applications ranging from chatbots and content creation to educational and research tools. However, it is essential to address ethical concerns, biases in training data, and the potential for misuse to ensure these technologies benefit humanity while minimizing harm.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "cb207372",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ü§ñ Hands-on Example 4: Question Answering\n",
    "\n",
    "LLMs can answer questions based on their training knowledge:\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "3cd7a0bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T03:02:07.224656Z",
     "start_time": "2025-12-16T03:01:45.309928Z"
    }
   },
   "source": [
    "# Question Answering Examples\n",
    "questions = [\n",
    "    \"What is the difference between machine learning and deep learning?\",\n",
    "    \"Explain quantum computing in simple terms.\",\n",
    "    \"What are the main components of a neural network?\"\n",
    "]\n",
    "\n",
    "for i, question in enumerate(questions, 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"‚ùì Question {i}: {question}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    response = connector.get_completion(question)\n",
    "    \n",
    "    if hasattr(response, 'content'):\n",
    "        print(f\"üí° Answer:\\n{response.content}\")\n",
    "    elif isinstance(response, dict):\n",
    "        print(f\"üí° Answer:\\n{response.get('content', response)}\")\n",
    "    else:\n",
    "        print(f\"üí° Answer:\\n{response}\")\n",
    "    \n",
    "    print()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "‚ùì Question 1: What is the difference between machine learning and deep learning?\n",
      "============================================================\n",
      "üí° Answer:\n",
      "Machine learning and deep learning are both subfields of artificial intelligence, but they have some key differences:\n",
      "\n",
      "1. **Definition and Complexity**:\n",
      "   - **Machine Learning (ML)**: This is a broader field that encompasses a variety of algorithms and techniques allowing computers to learn from and make predictions or decisions based on data. It includes methods like linear regression, decision trees, support vector machines, and more. Machine learning can handle structured data and does not necessarily require large volumes of data to be effective.\n",
      "   - **Deep Learning (DL)**: This is a subset of machine learning that specifically deals with neural networks with many layers (hence \"deep\"). Deep learning models, especially deep neural networks, are designed to mimic the human brain's neural structure, allowing them to recognize patterns and perform complex tasks. They require large amounts of data and significant computational power.\n",
      "\n",
      "2. **Data Requirements**:\n",
      "   - **Machine Learning**: Can work with relatively smaller datasets and often requires feature extraction or engineering by humans to transform raw data into a suitable format.\n",
      "   - **Deep Learning**: Typically requires large amounts of labeled data to perform well, particularly for tasks like image and speech recognition.\n",
      "\n",
      "3. **Feature Engineering**:\n",
      "   - **Machine Learning**: Often involves significant feature engineering, where domain experts manually select and create features that make algorithms work more effectively.\n",
      "   - **Deep Learning**: Reduces the need for feature engineering because it automatically extracts features from raw data through its layered structure.\n",
      "\n",
      "4. **Architecture**:\n",
      "   - **Machine Learning**: Uses a variety of models, such as decision trees, random forests, and k-nearest neighbors.\n",
      "   - **Deep Learning**: Primarily uses neural networks with various architectures, including convolutional neural networks (CNNs) for image processing and recurrent neural networks (RNNs) for sequence data.\n",
      "\n",
      "5. **Interpretability**:\n",
      "   - **Machine Learning**: Models tend to be more interpretable, allowing users to understand and explain predictions.\n",
      "   - **Deep Learning**: Models, especially deep neural networks, are often seen as \"black boxes,\" making them less interpretable, although research is ongoing to improve this aspect.\n",
      "\n",
      "6. **Computational Power**:\n",
      "   - **Machine Learning**: Generally requires less computational power and can be run on standard computers.\n",
      "   - **Deep Learning**: Requires significant computational resources, often necessitating GPUs or specialized hardware like TPUs because of its complex architectures.\n",
      "\n",
      "Both machine learning and deep learning are powerful tools for different types of problems, and the choice between them often depends on the specific application, the size and nature of the data, and the available computational resources.\n",
      "\n",
      "\n",
      "============================================================\n",
      "‚ùì Question 2: Explain quantum computing in simple terms.\n",
      "============================================================\n",
      "üí° Answer:\n",
      "Quantum computing is a new type of computing that takes advantage of the strange and fascinating properties of quantum mechanics, which is the branch of physics that deals with the smallest particles in the universe, like atoms and photons.\n",
      "\n",
      "In classical computing, which is what most of our current computers use, the basic unit of information is called a \"bit.\" A bit can be either a 0 or a 1, like a tiny switch that is off or on. These bits are used to perform calculations and process information.\n",
      "\n",
      "Quantum computing, on the other hand, uses \"quantum bits,\" or \"qubits.\" Qubits are different because they can be both 0 and 1 at the same time, thanks to a property called \"superposition.\" This means a quantum computer can process a huge amount of possibilities all at once.\n",
      "\n",
      "Another key concept in quantum computing is \"entanglement.\" When qubits become entangled, the state of one qubit is directly related to the state of another, no matter how far apart they are. This allows quantum computers to solve certain problems much more quickly than classical computers.\n",
      "\n",
      "Because of these unique properties, quantum computers have the potential to solve complex problems that are currently impossible or would take an impractical amount of time for classical computers to solve. Examples include breaking complex encryptions, optimizing large systems, and simulating molecular structures for drug discovery.\n",
      "\n",
      "However, quantum computing is still in its early stages of development, and there are many technical challenges to overcome before it becomes a mainstream technology.\n",
      "\n",
      "\n",
      "============================================================\n",
      "‚ùì Question 3: What are the main components of a neural network?\n",
      "============================================================\n",
      "üí° Answer:\n",
      "The main components of a neural network are:\n",
      "\n",
      "1. **Neurons (Nodes):** These are the basic units that make up each layer of the network. Each neuron receives one or more inputs, processes them, and produces an output. Neurons are inspired by biological neurons and are often referred to as perceptrons in the context of artificial neural networks.\n",
      "\n",
      "2. **Layers:**\n",
      "   - **Input Layer:** This is the first layer of the neural network that takes in the input features. Each neuron in this layer represents an input feature.\n",
      "   - **Hidden Layers:** These are the intermediate layers between the input and output layers. A neural network can have one or more hidden layers, and they are responsible for transforming the input into something the output layer can use. The number of hidden layers and the number of neurons in each layer can significantly affect the performance of the network.\n",
      "   - **Output Layer:** This is the final layer of the network that produces the output. The number of neurons in this layer typically corresponds to the number of desired output classes or values.\n",
      "\n",
      "3. **Weights and Biases:** Each connection between neurons has an associated weight, which is a parameter that the network learns during training. Weights are used to adjust the input features' importance. Biases are additional parameters in each neuron that allow the activation function to be shifted left or right, which is crucial for learning complex patterns.\n",
      "\n",
      "4. **Activation Functions:** These functions introduce non-linearity into the network, allowing it to learn complex patterns. Common activation functions include the sigmoid, hyperbolic tangent (tanh), and Rectified Linear Unit (ReLU).\n",
      "\n",
      "5. **Loss Function:** This function measures how well the neural network is performing. It calculates the difference between the predicted output and the actual target values. Common loss functions include mean squared error for regression tasks and cross-entropy loss for classification tasks.\n",
      "\n",
      "6. **Optimizer:** This is an algorithm used to adjust the weights and biases to minimize the loss function. Popular optimizers include stochastic gradient descent (SGD), Adam, and RMSprop.\n",
      "\n",
      "7. **Learning Rate:** This is a hyperparameter that controls how much the weights are updated during training. A smaller learning rate might lead to a more accurate model, but it will take longer to converge. A larger learning rate might converge faster but could overshoot the optimal solution.\n",
      "\n",
      "These components work together to allow a neural network to learn from data and make predictions or decisions based on that learned information.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "967740d7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üíª Hands-on Example 5: Code Generation\n",
    "\n",
    "LLMs can understand and generate code in multiple programming languages:\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "829d16c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T03:02:22.196580Z",
     "start_time": "2025-12-16T03:02:07.260565Z"
    }
   },
   "source": [
    "# Code Generation Example\n",
    "print(\"=\" * 60)\n",
    "print(\"üíª Code Generation: Python Function\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "prompt_code = (\n",
    "    \"Write a Python function that calculates the factorial of a number. \"\n",
    "    \"Include a docstring and handle edge cases.\"\n",
    ")\n",
    "\n",
    "response_code = connector.get_completion(prompt_code)\n",
    "\n",
    "if hasattr(response_code, 'content'):\n",
    "    print(response_code.content)\n",
    "elif isinstance(response_code, dict):\n",
    "    print(response_code.get('content', response_code))\n",
    "else:\n",
    "    print(response_code)\n",
    "\n",
    "# You can even ask the LLM to explain code\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìö Code Explanation\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "code_to_explain = \"\"\"\n",
    "def fibonacci(n):\n",
    "    if n <= 1:\n",
    "        return n\n",
    "    return fibonacci(n-1) + fibonacci(n-2)\n",
    "\"\"\"\n",
    "\n",
    "prompt_explain = f\"Explain what this Python function does:\\n\\n{code_to_explain}\"\n",
    "response_explain = connector.get_completion(prompt_explain)\n",
    "\n",
    "if hasattr(response_explain, 'content'):\n",
    "    print(response_explain.content)\n",
    "elif isinstance(response_explain, dict):\n",
    "    print(response_explain.get('content', response_explain))\n",
    "else:\n",
    "    print(response_explain)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üíª Code Generation: Python Function\n",
      "============================================================\n",
      "Certainly! Below is a Python function that calculates the factorial of a number, complete with a docstring and handling for edge cases:\n",
      "\n",
      "```python\n",
      "def factorial(n):\n",
      "    \"\"\"\n",
      "    Calculate the factorial of a non-negative integer n.\n",
      "\n",
      "    The factorial of a non-negative integer n is the product of all positive integers less than or equal to n.\n",
      "    It is denoted by n! and defined by the relation:\n",
      "    n! = n * (n-1) * (n-2) * ... * 1, with 0! = 1 by convention.\n",
      "\n",
      "    Parameters:\n",
      "    n (int): A non-negative integer whose factorial is to be computed.\n",
      "\n",
      "    Returns:\n",
      "    int: The factorial of the given number.\n",
      "\n",
      "    Raises:\n",
      "    ValueError: If n is a negative integer.\n",
      "\n",
      "    Examples:\n",
      "    >>> factorial(5)\n",
      "    120\n",
      "    >>> factorial(0)\n",
      "    1\n",
      "    >>> factorial(1)\n",
      "    1\n",
      "    >>> factorial(3)\n",
      "    6\n",
      "    \"\"\"\n",
      "    if not isinstance(n, int):\n",
      "        raise TypeError(\"The input must be a non-negative integer.\")\n",
      "    if n < 0:\n",
      "        raise ValueError(\"The input must be a non-negative integer.\")\n",
      "    if n == 0 or n == 1:\n",
      "        return 1\n",
      "\n",
      "    result = 1\n",
      "    for i in range(2, n + 1):\n",
      "        result *= i\n",
      "    return result\n",
      "\n",
      "# Example usage:\n",
      "# print(factorial(5))  # Output: 120\n",
      "# print(factorial(0))  # Output: 1\n",
      "```\n",
      "\n",
      "### Key Points:\n",
      "- **Docstring**: The function includes a docstring that explains what the function does, its parameters, return value, and potential exceptions.\n",
      "- **Edge Cases**: The function handles the edge case where `n` is 0 by returning 1, as by convention 0! = 1. It also checks if `n` is a negative number and raises a `ValueError` in such cases.\n",
      "- **Type Checking**: The function checks if the input is of type `int` and raises a `TypeError` if it is not. This ensures that only non-negative integers are processed.\n",
      "- **Iterative Approach**: The function uses an iterative approach to compute the factorial. This is generally more efficient than a recursive approach for larger numbers due to Python's recursion depth limitation.\n",
      "\n",
      "============================================================\n",
      "üìö Code Explanation\n",
      "============================================================\n",
      "This Python function, named `fibonacci`, is designed to compute the nth number in the Fibonacci sequence using a recursive approach. Here's a step-by-step explanation of how it works:\n",
      "\n",
      "1. **Function Definition**: The function `fibonacci` takes a single argument `n`, which represents the position in the Fibonacci sequence for which we want to compute the corresponding value.\n",
      "\n",
      "2. **Base Case**: \n",
      "   - The function first checks if `n` is less than or equal to 1. \n",
      "   - If `n` is 0 or 1, the function returns `n` itself. This is because the Fibonacci sequence is defined such that:\n",
      "     - `fibonacci(0) = 0`\n",
      "     - `fibonacci(1) = 1`\n",
      "\n",
      "3. **Recursive Case**: \n",
      "   - If `n` is greater than 1, the function proceeds with the recursive calculation.\n",
      "   - It calls itself twice: `fibonacci(n-1)` and `fibonacci(n-2)`, and adds the results of these calls together. This is based on the Fibonacci sequence definition:\n",
      "     - `fibonacci(n) = fibonacci(n-1) + fibonacci(n-2)`\n",
      "\n",
      "4. **Recursive Evaluation**: \n",
      "   - The function continues to call itself with decreasing values of `n` until it reaches the base cases (`n = 0` or `n = 1`).\n",
      "   - These base cases provide the necessary stopping point for the recursion.\n",
      "\n",
      "5. **Result**: \n",
      "   - The final result is the nth Fibonacci number, computed through the sum of the two preceding Fibonacci numbers.\n",
      "\n",
      "**Considerations**: \n",
      "- This recursive implementation has an exponential time complexity of O(2^n), which can be quite inefficient for larger values of `n` due to the repeated calculations of the same Fibonacci numbers.\n",
      "- For more efficient computation of Fibonacci numbers, iterative methods or memoization (caching previously computed results) can be used.\n",
      "\n",
      "In summary, this function computes the nth Fibonacci number using a simple recursive approach by leveraging the fundamental property of the Fibonacci sequence.\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "b65a195a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üß† Hands-on Example 6: Reasoning and Problem Solving\n",
    "\n",
    "LLMs can reason through problems step by step:\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "00b7f541",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T03:02:25.859275Z",
     "start_time": "2025-12-16T03:02:22.206437Z"
    }
   },
   "source": [
    "# Reasoning Example\n",
    "print(\"=\" * 60)\n",
    "print(\"üß† Reasoning: Logic Problem\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "reasoning_prompt = \"\"\"\n",
    "Solve this logic problem step by step:\n",
    "\n",
    "A farmer has 17 sheep. All but 9 die. How many are left?\n",
    "\n",
    "Think through this carefully and explain your reasoning.\n",
    "\"\"\"\n",
    "\n",
    "response_reasoning = connector.get_completion(reasoning_prompt)\n",
    "\n",
    "if hasattr(response_reasoning, 'content'):\n",
    "    print(response_reasoning.content)\n",
    "elif isinstance(response_reasoning, dict):\n",
    "    print(response_reasoning.get('content', response_reasoning))\n",
    "else:\n",
    "    print(response_reasoning)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üß† Reasoning: Logic Problem\n",
      "============================================================\n",
      "To solve this logic problem, let's break it down step by step:\n",
      "\n",
      "1. **Understand the Initial Information**: The farmer initially has 17 sheep.\n",
      "\n",
      "2. **Interpret the Phrase \"All but 9 die\"**: This phrase can be tricky, but it‚Äôs important to focus on its meaning. \"All but 9 die\" means that all of the sheep except for 9 die. In other words, 9 sheep remain alive.\n",
      "\n",
      "3. **Calculate the Number of Sheep Left**: Since \"all but 9 die\" means that 9 sheep are still alive, the number of sheep left is 9.\n",
      "\n",
      "Therefore, the correct answer is that there are 9 sheep left.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "89328b52-b97d-42bb-8afb-2025f529eadb",
   "metadata": {},
   "source": [
    "## üî• LLMs vs Traditional Machine Learning Models\n",
    "\n",
    "| Feature                 | Traditional ML             | Large Language Models (LLMs)      |\n",
    "|-------------------------|----------------------------|------------------------------------|\n",
    "| üìö Training Data        | Small, task-specific data  | Massive text datasets (entire internet) |\n",
    "| üß† Capabilities         | Narrow (one task)          | Broad (multi-task, reasoning)     |\n",
    "| üìù Example              | Spam detection model       | ChatGPT answering complex questions |\n",
    "| üèóÔ∏è Adaptability         | Needs retraining per task  | Zero-shot/few-shot learning       |\n",
    "| üöÄ Real-world Impact    | Limited to domain          | Cross-domain applications         |"
   ]
  },
  {
   "cell_type": "code",
   "id": "88b1a354-eeaf-47a8-aba7-0914193affc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T03:02:36.521233Z",
     "start_time": "2025-12-16T03:02:25.870441Z"
    }
   },
   "source": [
    "# Prompt: Compare LLMs vs Traditional ML\n",
    "prompt = (\n",
    "    \"Compare Large Language Models (LLMs) with traditional Machine Learning models \"\n",
    "    \"in a detailed but easy-to-read tabular format.\"\n",
    ")\n",
    "\n",
    "response = connector.get_completion(prompt)\n",
    "print(response['content'] if isinstance(response, dict) else response)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"Certainly! Here's a comparison between Large Language Models (LLMs) and traditional Machine Learning models in a tabular format:\\n\\n| Feature                          | Large Language Models (LLMs)                                     | Traditional Machine Learning Models                          |\\n|----------------------------------|------------------------------------------------------------------|--------------------------------------------------------------|\\n| **Definition**                   | Models designed to understand and generate human-like text.      | Models designed to perform specific tasks like classification or regression. |\\n| **Data Requirements**            | Require vast amounts of text data for training.                  | Vary widely; some require large datasets while others work well with smaller datasets. |\\n| **Training Complexity**          | Highly complex; involves billions of parameters and extensive computational resources. | Generally less complex; varies by model type (e.g., linear regression vs. neural networks). |\\n| **Scalability**                  | Highly scalable; can handle diverse and large-scale language tasks. | Scalability varies; some models are limited to specific tasks. |\\n| **Adaptability**                 | Can generalize across various language tasks without task-specific tuning. | Typically require task-specific training and tuning.        |\\n| **Interpretability**             | Often viewed as black-box models; difficult to interpret.       | Varies; some models like decision trees are interpretable, while others like neural networks are not. |\\n| **Use Cases**                    | Natural language processing, content generation, language translation, chatbots. | Image recognition, fraud detection, recommendation systems, etc. |\\n| **Pretrained Models**            | Often pretrained on large corpora and fine-tuned for specific tasks. | Pretraining is less common; models are usually trained from scratch or with transfer learning. |\\n| **Performance**                  | High performance on language understanding and generation tasks. | Performance varies widely depending on the model and task.   |\\n| **Resource Intensity**           | Resource-intensive; requires significant computational power and memory. | Generally less resource-intensive; varies by model complexity. |\\n| **Deployment**                   | More complex to deploy due to size and resource requirements.    | Easier to deploy; many models are lightweight and require less computational power. |\\n| **Updates and Maintenance**      | Regular updates needed to keep up with language evolution.      | Updates depend on the domain; may require periodic retraining. |\\n| **Ethical Considerations**       | Concerns about bias, misuse, and ethical implications of generated content. | Concerns about bias and fairness, especially in sensitive applications. |\\n\\nThis table provides a high-level comparison, and specific details may vary based on the model architecture and application domain.\", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "239dc78f-79d5-4f48-bc70-29b0ba917e3c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üåü Real-World Applications\n",
    "\n",
    "LLMs are being used in many industries:\n",
    "\n",
    "1. **Customer Service**: Chatbots that understand and respond to customer queries\n",
    "2. **Content Creation**: Writing articles, social media posts, and marketing copy\n",
    "3. **Education**: Tutoring systems, homework help, and personalized learning\n",
    "4. **Healthcare**: Medical documentation, research summaries, and patient communication\n",
    "5. **Software Development**: Code generation, debugging, and documentation\n",
    "6. **Legal**: Document analysis, contract review, and legal research\n",
    "7. **Finance**: Market analysis, report generation, and risk assessment\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Summary\n",
    "\n",
    "In this notebook, we've:\n",
    "\n",
    "‚úÖ **Explored what LLMs are** - AI systems trained on massive text data that learn language patterns  \n",
    "‚úÖ **Understood how they work** - Next-token prediction with emergent capabilities  \n",
    "‚úÖ **Seen real-world analogies** - Brain, pianist, chef, encyclopedia, and map  \n",
    "‚úÖ **Demonstrated capabilities** - Text generation, translation, summarization, Q&A, code generation, and reasoning  \n",
    "‚úÖ **Compared with traditional ML** - Understanding when to use each approach  \n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- LLMs are **general-purpose** language understanding systems\n",
    "- They excel at **multiple tasks** without task-specific training\n",
    "- They require **significant computational resources** but offer powerful capabilities\n",
    "- They're best for **unstructured text** and **language-related tasks**\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "In the following notebooks, we'll dive deeper into:\n",
    "- How LLMs are trained (Notebook 2)\n",
    "- LLM architectures (Notebook 3)\n",
    "- Training vs Inference (Notebook 4)\n",
    "- Prompt engineering (Notebook 5)\n",
    "- And much more!\n",
    "\n",
    "---\n",
    "\n",
    "## üéì Try It Yourself!\n",
    "\n",
    "**Exercise 1**: Modify the text generation example to write a poem about AI.\n",
    "\n",
    "**Exercise 2**: Ask the LLM to translate a sentence into a language of your choice.\n",
    "\n",
    "**Exercise 3**: Create a prompt that asks the LLM to explain a complex topic in simple terms.\n",
    "\n",
    "**Exercise 4**: Try generating code in a different programming language (e.g., JavaScript, Java).\n",
    "\n",
    "Feel free to experiment with different prompts and see what the LLM can do!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

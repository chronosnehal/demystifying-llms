{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad1d8dcc-6361-402f-9647-1d7196073419",
   "metadata": {},
   "source": [
    "# üìñ Section 5: Prompt Engineering and LLM Optimization\n",
    "\n",
    "Prompt engineering is the key to unlocking the full potential of LLMs. By carefully designing input prompts, we can guide models to produce more accurate, relevant, and creative outputs. This is one of the most practical skills for working with LLMs.\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- ‚úÖ Understand what prompt engineering is and why it matters\n",
    "- ‚úÖ Master common prompt engineering techniques\n",
    "- ‚úÖ Learn best practices for designing effective prompts\n",
    "- ‚úÖ Explore optimization strategies for cost and performance\n",
    "- ‚úÖ Practice hands-on examples with different techniques\n",
    "\n",
    "## üìö What You'll Learn\n",
    "\n",
    "1. **Prompt Engineering Basics** - What it is and why it's important\n",
    "2. **Core Techniques** - Zero-shot, few-shot, chain-of-thought, role prompting\n",
    "3. **Best Practices** - How to design effective prompts\n",
    "4. **Advanced Techniques** - Delimiters, constraints, formatting\n",
    "5. **Optimization** - Cost and performance optimization strategies\n",
    "6. **Hands-on Examples** - Practical demonstrations you can try"
   ]
  },
  {
   "cell_type": "code",
   "id": "5bf4f8d9-5038-4269-916b-dac7e366be7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T03:01:17.251429Z",
     "start_time": "2025-12-16T03:01:16.545698Z"
    }
   },
   "source": [
    "# =============================\n",
    "# üìì SECTION 5: PROMPT ENGINEERING AND LLM OPTIMIZATION\n",
    "# =============================\n",
    "\n",
    "%run ./utils_llm_connector.ipynb\n",
    "\n",
    "# Create a connector instance\n",
    "connector = LLMConnector()\n",
    "\n",
    "# Confirm connection\n",
    "print(\"üì° LLM Connector initialized and ready.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîë LLM Configuration Check:\n",
      "‚úÖ OpenAI API Details: FOUND\n",
      "‚úÖ Connected to OpenAI (model: gpt-4o)\n",
      "üì° LLM Connector initialized and ready.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "95f2876a-a6a2-4ebb-b58a-87ca506244e9",
   "metadata": {},
   "source": [
    "## üî• What is Prompt Engineering?\n",
    "\n",
    "Prompt engineering involves crafting the input given to an LLM in a way that optimizes its output.  \n",
    "\n",
    "Think of it as asking a question in just the right way to get the answer you want.  \n",
    "\n",
    "### üìù Example\n",
    "- ‚ùå Bad Prompt: ‚ÄúWrite Python code.‚Äù  \n",
    "- ‚úÖ Good Prompt: ‚ÄúWrite Python code to sort a list of integers in ascending order using the bubble sort algorithm with a time complexity explanation.‚Äù"
   ]
  },
  {
   "cell_type": "code",
   "id": "67c1dcaf-56c1-4bb3-b2b0-5a1cdc150be7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T03:01:24.568667Z",
     "start_time": "2025-12-16T03:01:17.252030Z"
    }
   },
   "source": [
    "# Hands-on Example: Comparing Prompt Quality\n",
    "print(\"=\" * 60)\n",
    "print(\"üéØ Hands-on Example: Prompt Quality Comparison\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Bad vs Good prompts\n",
    "examples = [\n",
    "    {\n",
    "        \"task\": \"Code Generation\",\n",
    "        \"bad\": \"Write code\",\n",
    "        \"good\": \"Write a Python function that calculates the factorial of a number. Include error handling for negative numbers and a docstring.\"\n",
    "    },\n",
    "    {\n",
    "        \"task\": \"Summarization\",\n",
    "        \"bad\": \"Summarize this\",\n",
    "        \"good\": \"Summarize the following article in exactly 3 bullet points, focusing on the main findings and their implications.\"\n",
    "    },\n",
    "    {\n",
    "        \"task\": \"Translation\",\n",
    "        \"bad\": \"Translate\",\n",
    "        \"good\": \"Translate the following English text to Spanish, maintaining the formal tone: [text]\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for i, ex in enumerate(examples, 1):\n",
    "    print(f\"\\nüìã Example {i}: {ex['task']}\")\n",
    "    print(f\"   ‚ùå Bad: '{ex['bad']}'\")\n",
    "    print(f\"   ‚úÖ Good: '{ex['good']}'\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üí° Notice how specificity improves results!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Ask LLM for analogies\n",
    "prompt = (\n",
    "    \"Explain what prompt engineering is in Large Language Models. \"\n",
    "    \"Provide 3 simple, real-world analogies.\"\n",
    ")\n",
    "\n",
    "response = connector.get_completion(prompt)\n",
    "if hasattr(response, 'content'):\n",
    "    print(\"\\n\" + response.content)\n",
    "elif isinstance(response, dict):\n",
    "    print(\"\\n\" + response.get('content', str(response)))\n",
    "else:\n",
    "    print(\"\\n\" + str(response))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üéØ Hands-on Example: Prompt Quality Comparison\n",
      "============================================================\n",
      "\n",
      "üìã Example 1: Code Generation\n",
      "   ‚ùå Bad: 'Write code'\n",
      "   ‚úÖ Good: 'Write a Python function that calculates the factorial of a number. Include error handling for negative numbers and a docstring.'\n",
      "\n",
      "üìã Example 2: Summarization\n",
      "   ‚ùå Bad: 'Summarize this'\n",
      "   ‚úÖ Good: 'Summarize the following article in exactly 3 bullet points, focusing on the main findings and their implications.'\n",
      "\n",
      "üìã Example 3: Translation\n",
      "   ‚ùå Bad: 'Translate'\n",
      "   ‚úÖ Good: 'Translate the following English text to Spanish, maintaining the formal tone: [text]'\n",
      "\n",
      "============================================================\n",
      "üí° Notice how specificity improves results!\n",
      "============================================================\n",
      "\n",
      "Prompt engineering in the context of Large Language Models (LLMs) like GPT-3 or GPT-4 involves crafting specific inputs or \"prompts\" to elicit desired outputs from the model. The idea is to guide the model's responses by carefully designing the text that is fed into it, optimizing for clarity, relevance, and specificity.\n",
      "\n",
      "Here are three simple, real-world analogies to help explain prompt engineering:\n",
      "\n",
      "1. **Interview Questions**: Imagine conducting a job interview. The questions you ask are crucial in obtaining the information you need from the candidate. A well-crafted question elicits a detailed and relevant response, while a vague question might only yield superficial answers. Similarly, in prompt engineering, the way you frame your prompt can determine the depth and accuracy of the model's response.\n",
      "\n",
      "2. **Recipe Instructions**: Consider following a recipe to bake a cake. If the instructions are clear and precise, you're more likely to end up with a delicious cake. However, if the instructions are vague or unclear, the chances of making mistakes increase. In prompt engineering, a clearly defined prompt helps the model produce a more accurate and contextually appropriate output.\n",
      "\n",
      "3. **Search Engine Queries**: Think of how you use a search engine. The way you phrase your query can significantly impact the search results you get. A well-formulated query can lead you directly to the information you need, while a poorly constructed one might not. Similarly, in prompt engineering, crafting a specific and relevant prompt helps in obtaining precise and useful information from the model.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "3d2189c0-c287-4dc9-a951-af501ec9fe88",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Common Prompt Engineering Techniques\n",
    "\n",
    "### 1Ô∏è‚É£ Zero-shot prompting\n",
    "Ask the model to perform a task without examples.  \n",
    "‚úÖ *‚ÄúTranslate ‚ÄòHello‚Äô to Spanish.‚Äù*\n",
    "\n",
    "### 2Ô∏è‚É£ Few-shot prompting\n",
    "Provide a few examples to guide the model.  \n",
    "‚úÖ *‚ÄúTranslate: Hello ‚Üí Hola, Goodnight ‚Üí Buenas noches, Love ‚Üí [Answer]‚Äù*\n",
    "\n",
    "### 3Ô∏è‚É£ Chain-of-thought prompting\n",
    "Encourage step-by-step reasoning.  \n",
    "‚úÖ *‚ÄúExplain your reasoning step by step before giving the final answer.‚Äù*\n",
    "\n",
    "### 4Ô∏è‚É£ Role prompting\n",
    "Assign the model a persona or role.  \n",
    "‚úÖ *‚ÄúYou are a cybersecurity expert. Explain X.‚Äù*\n",
    "\n",
    "### 5Ô∏è‚É£ Delimiter prompting\n",
    "Use delimiters like ``` to specify sections.  \n",
    "‚úÖ *‚ÄúSummarize the following text: ```{text}```‚Äù*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6589e256",
   "metadata": {},
   "source": [
    "## üìö Detailed Examples: Zero-Shot, Few-Shot, and Chain-of-Thought\n",
    "\n",
    "Let's explore each technique in depth with multiple examples to understand when and how to use them effectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddc8989",
   "metadata": {},
   "source": [
    "### üéØ Zero-Shot Prompting: Deep Dive\n",
    "\n",
    "Zero-shot prompting works best for tasks the model already understands well from its training.\n",
    "\n",
    "**When to Use:**\n",
    "- Common tasks (translation, summarization, Q&A)\n",
    "- Tasks with clear, unambiguous instructions\n",
    "- When you want quick results without examples\n",
    "\n",
    "**Examples:**\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "d6d1e053",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T03:01:40.489749Z",
     "start_time": "2025-12-16T03:01:24.608610Z"
    }
   },
   "source": [
    "# Detailed Zero-Shot Examples\n",
    "print(\"=\" * 60)\n",
    "print(\"üéØ Zero-Shot Prompting: Detailed Examples\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Example 1: Translation\n",
    "print(\"\\nüìù Example 1: Translation\")\n",
    "print(\"-\" * 60)\n",
    "prompt1 = \"Translate 'The weather is beautiful today' to Spanish.\"\n",
    "print(f\"Prompt: {prompt1}\")\n",
    "response1 = connector.get_completion(prompt1)\n",
    "if hasattr(response1, 'content'):\n",
    "    print(f\"Response: {response1.content}\")\n",
    "elif isinstance(response1, dict):\n",
    "    print(f\"Response: {response1.get('content', '')}\")\n",
    "\n",
    "# Example 2: Question Answering\n",
    "print(\"\\nüìù Example 2: Question Answering\")\n",
    "print(\"-\" * 60)\n",
    "prompt2 = \"What is the difference between machine learning and deep learning?\"\n",
    "print(f\"Prompt: {prompt2}\")\n",
    "response2 = connector.get_completion(prompt2)\n",
    "if hasattr(response2, 'content'):\n",
    "    print(f\"Response: {response2.content[:200]}...\")\n",
    "elif isinstance(response2, dict):\n",
    "    print(f\"Response: {response2.get('content', '')[:200]}...\")\n",
    "\n",
    "# Example 3: Code Generation\n",
    "print(\"\\nüìù Example 3: Code Generation\")\n",
    "print(\"-\" * 60)\n",
    "prompt3 = \"Write a Python function that checks if a number is prime.\"\n",
    "print(f\"Prompt: {prompt3}\")\n",
    "response3 = connector.get_completion(prompt3)\n",
    "if hasattr(response3, 'content'):\n",
    "    print(f\"Response: {response3.content[:250]}...\")\n",
    "elif isinstance(response3, dict):\n",
    "    print(f\"Response: {response3.get('content', '')[:250]}...\")\n",
    "\n",
    "# Example 4: Summarization\n",
    "print(\"\\nüìù Example 4: Summarization\")\n",
    "print(\"-\" * 60)\n",
    "long_text = \"Artificial intelligence is transforming industries worldwide. Machine learning algorithms enable computers to learn from data without explicit programming. Deep learning, using neural networks, has achieved remarkable success in image recognition, natural language processing, and autonomous systems.\"\n",
    "prompt4 = f\"Summarize this in one sentence: {long_text}\"\n",
    "print(f\"Prompt: {prompt4[:80]}...\")\n",
    "response4 = connector.get_completion(prompt4)\n",
    "if hasattr(response4, 'content'):\n",
    "    print(f\"Response: {response4.content}\")\n",
    "elif isinstance(response4, dict):\n",
    "    print(f\"Response: {response4.get('content', '')}\")\n",
    "\n",
    "# Example 5: Classification\n",
    "print(\"\\nüìù Example 5: Classification\")\n",
    "print(\"-\" * 60)\n",
    "prompt5 = \"Classify this text as formal or informal: 'Hey there! How's it going?'\"\n",
    "print(f\"Prompt: {prompt5}\")\n",
    "response5 = connector.get_completion(prompt5)\n",
    "if hasattr(response5, 'content'):\n",
    "    print(f\"Response: {response5.content}\")\n",
    "elif isinstance(response5, dict):\n",
    "    print(f\"Response: {response5.get('content', '')}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üí° Zero-shot works for common tasks the model knows well!\")\n",
    "print(\"=\" * 60)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üéØ Zero-Shot Prompting: Detailed Examples\n",
      "============================================================\n",
      "\n",
      "üìù Example 1: Translation\n",
      "------------------------------------------------------------\n",
      "Prompt: Translate 'The weather is beautiful today' to Spanish.\n",
      "Response: El clima est√° hermoso hoy.\n",
      "\n",
      "üìù Example 2: Question Answering\n",
      "------------------------------------------------------------\n",
      "Prompt: What is the difference between machine learning and deep learning?\n",
      "Response: Machine learning and deep learning are both subfields of artificial intelligence, but they have some key differences in terms of structure, complexity, and applications. Here‚Äôs a breakdown of their di...\n",
      "\n",
      "üìù Example 3: Code Generation\n",
      "------------------------------------------------------------\n",
      "Prompt: Write a Python function that checks if a number is prime.\n",
      "Response: Certainly! A prime number is a natural number greater than 1 that has no positive divisors other than 1 and itself. Here's a Python function that checks if a number is prime:\n",
      "\n",
      "```python\n",
      "def is_prime(n):\n",
      "    \"\"\"Check if a number is prime.\"\"\"\n",
      "    if n ...\n",
      "\n",
      "üìù Example 4: Summarization\n",
      "------------------------------------------------------------\n",
      "Prompt: Summarize this in one sentence: Artificial intelligence is transforming industri...\n",
      "Response: Artificial intelligence, particularly through machine learning and deep learning, is revolutionizing global industries by enabling computers to autonomously learn from data and excel in tasks like image recognition, natural language processing, and autonomous systems.\n",
      "\n",
      "üìù Example 5: Classification\n",
      "------------------------------------------------------------\n",
      "Prompt: Classify this text as formal or informal: 'Hey there! How's it going?'\n",
      "Response: The text is informal.\n",
      "\n",
      "============================================================\n",
      "üí° Zero-shot works for common tasks the model knows well!\n",
      "============================================================\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "a528e6cf",
   "metadata": {},
   "source": [
    "### üéØ Few-Shot Prompting: Deep Dive\n",
    "\n",
    "Few-shot prompting provides examples to teach the model the desired pattern or format.\n",
    "\n",
    "**When to Use:**\n",
    "- You need a specific output format\n",
    "- The task requires a particular style or structure\n",
    "- You want consistent formatting across outputs\n",
    "- The model might not understand the task from description alone\n",
    "\n",
    "**Key Principles:**\n",
    "- Show 2-5 clear examples\n",
    "- Make examples representative of your use case\n",
    "- Keep examples consistent in format\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "2b8bf459",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T03:01:44.318569Z",
     "start_time": "2025-12-16T03:01:40.504711Z"
    }
   },
   "source": [
    "# Detailed Few-Shot Examples\n",
    "print(\"=\" * 60)\n",
    "print(\"üéØ Few-Shot Prompting: Detailed Examples\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Example 1: Sentiment Classification\n",
    "print(\"\\nüìù Example 1: Sentiment Classification\")\n",
    "print(\"-\" * 60)\n",
    "few_shot_1 = \"\"\"Classify the sentiment of these reviews:\n",
    "Review: \"This product is amazing! Best purchase ever!\" ‚Üí Positive\n",
    "Review: \"Terrible quality, very disappointed. Waste of money.\" ‚Üí Negative\n",
    "Review: \"It's okay, nothing special but it works.\" ‚Üí Neutral\n",
    "Review: \"Absolutely love it! Exceeded my expectations!\" ‚Üí [Answer]\"\"\"\n",
    "print(f\"Prompt:\\n{few_shot_1}\")\n",
    "response_fs1 = connector.get_completion(few_shot_1)\n",
    "if hasattr(response_fs1, 'content'):\n",
    "    print(f\"\\nResponse: {response_fs1.content}\")\n",
    "elif isinstance(response_fs1, dict):\n",
    "    print(f\"\\nResponse: {response_fs1.get('content', '')}\")\n",
    "\n",
    "# Example 2: Translation with Format\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìù Example 2: Translation with Specific Format\")\n",
    "print(\"-\" * 60)\n",
    "few_shot_2 = \"\"\"Translate these English phrases to French:\n",
    "Good morning ‚Üí Bonjour\n",
    "Thank you ‚Üí Merci\n",
    "How are you? ‚Üí Comment allez-vous?\n",
    "See you later ‚Üí [Answer]\"\"\"\n",
    "print(f\"Prompt:\\n{few_shot_2}\")\n",
    "response_fs2 = connector.get_completion(few_shot_2)\n",
    "if hasattr(response_fs2, 'content'):\n",
    "    print(f\"\\nResponse: {response_fs2.content}\")\n",
    "elif isinstance(response_fs2, dict):\n",
    "    print(f\"\\nResponse: {response_fs2.get('content', '')}\")\n",
    "\n",
    "# Example 3: Code Pattern Learning\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìù Example 3: Learning Code Patterns\")\n",
    "print(\"-\" * 60)\n",
    "few_shot_3 = \"\"\"Write Python functions following this pattern:\n",
    "Double a number: def double(n): return n * 2\n",
    "Triple a number: def triple(n): return n * 3\n",
    "Quadruple a number: [Answer]\"\"\"\n",
    "print(f\"Prompt:\\n{few_shot_3}\")\n",
    "response_fs3 = connector.get_completion(few_shot_3)\n",
    "if hasattr(response_fs3, 'content'):\n",
    "    print(f\"\\nResponse: {response_fs3.content}\")\n",
    "elif isinstance(response_fs3, dict):\n",
    "    print(f\"\\nResponse: {response_fs3.get('content', '')}\")\n",
    "\n",
    "# Example 4: Date Formatting\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìù Example 4: Date Format Conversion\")\n",
    "print(\"-\" * 60)\n",
    "few_shot_4 = \"\"\"Convert these dates to YYYY-MM-DD format:\n",
    "January 15, 2023 ‚Üí 2023-01-15\n",
    "March 3, 2024 ‚Üí 2024-03-03\n",
    "December 25, 2022 ‚Üí 2022-12-25\n",
    "July 4, 2025 ‚Üí [Answer]\"\"\"\n",
    "print(f\"Prompt:\\n{few_shot_4}\")\n",
    "response_fs4 = connector.get_completion(few_shot_4)\n",
    "if hasattr(response_fs4, 'content'):\n",
    "    print(f\"\\nResponse: {response_fs4.content}\")\n",
    "elif isinstance(response_fs4, dict):\n",
    "    print(f\"\\nResponse: {response_fs4.get('content', '')}\")\n",
    "\n",
    "# Example 5: Email Tone Transformation\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìù Example 5: Tone Transformation\")\n",
    "print(\"-\" * 60)\n",
    "few_shot_5 = \"\"\"Rewrite these emails in a professional tone:\n",
    "Casual: \"Hey, can you send me that file?\"\n",
    "Professional: \"Hello, could you please send me the file when convenient?\"\n",
    "\n",
    "Casual: \"Thanks a lot!\"\n",
    "Professional: \"Thank you very much for your assistance.\"\n",
    "\n",
    "Casual: \"What's up with the project?\"\n",
    "Professional: [Answer]\"\"\"\n",
    "print(f\"Prompt:\\n{few_shot_5}\")\n",
    "response_fs5 = connector.get_completion(few_shot_5)\n",
    "if hasattr(response_fs5, 'content'):\n",
    "    print(f\"\\nResponse: {response_fs5.content}\")\n",
    "elif isinstance(response_fs5, dict):\n",
    "    print(f\"\\nResponse: {response_fs5.get('content', '')}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üí° Few-shot teaches the model exactly what format you want!\")\n",
    "print(\"=\" * 60)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üéØ Few-Shot Prompting: Detailed Examples\n",
      "============================================================\n",
      "\n",
      "üìù Example 1: Sentiment Classification\n",
      "------------------------------------------------------------\n",
      "Prompt:\n",
      "Classify the sentiment of these reviews:\n",
      "Review: \"This product is amazing! Best purchase ever!\" ‚Üí Positive\n",
      "Review: \"Terrible quality, very disappointed. Waste of money.\" ‚Üí Negative\n",
      "Review: \"It's okay, nothing special but it works.\" ‚Üí Neutral\n",
      "Review: \"Absolutely love it! Exceeded my expectations!\" ‚Üí [Answer]\n",
      "\n",
      "Response: Positive\n",
      "\n",
      "============================================================\n",
      "üìù Example 2: Translation with Specific Format\n",
      "------------------------------------------------------------\n",
      "Prompt:\n",
      "Translate these English phrases to French:\n",
      "Good morning ‚Üí Bonjour\n",
      "Thank you ‚Üí Merci\n",
      "How are you? ‚Üí Comment allez-vous?\n",
      "See you later ‚Üí [Answer]\n",
      "\n",
      "Response: See you later ‚Üí √Ä plus tard\n",
      "\n",
      "============================================================\n",
      "üìù Example 3: Learning Code Patterns\n",
      "------------------------------------------------------------\n",
      "Prompt:\n",
      "Write Python functions following this pattern:\n",
      "Double a number: def double(n): return n * 2\n",
      "Triple a number: def triple(n): return n * 3\n",
      "Quadruple a number: [Answer]\n",
      "\n",
      "Response: To follow the pattern demonstrated in the examples for doubling and tripling a number, here is the function to quadruple a number:\n",
      "\n",
      "```python\n",
      "def quadruple(n):\n",
      "    return n * 4\n",
      "```\n",
      "\n",
      "This function takes a number `n` as input and returns the result of multiplying the number by 4.\n",
      "\n",
      "============================================================\n",
      "üìù Example 4: Date Format Conversion\n",
      "------------------------------------------------------------\n",
      "Prompt:\n",
      "Convert these dates to YYYY-MM-DD format:\n",
      "January 15, 2023 ‚Üí 2023-01-15\n",
      "March 3, 2024 ‚Üí 2024-03-03\n",
      "December 25, 2022 ‚Üí 2022-12-25\n",
      "July 4, 2025 ‚Üí [Answer]\n",
      "\n",
      "Response: July 4, 2025 ‚Üí 2025-07-04\n",
      "\n",
      "============================================================\n",
      "üìù Example 5: Tone Transformation\n",
      "------------------------------------------------------------\n",
      "Prompt:\n",
      "Rewrite these emails in a professional tone:\n",
      "Casual: \"Hey, can you send me that file?\"\n",
      "Professional: \"Hello, could you please send me the file when convenient?\"\n",
      "\n",
      "Casual: \"Thanks a lot!\"\n",
      "Professional: \"Thank you very much for your assistance.\"\n",
      "\n",
      "Casual: \"What's up with the project?\"\n",
      "Professional: [Answer]\n",
      "\n",
      "Response: Professional: \"Hello, could you provide an update on the status of the project?\"\n",
      "\n",
      "============================================================\n",
      "üí° Few-shot teaches the model exactly what format you want!\n",
      "============================================================\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "eeb58ab6",
   "metadata": {},
   "source": [
    "### üéØ Chain-of-Thought Prompting: Deep Dive\n",
    "\n",
    "Chain-of-thought prompting encourages the model to show its reasoning process step-by-step.\n",
    "\n",
    "**When to Use:**\n",
    "- Math problems and calculations\n",
    "- Logical reasoning tasks\n",
    "- Multi-step problem solving\n",
    "- When you need to verify the model's logic\n",
    "- Complex analysis requiring intermediate steps\n",
    "\n",
    "**Benefits:**\n",
    "- Improves accuracy on reasoning tasks\n",
    "- Makes the model's thinking transparent\n",
    "- Helps catch errors in logic\n",
    "- Better for complex problems\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "1130e730",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T03:02:06.176216Z",
     "start_time": "2025-12-16T03:01:44.333460Z"
    }
   },
   "source": [
    "# Detailed Chain-of-Thought Examples\n",
    "print(\"=\" * 60)\n",
    "print(\"üéØ Chain-of-Thought Prompting: Detailed Examples\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Example 1: Simple Arithmetic\n",
    "print(\"\\nüìù Example 1: Simple Math Problem\")\n",
    "print(\"-\" * 60)\n",
    "cot_1 = \"\"\"Solve this step by step, showing your reasoning:\n",
    "A store has 20 apples. They sell 8 in the morning and 5 in the afternoon. \n",
    "How many apples are left?\"\"\"\n",
    "print(f\"Prompt: {cot_1}\")\n",
    "response_cot1 = connector.get_completion(cot_1)\n",
    "if hasattr(response_cot1, 'content'):\n",
    "    print(f\"\\nResponse:\\n{response_cot1.content}\")\n",
    "elif isinstance(response_cot1, dict):\n",
    "    print(f\"\\nResponse:\\n{response_cot1.get('content', '')}\")\n",
    "\n",
    "# Example 2: Multi-Step Word Problem\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìù Example 2: Multi-Step Word Problem\")\n",
    "print(\"-\" * 60)\n",
    "cot_2 = \"\"\"Solve this problem step by step, showing all calculations:\n",
    "Sarah has 3 times as many books as Tom. If Tom has 12 books, \n",
    "how many books do they have together? Show your reasoning.\"\"\"\n",
    "print(f\"Prompt: {cot_2}\")\n",
    "response_cot2 = connector.get_completion(cot_2)\n",
    "if hasattr(response_cot2, 'content'):\n",
    "    print(f\"\\nResponse:\\n{response_cot2.content[:300]}...\")\n",
    "elif isinstance(response_cot2, dict):\n",
    "    print(f\"\\nResponse:\\n{response_cot2.get('content', '')[:300]}...\")\n",
    "\n",
    "# Example 3: Logical Reasoning\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìù Example 3: Logical Reasoning\")\n",
    "print(\"-\" * 60)\n",
    "cot_3 = \"\"\"Think through this logic problem step by step:\n",
    "If all roses are flowers, and some flowers are red, \n",
    "can we conclude that some roses are red? Explain your reasoning step by step.\"\"\"\n",
    "print(f\"Prompt: {cot_3}\")\n",
    "response_cot3 = connector.get_completion(cot_3)\n",
    "if hasattr(response_cot3, 'content'):\n",
    "    print(f\"\\nResponse:\\n{response_cot3.content[:300]}...\")\n",
    "elif isinstance(response_cot3, dict):\n",
    "    print(f\"\\nResponse:\\n{response_cot3.get('content', '')[:300]}...\")\n",
    "\n",
    "# Example 4: Financial Calculation\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìù Example 4: Financial Comparison\")\n",
    "print(\"-\" * 60)\n",
    "cot_4 = \"\"\"Compare these two options step by step:\n",
    "Option A: $1000 now\n",
    "Option B: $1100 in one year (assuming 5% annual interest rate)\n",
    "Which is better? Show your calculations and reasoning.\"\"\"\n",
    "print(f\"Prompt: {cot_4}\")\n",
    "response_cot4 = connector.get_completion(cot_4)\n",
    "if hasattr(response_cot4, 'content'):\n",
    "    print(f\"\\nResponse:\\n{response_cot4.content[:300]}...\")\n",
    "elif isinstance(response_cot4, dict):\n",
    "    print(f\"\\nResponse:\\n{response_cot4.get('content', '')[:300]}...\")\n",
    "\n",
    "# Example 5: Speed Calculation\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìù Example 5: Speed Calculation\")\n",
    "print(\"-\" * 60)\n",
    "cot_5 = \"\"\"Solve this problem step by step:\n",
    "A train travels 120 miles in 2 hours. Another train travels 180 miles in 3 hours.\n",
    "Which train is faster? Show your calculations for speed (distance/time) for each train.\"\"\"\n",
    "print(f\"Prompt: {cot_5}\")\n",
    "response_cot5 = connector.get_completion(cot_5)\n",
    "if hasattr(response_cot5, 'content'):\n",
    "    print(f\"\\nResponse:\\n{response_cot5.content[:300]}...\")\n",
    "elif isinstance(response_cot5, dict):\n",
    "    print(f\"\\nResponse:\\n{response_cot5.get('content', '')[:300]}...\")\n",
    "\n",
    "# Example 6: Percentage Problem\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìù Example 6: Percentage Calculation\")\n",
    "print(\"-\" * 60)\n",
    "cot_6 = \"\"\"Solve this step by step:\n",
    "A shirt originally costs $50. It's on sale for 20% off. \n",
    "Then you have a coupon for an additional 10% off the sale price.\n",
    "What's the final price? Show each step of your calculation.\"\"\"\n",
    "print(f\"Prompt: {cot_6}\")\n",
    "response_cot6 = connector.get_completion(cot_6)\n",
    "if hasattr(response_cot6, 'content'):\n",
    "    print(f\"\\nResponse:\\n{response_cot6.content[:300]}...\")\n",
    "elif isinstance(response_cot6, dict):\n",
    "    print(f\"\\nResponse:\\n{response_cot6.get('content', '')[:300]}...\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üí° Chain-of-thought makes reasoning transparent and improves accuracy!\")\n",
    "print(\"=\" * 60)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üéØ Chain-of-Thought Prompting: Detailed Examples\n",
      "============================================================\n",
      "\n",
      "üìù Example 1: Simple Math Problem\n",
      "------------------------------------------------------------\n",
      "Prompt: Solve this step by step, showing your reasoning:\n",
      "A store has 20 apples. They sell 8 in the morning and 5 in the afternoon. \n",
      "How many apples are left?\n",
      "\n",
      "Response:\n",
      "To find out how many apples are left in the store after some are sold, we can follow these steps:\n",
      "\n",
      "1. **Determine the initial quantity of apples.**  \n",
      "   The store starts with 20 apples.\n",
      "\n",
      "2. **Calculate the number of apples sold in the morning.**  \n",
      "   The store sells 8 apples in the morning.\n",
      "\n",
      "3. **Calculate the number of apples sold in the afternoon.**  \n",
      "   The store sells 5 apples in the afternoon.\n",
      "\n",
      "4. **Find the total number of apples sold during the day.**  \n",
      "   Add the apples sold in the morning and in the afternoon:  \n",
      "   \\(8 + 5 = 13\\) apples are sold in total.\n",
      "\n",
      "5. **Subtract the total number of apples sold from the initial number of apples to find how many are left.**  \n",
      "   Starting with 20 apples and subtracting the 13 sold gives:  \n",
      "   \\(20 - 13 = 7\\)\n",
      "\n",
      "So, there are 7 apples left in the store.\n",
      "\n",
      "============================================================\n",
      "üìù Example 2: Multi-Step Word Problem\n",
      "------------------------------------------------------------\n",
      "Prompt: Solve this problem step by step, showing all calculations:\n",
      "Sarah has 3 times as many books as Tom. If Tom has 12 books, \n",
      "how many books do they have together? Show your reasoning.\n",
      "\n",
      "Response:\n",
      "To solve this problem, we need to determine how many books Sarah has and then add that to the number of books Tom has to find the total number of books they have together.\n",
      "\n",
      "1. **Identify the number of books Tom has:**\n",
      "   - Tom has 12 books.\n",
      "\n",
      "2. **Determine how many books Sarah has:**\n",
      "   - According ...\n",
      "\n",
      "============================================================\n",
      "üìù Example 3: Logical Reasoning\n",
      "------------------------------------------------------------\n",
      "Prompt: Think through this logic problem step by step:\n",
      "If all roses are flowers, and some flowers are red, \n",
      "can we conclude that some roses are red? Explain your reasoning step by step.\n",
      "\n",
      "Response:\n",
      "To solve this logic problem, let's analyze the statements and their implications step by step:\n",
      "\n",
      "1. **Statement 1**: \"All roses are flowers.\"\n",
      "   - This tells us that every rose is included in the category of flowers. In other words, the set of roses is a subset of the set of flowers.\n",
      "\n",
      "2. **Statement ...\n",
      "\n",
      "============================================================\n",
      "üìù Example 4: Financial Comparison\n",
      "------------------------------------------------------------\n",
      "Prompt: Compare these two options step by step:\n",
      "Option A: $1000 now\n",
      "Option B: $1100 in one year (assuming 5% annual interest rate)\n",
      "Which is better? Show your calculations and reasoning.\n",
      "\n",
      "Response:\n",
      "To compare these two options, we need to consider the time value of money, which allows us to determine the present value of future cash flows. In this case, we want to compare receiving $1000 now (Option A) with receiving $1100 in one year (Option B), assuming a 5% annual interest rate.\n",
      "\n",
      "### Option...\n",
      "\n",
      "============================================================\n",
      "üìù Example 5: Speed Calculation\n",
      "------------------------------------------------------------\n",
      "Prompt: Solve this problem step by step:\n",
      "A train travels 120 miles in 2 hours. Another train travels 180 miles in 3 hours.\n",
      "Which train is faster? Show your calculations for speed (distance/time) for each train.\n",
      "\n",
      "Response:\n",
      "To determine which train is faster, we need to calculate the speed of each train using the formula for speed: \n",
      "\n",
      "\\[ \\text{Speed} = \\frac{\\text{Distance}}{\\text{Time}} \\]\n",
      "\n",
      "**For the first train:**\n",
      "- Distance traveled = 120 miles\n",
      "- Time taken = 2 hours\n",
      "\n",
      "Calculating the speed:\n",
      "\n",
      "\\[ \\text{Speed of the fir...\n",
      "\n",
      "============================================================\n",
      "üìù Example 6: Percentage Calculation\n",
      "------------------------------------------------------------\n",
      "Prompt: Solve this step by step:\n",
      "A shirt originally costs $50. It's on sale for 20% off. \n",
      "Then you have a coupon for an additional 10% off the sale price.\n",
      "What's the final price? Show each step of your calculation.\n",
      "\n",
      "Response:\n",
      "To find the final price of the shirt, follow these steps:\n",
      "\n",
      "1. **Calculate the 20% discount off the original price:**\n",
      "   - The original price of the shirt is $50.\n",
      "   - The discount is 20%, so calculate 20% of $50:\n",
      "     \\[\n",
      "     0.20 \\times 50 = 10\n",
      "     \\]\n",
      "   - Subtract the discount from the original p...\n",
      "\n",
      "============================================================\n",
      "üí° Chain-of-thought makes reasoning transparent and improves accuracy!\n",
      "============================================================\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "79e124e3",
   "metadata": {},
   "source": [
    "## üîç Comparing Techniques: Side-by-Side\n",
    "\n",
    "Let's see how the same task can be approached with different techniques:\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "aca8cc9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T03:02:12.462520Z",
     "start_time": "2025-12-16T03:02:06.195386Z"
    }
   },
   "source": [
    "# Comparison: Same Task with Different Techniques\n",
    "print(\"=\" * 60)\n",
    "print(\"üîç Comparison: Same Task, Different Techniques\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "task = \"Calculate: If a pizza costs $12 and you buy 3 pizzas, what's the total cost?\"\n",
    "\n",
    "print(f\"\\nüìã Task: {task}\\n\")\n",
    "\n",
    "# Zero-shot approach\n",
    "print(\"=\" * 60)\n",
    "print(\"1Ô∏è‚É£ Zero-Shot Approach\")\n",
    "print(\"-\" * 60)\n",
    "zero_shot = task\n",
    "print(f\"Prompt: {zero_shot}\")\n",
    "response_zs = connector.get_completion(zero_shot)\n",
    "if hasattr(response_zs, 'content'):\n",
    "    print(f\"Response: {response_zs.content[:150]}...\")\n",
    "elif isinstance(response_zs, dict):\n",
    "    print(f\"Response: {response_zs.get('content', '')[:150]}...\")\n",
    "\n",
    "# Few-shot approach\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"2Ô∏è‚É£ Few-Shot Approach\")\n",
    "print(\"-\" * 60)\n",
    "few_shot = \"\"\"Calculate the total cost:\n",
    "2 apples at $1 each = $2\n",
    "3 oranges at $2 each = $6\n",
    "3 pizzas at $12 each = [Answer]\"\"\"\n",
    "print(f\"Prompt: {few_shot}\")\n",
    "response_fs = connector.get_completion(few_shot)\n",
    "if hasattr(response_fs, 'content'):\n",
    "    print(f\"Response: {response_fs.content[:150]}...\")\n",
    "elif isinstance(response_fs, dict):\n",
    "    print(f\"Response: {response_fs.get('content', '')[:150]}...\")\n",
    "\n",
    "# Chain-of-thought approach\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"3Ô∏è‚É£ Chain-of-Thought Approach\")\n",
    "print(\"-\" * 60)\n",
    "cot = f\"\"\"Solve this step by step, showing your reasoning:\n",
    "{task}\n",
    "\n",
    "Show each step of your calculation.\"\"\"\n",
    "print(f\"Prompt: {cot}\")\n",
    "response_cot = connector.get_completion(cot)\n",
    "if hasattr(response_cot, 'content'):\n",
    "    print(f\"Response: {response_cot.content[:200]}...\")\n",
    "elif isinstance(response_cot, dict):\n",
    "    print(f\"Response: {response_cot.get('content', '')[:200]}...\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üí° Notice how each technique provides different levels of detail!\")\n",
    "print(\"=\" * 60)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üîç Comparison: Same Task, Different Techniques\n",
      "============================================================\n",
      "\n",
      "üìã Task: Calculate: If a pizza costs $12 and you buy 3 pizzas, what's the total cost?\n",
      "\n",
      "============================================================\n",
      "1Ô∏è‚É£ Zero-Shot Approach\n",
      "------------------------------------------------------------\n",
      "Prompt: Calculate: If a pizza costs $12 and you buy 3 pizzas, what's the total cost?\n",
      "Response: To find the total cost of buying 3 pizzas at $12 each, you multiply the cost of one pizza by the number of pizzas:\n",
      "\n",
      "\\[ 12 \\text{ dollars/pizza} \\times...\n",
      "\n",
      "============================================================\n",
      "2Ô∏è‚É£ Few-Shot Approach\n",
      "------------------------------------------------------------\n",
      "Prompt: Calculate the total cost:\n",
      "2 apples at $1 each = $2\n",
      "3 oranges at $2 each = $6\n",
      "3 pizzas at $12 each = [Answer]\n",
      "Response: To find the total cost of the pizzas, multiply the number of pizzas by the cost per pizza: \n",
      "\n",
      "3 pizzas √ó $12 each = $36\n",
      "\n",
      "Now, add up the costs of all t...\n",
      "\n",
      "============================================================\n",
      "3Ô∏è‚É£ Chain-of-Thought Approach\n",
      "------------------------------------------------------------\n",
      "Prompt: Solve this step by step, showing your reasoning:\n",
      "Calculate: If a pizza costs $12 and you buy 3 pizzas, what's the total cost?\n",
      "\n",
      "Show each step of your calculation.\n",
      "Response: To solve this problem step by step, we need to calculate the total cost of buying 3 pizzas, each costing $12.\n",
      "\n",
      "### Step 1: Identify the Cost of One Pizza\n",
      "The cost of one pizza is given as $12.\n",
      "\n",
      "### St...\n",
      "\n",
      "============================================================\n",
      "üí° Notice how each technique provides different levels of detail!\n",
      "============================================================\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "51f1233f",
   "metadata": {},
   "source": [
    "## üìä Technique Selection Guide\n",
    "\n",
    "### When to Use Each Technique\n",
    "\n",
    "| Technique | Best For | Example Use Cases |\n",
    "|-----------|----------|-------------------|\n",
    "| **Zero-Shot** | Common, well-understood tasks | Translation, simple Q&A, basic code generation |\n",
    "| **Few-Shot** | Specific formats or patterns | Custom output formats, style transformation, pattern learning |\n",
    "| **Chain-of-Thought** | Reasoning and calculation tasks | Math problems, logical reasoning, multi-step analysis |\n",
    "\n",
    "### Decision Tree\n",
    "\n",
    "```\n",
    "Is it a common task the model knows well?\n",
    "‚îú‚îÄ YES ‚Üí Use Zero-Shot\n",
    "‚îî‚îÄ NO ‚Üí Do you need a specific format/style?\n",
    "    ‚îú‚îÄ YES ‚Üí Use Few-Shot\n",
    "    ‚îî‚îÄ NO ‚Üí Does it require reasoning or calculation?\n",
    "        ‚îú‚îÄ YES ‚Üí Use Chain-of-Thought\n",
    "        ‚îî‚îÄ NO ‚Üí Try Zero-Shot first, then refine\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "e129ad29-105c-4333-9417-399be043a133",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T03:02:16.816159Z",
     "start_time": "2025-12-16T03:02:12.474606Z"
    }
   },
   "source": [
    "# Hands-on Example: Trying Different Techniques\n",
    "print(\"=\" * 60)\n",
    "print(\"üéØ Hands-on Example: Prompt Engineering Techniques\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ============================================================\n",
    "# 1Ô∏è‚É£ ZERO-SHOT PROMPTING - Multiple Examples\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"1Ô∏è‚É£ Zero-Shot Prompting: Multiple Examples\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "zero_shot_examples = [\n",
    "    {\n",
    "        \"task\": \"Definition\",\n",
    "        \"prompt\": \"Explain what machine learning is in one sentence.\",\n",
    "        \"description\": \"Simple definition request\"\n",
    "    },\n",
    "    {\n",
    "        \"task\": \"Translation\",\n",
    "        \"prompt\": \"Translate 'Good morning, how are you?' to French.\",\n",
    "        \"description\": \"Direct translation task\"\n",
    "    },\n",
    "    {\n",
    "        \"task\": \"Classification\",\n",
    "        \"prompt\": \"Is the following sentiment positive or negative? 'I love this new product!'\",\n",
    "        \"description\": \"Sentiment classification\"\n",
    "    },\n",
    "    {\n",
    "        \"task\": \"Code Generation\",\n",
    "        \"prompt\": \"Write a Python function to reverse a string.\",\n",
    "        \"description\": \"Code generation without examples\"\n",
    "    },\n",
    "    {\n",
    "        \"task\": \"Summarization\",\n",
    "        \"prompt\": \"Summarize quantum computing in 2 sentences.\",\n",
    "        \"description\": \"Brief summarization\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"\\nüìã Zero-Shot Examples:\")\n",
    "for i, ex in enumerate(zero_shot_examples, 1):\n",
    "    print(f\"\\n   Example {i}: {ex['task']} ({ex['description']})\")\n",
    "    print(f\"   Prompt: '{ex['prompt']}'\")\n",
    "    \n",
    "    # Execute first example to show it works\n",
    "    if i == 1:\n",
    "        response = connector.get_completion(ex['prompt'])\n",
    "        if hasattr(response, 'content'):\n",
    "            print(f\"   Response: {response.content[:80]}...\")\n",
    "        elif isinstance(response, dict):\n",
    "            print(f\"   Response: {response.get('content', '')[:80]}...\")\n",
    "\n",
    "print(\"\\nüí° Zero-shot works well for common, straightforward tasks!\")\n",
    "\n",
    "# ============================================================\n",
    "# 2Ô∏è‚É£ FEW-SHOT PROMPTING - Multiple Examples\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"2Ô∏è‚É£ Few-Shot Prompting: Multiple Examples\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "few_shot_examples = [\n",
    "    {\n",
    "        \"task\": \"Sentiment Classification\",\n",
    "        \"prompt\": \"\"\"Classify the sentiment of these reviews:\n",
    "Review: \"This product is amazing!\" ‚Üí Positive\n",
    "Review: \"Terrible quality, very disappointed.\" ‚Üí Negative\n",
    "Review: \"It's okay, nothing special.\" ‚Üí [Answer]\"\"\",\n",
    "        \"description\": \"Learning pattern from examples\"\n",
    "    },\n",
    "    {\n",
    "        \"task\": \"Translation Pattern\",\n",
    "        \"prompt\": \"\"\"Translate the following to Spanish:\n",
    "Hello ‚Üí Hola\n",
    "Goodbye ‚Üí Adi√≥s\n",
    "Thank you ‚Üí Gracias\n",
    "Please ‚Üí [Answer]\"\"\",\n",
    "        \"description\": \"Learning translation format\"\n",
    "    },\n",
    "    {\n",
    "        \"task\": \"Code Pattern\",\n",
    "        \"prompt\": \"\"\"Write Python functions following this pattern:\n",
    "Square: def square(n): return n * n\n",
    "Cube: def cube(n): return n * n * n\n",
    "Power of 4: [Answer]\"\"\",\n",
    "        \"description\": \"Learning code structure\"\n",
    "    },\n",
    "    {\n",
    "        \"task\": \"Date Formatting\",\n",
    "        \"prompt\": \"\"\"Convert dates to ISO format:\n",
    "Jan 1, 2023 ‚Üí 2023-01-01\n",
    "Dec 25, 2024 ‚Üí 2024-12-25\n",
    "Mar 15, 2025 ‚Üí [Answer]\"\"\",\n",
    "        \"description\": \"Learning date format pattern\"\n",
    "    },\n",
    "    {\n",
    "        \"task\": \"Email Tone\",\n",
    "        \"prompt\": \"\"\"Rewrite these emails in a professional tone:\n",
    "Casual: \"Hey, can you send me that file?\"\n",
    "Professional: \"Hello, could you please send me the file when convenient?\"\n",
    "Casual: \"Thanks a lot!\"\n",
    "Professional: [Answer]\"\"\",\n",
    "        \"description\": \"Learning tone transformation\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"\\nüìã Few-Shot Examples:\")\n",
    "for i, ex in enumerate(few_shot_examples, 1):\n",
    "    print(f\"\\n   Example {i}: {ex['task']} ({ex['description']})\")\n",
    "    print(f\"   Prompt preview: {ex['prompt'][:60]}...\")\n",
    "    \n",
    "    # Execute first example\n",
    "    if i == 1:\n",
    "        response = connector.get_completion(ex['prompt'])\n",
    "        if hasattr(response, 'content'):\n",
    "            print(f\"   Response: {response.content[:100]}...\")\n",
    "        elif isinstance(response, dict):\n",
    "            print(f\"   Response: {response.get('content', '')[:100]}...\")\n",
    "\n",
    "print(\"\\nüí° Few-shot teaches the model the pattern you want!\")\n",
    "\n",
    "# ============================================================\n",
    "# 3Ô∏è‚É£ CHAIN-OF-THOUGHT PROMPTING - Multiple Examples\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"3Ô∏è‚É£ Chain-of-Thought Prompting: Multiple Examples\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "cot_examples = [\n",
    "    {\n",
    "        \"task\": \"Simple Math\",\n",
    "        \"prompt\": \"\"\"Solve this step by step, showing your reasoning:\n",
    "A store has 20 apples. They sell 8 in the morning and 5 in the afternoon. \n",
    "How many apples are left?\"\"\",\n",
    "        \"description\": \"Basic arithmetic with steps\"\n",
    "    },\n",
    "    {\n",
    "        \"task\": \"Word Problem\",\n",
    "        \"prompt\": \"\"\"Solve this problem step by step:\n",
    "Sarah has 3 times as many books as Tom. If Tom has 12 books, \n",
    "how many books do they have together? Show your reasoning.\"\"\",\n",
    "        \"description\": \"Multi-step word problem\"\n",
    "    },\n",
    "    {\n",
    "        \"task\": \"Logical Reasoning\",\n",
    "        \"prompt\": \"\"\"Think through this logic problem step by step:\n",
    "If all roses are flowers, and some flowers are red, \n",
    "can we conclude that some roses are red? Explain your reasoning.\"\"\",\n",
    "        \"description\": \"Logical deduction\"\n",
    "    },\n",
    "    {\n",
    "        \"task\": \"Comparison\",\n",
    "        \"prompt\": \"\"\"Compare these two options step by step:\n",
    "Option A: $1000 now\n",
    "Option B: $1100 in one year (assuming 5% interest rate)\n",
    "Which is better? Show your calculations.\"\"\",\n",
    "        \"description\": \"Financial comparison with reasoning\"\n",
    "    },\n",
    "    {\n",
    "        \"task\": \"Problem Solving\",\n",
    "        \"prompt\": \"\"\"Solve this problem step by step:\n",
    "A train travels 120 miles in 2 hours. Another train travels 180 miles in 3 hours.\n",
    "Which train is faster? Show your calculations for speed.\"\"\",\n",
    "        \"description\": \"Speed calculation with steps\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"\\nüìã Chain-of-Thought Examples:\")\n",
    "for i, ex in enumerate(cot_examples, 1):\n",
    "    print(f\"\\n   Example {i}: {ex['task']} ({ex['description']})\")\n",
    "    print(f\"   Prompt preview: {ex['prompt'][:70]}...\")\n",
    "    \n",
    "    # Execute first example\n",
    "    if i == 1:\n",
    "        response = connector.get_completion(ex['prompt'])\n",
    "        if hasattr(response, 'content'):\n",
    "            print(f\"   Response: {response.content[:200]}...\")\n",
    "        elif isinstance(response, dict):\n",
    "            print(f\"   Response: {response.get('content', '')[:200]}...\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üí° Chain-of-thought improves accuracy on reasoning tasks!\")\n",
    "print(\"=\" * 60)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üéØ Hands-on Example: Prompt Engineering Techniques\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "1Ô∏è‚É£ Zero-Shot Prompting: Multiple Examples\n",
      "============================================================\n",
      "\n",
      "üìã Zero-Shot Examples:\n",
      "\n",
      "   Example 1: Definition (Simple definition request)\n",
      "   Prompt: 'Explain what machine learning is in one sentence.'\n",
      "   Response: Machine learning is a field of artificial intelligence that uses algorithms and ...\n",
      "\n",
      "   Example 2: Translation (Direct translation task)\n",
      "   Prompt: 'Translate 'Good morning, how are you?' to French.'\n",
      "\n",
      "   Example 3: Classification (Sentiment classification)\n",
      "   Prompt: 'Is the following sentiment positive or negative? 'I love this new product!''\n",
      "\n",
      "   Example 4: Code Generation (Code generation without examples)\n",
      "   Prompt: 'Write a Python function to reverse a string.'\n",
      "\n",
      "   Example 5: Summarization (Brief summarization)\n",
      "   Prompt: 'Summarize quantum computing in 2 sentences.'\n",
      "\n",
      "üí° Zero-shot works well for common, straightforward tasks!\n",
      "\n",
      "============================================================\n",
      "2Ô∏è‚É£ Few-Shot Prompting: Multiple Examples\n",
      "============================================================\n",
      "\n",
      "üìã Few-Shot Examples:\n",
      "\n",
      "   Example 1: Sentiment Classification (Learning pattern from examples)\n",
      "   Prompt preview: Classify the sentiment of these reviews:\n",
      "Review: \"This produ...\n",
      "   Response: Neutral...\n",
      "\n",
      "   Example 2: Translation Pattern (Learning translation format)\n",
      "   Prompt preview: Translate the following to Spanish:\n",
      "Hello ‚Üí Hola\n",
      "Goodbye ‚Üí A...\n",
      "\n",
      "   Example 3: Code Pattern (Learning code structure)\n",
      "   Prompt preview: Write Python functions following this pattern:\n",
      "Square: def s...\n",
      "\n",
      "   Example 4: Date Formatting (Learning date format pattern)\n",
      "   Prompt preview: Convert dates to ISO format:\n",
      "Jan 1, 2023 ‚Üí 2023-01-01\n",
      "Dec 25...\n",
      "\n",
      "   Example 5: Email Tone (Learning tone transformation)\n",
      "   Prompt preview: Rewrite these emails in a professional tone:\n",
      "Casual: \"Hey, c...\n",
      "\n",
      "üí° Few-shot teaches the model the pattern you want!\n",
      "\n",
      "============================================================\n",
      "3Ô∏è‚É£ Chain-of-Thought Prompting: Multiple Examples\n",
      "============================================================\n",
      "\n",
      "üìã Chain-of-Thought Examples:\n",
      "\n",
      "   Example 1: Simple Math (Basic arithmetic with steps)\n",
      "   Prompt preview: Solve this step by step, showing your reasoning:\n",
      "A store has 20 apples...\n",
      "   Response: To solve this problem, we need to determine how many apples are left after some are sold in the morning and the afternoon.\n",
      "\n",
      "1. **Start with the initial number of apples**:  \n",
      "   The store begins with 2...\n",
      "\n",
      "   Example 2: Word Problem (Multi-step word problem)\n",
      "   Prompt preview: Solve this problem step by step:\n",
      "Sarah has 3 times as many books as To...\n",
      "\n",
      "   Example 3: Logical Reasoning (Logical deduction)\n",
      "   Prompt preview: Think through this logic problem step by step:\n",
      "If all roses are flower...\n",
      "\n",
      "   Example 4: Comparison (Financial comparison with reasoning)\n",
      "   Prompt preview: Compare these two options step by step:\n",
      "Option A: $1000 now\n",
      "Option B: ...\n",
      "\n",
      "   Example 5: Problem Solving (Speed calculation with steps)\n",
      "   Prompt preview: Solve this problem step by step:\n",
      "A train travels 120 miles in 2 hours....\n",
      "\n",
      "============================================================\n",
      "üí° Chain-of-thought improves accuracy on reasoning tasks!\n",
      "============================================================\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "0b87e809",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T03:02:29.374993Z",
     "start_time": "2025-12-16T03:02:16.831313Z"
    }
   },
   "source": [
    "# More Hands-on Examples: Role and Delimiter Prompting\n",
    "print(\"=\" * 60)\n",
    "print(\"üéØ Additional Examples: Role & Delimiter Prompting\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Example 4: Role Prompting\n",
    "print(\"\\n4Ô∏è‚É£ Role Prompting:\")\n",
    "print(\"-\" * 60)\n",
    "role_prompt = \"\"\"You are a senior software engineer with 10 years of experience.\n",
    "Explain the concept of recursion to a beginner programmer in simple terms.\n",
    "Use analogies and avoid jargon.\"\"\"\n",
    "print(f\"Prompt: {role_prompt[:100]}...\")\n",
    "response4 = connector.get_completion(role_prompt)\n",
    "if hasattr(response4, 'content'):\n",
    "    print(f\"Response: {response4.content[:200]}...\")\n",
    "elif isinstance(response4, dict):\n",
    "    print(f\"Response: {response4.get('content', '')[:200]}...\")\n",
    "\n",
    "# Example 5: Delimiter Prompting\n",
    "print(\"\\n5Ô∏è‚É£ Delimiter Prompting:\")\n",
    "print(\"-\" * 60)\n",
    "article_text = \"\"\"\n",
    "Artificial Intelligence has revolutionized many industries. Machine learning algorithms \n",
    "can now process vast amounts of data and make predictions. Deep learning, a subset of \n",
    "machine learning, uses neural networks to solve complex problems. These technologies \n",
    "are being used in healthcare, finance, transportation, and more.\n",
    "\"\"\"\n",
    "delimiter_prompt = f\"\"\"Summarize the following article in exactly 2 sentences:\n",
    "\n",
    "---\n",
    "{article_text}\n",
    "---\n",
    "\n",
    "Focus on the main applications mentioned.\"\"\"\n",
    "print(f\"Prompt: {delimiter_prompt[:120]}...\")\n",
    "response5 = connector.get_completion(delimiter_prompt)\n",
    "if hasattr(response5, 'content'):\n",
    "    print(f\"Response: {response5.content[:200]}...\")\n",
    "elif isinstance(response5, dict):\n",
    "    print(f\"Response: {response5.get('content', '')[:200]}...\")\n",
    "\n",
    "# Example 6: Constraint Prompting\n",
    "print(\"\\n6Ô∏è‚É£ Constraint Prompting:\")\n",
    "print(\"-\" * 60)\n",
    "constraint_prompt = \"\"\"Write a product description for a wireless mouse in exactly 30 words.\n",
    "Include: battery life, connectivity type, and ergonomic design.\n",
    "Use a professional marketing tone.\"\"\"\n",
    "print(f\"Prompt: {constraint_prompt}\")\n",
    "response6 = connector.get_completion(constraint_prompt)\n",
    "if hasattr(response6, 'content'):\n",
    "    print(f\"Response: {response6.content}\")\n",
    "    word_count = len(response6.content.split())\n",
    "    print(f\"\\nWord count: {word_count} words\")\n",
    "elif isinstance(response6, dict):\n",
    "    content = response6.get('content', '')\n",
    "    print(f\"Response: {content}\")\n",
    "    word_count = len(content.split())\n",
    "    print(f\"\\nWord count: {word_count} words\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üí° Notice how constraints shape the output!\")\n",
    "print(\"=\" * 60)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üéØ Additional Examples: Role & Delimiter Prompting\n",
      "============================================================\n",
      "\n",
      "4Ô∏è‚É£ Role Prompting:\n",
      "------------------------------------------------------------\n",
      "Prompt: You are a senior software engineer with 10 years of experience.\n",
      "Explain the concept of recursion to ...\n",
      "Response: Certainly! Imagine you're standing in front of a set of Russian nesting dolls (also known as Matryoshka dolls). These are the kind of dolls where a big doll contains a slightly smaller doll inside, wh...\n",
      "\n",
      "5Ô∏è‚É£ Delimiter Prompting:\n",
      "------------------------------------------------------------\n",
      "Prompt: Summarize the following article in exactly 2 sentences:\n",
      "\n",
      "---\n",
      "\n",
      "Artificial Intelligence has revolutionized many industries...\n",
      "Response: Artificial Intelligence, particularly through machine learning and deep learning, is transforming industries by processing vast data and solving complex problems. These technologies are being utilized...\n",
      "\n",
      "6Ô∏è‚É£ Constraint Prompting:\n",
      "------------------------------------------------------------\n",
      "Prompt: Write a product description for a wireless mouse in exactly 30 words.\n",
      "Include: battery life, connectivity type, and ergonomic design.\n",
      "Use a professional marketing tone.\n",
      "Response: Experience seamless navigation with our wireless mouse, offering a remarkable 12-month battery life. Featuring advanced Bluetooth connectivity and an ergonomic design, it ensures comfort and precision for all-day productivity.\n",
      "\n",
      "Word count: 29 words\n",
      "\n",
      "============================================================\n",
      "üí° Notice how constraints shape the output!\n",
      "============================================================\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "fc146845",
   "metadata": {},
   "source": [
    "## üîÑ Iterative Refinement Example\n",
    "\n",
    "One of the most powerful techniques is **iterative refinement** - starting with a simple prompt and improving it based on the output.\n",
    "\n",
    "### The Process\n",
    "\n",
    "1. **Initial Prompt** ‚Üí Get response\n",
    "2. **Identify Issues** ‚Üí What's wrong or missing?\n",
    "3. **Refine Prompt** ‚Üí Add details, constraints, examples\n",
    "4. **Test Again** ‚Üí Compare with previous output\n",
    "5. **Repeat** ‚Üí Until satisfied\n",
    "\n",
    "### Example: Email Generation\n",
    "\n",
    "Let's see how iterative refinement improves results:\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "d876f5b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T03:02:38.986917Z",
     "start_time": "2025-12-16T03:02:29.389092Z"
    }
   },
   "source": [
    "# Hands-on Example: Iterative Refinement\n",
    "print(\"=\" * 60)\n",
    "print(\"üîÑ Iterative Refinement: Email Generation\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Iteration 1: Basic prompt\n",
    "print(\"\\nüìù Iteration 1: Basic Prompt\")\n",
    "print(\"-\" * 60)\n",
    "prompt_v1 = \"Write an email.\"\n",
    "print(f\"Prompt: {prompt_v1}\")\n",
    "response_v1 = connector.get_completion(prompt_v1)\n",
    "if hasattr(response_v1, 'content'):\n",
    "    print(f\"Response length: {len(response_v1.content)} characters\")\n",
    "    print(f\"Preview: {response_v1.content[:100]}...\")\n",
    "elif isinstance(response_v1, dict):\n",
    "    content = response_v1.get('content', '')\n",
    "    print(f\"Response length: {len(content)} characters\")\n",
    "    print(f\"Preview: {content[:100]}...\")\n",
    "\n",
    "# Iteration 2: Add context\n",
    "print(\"\\nüìù Iteration 2: Add Context\")\n",
    "print(\"-\" * 60)\n",
    "prompt_v2 = \"Write an email to a colleague requesting feedback on a project proposal.\"\n",
    "print(f\"Prompt: {prompt_v2}\")\n",
    "response_v2 = connector.get_completion(prompt_v2)\n",
    "if hasattr(response_v2, 'content'):\n",
    "    print(f\"Response length: {len(response_v2.content)} characters\")\n",
    "    print(f\"Preview: {response_v2.content[:100]}...\")\n",
    "elif isinstance(response_v2, dict):\n",
    "    content = response_v2.get('content', '')\n",
    "    print(f\"Response length: {len(content)} characters\")\n",
    "    print(f\"Preview: {content[:100]}...\")\n",
    "\n",
    "# Iteration 3: Add tone and format constraints\n",
    "print(\"\\nüìù Iteration 3: Add Tone & Format\")\n",
    "print(\"-\" * 60)\n",
    "prompt_v3 = \"\"\"Write a professional email to a colleague requesting feedback on a project proposal.\n",
    "Requirements:\n",
    "- Professional but friendly tone\n",
    "- Keep it concise (2-3 paragraphs)\n",
    "- Include: project overview, specific feedback needed, deadline\n",
    "- Subject line included\"\"\"\n",
    "print(f\"Prompt: {prompt_v3[:120]}...\")\n",
    "response_v3 = connector.get_completion(prompt_v3)\n",
    "if hasattr(response_v3, 'content'):\n",
    "    print(f\"Response length: {len(response_v3.content)} characters\")\n",
    "    print(f\"Preview: {response_v3.content[:150]}...\")\n",
    "elif isinstance(response_v3, dict):\n",
    "    content = response_v3.get('content', '')\n",
    "    print(f\"Response length: {len(content)} characters\")\n",
    "    print(f\"Preview: {content[:150]}...\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üí° Notice how each iteration improves specificity and quality!\")\n",
    "print(\"=\" * 60)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üîÑ Iterative Refinement: Email Generation\n",
      "============================================================\n",
      "\n",
      "üìù Iteration 1: Basic Prompt\n",
      "------------------------------------------------------------\n",
      "Prompt: Write an email.\n",
      "Response length: 189 characters\n",
      "Preview: Certainly! Could you please provide more details about the email you'd like written? For example, wh...\n",
      "\n",
      "üìù Iteration 2: Add Context\n",
      "------------------------------------------------------------\n",
      "Prompt: Write an email to a colleague requesting feedback on a project proposal.\n",
      "Response length: 1195 characters\n",
      "Preview: Subject: Request for Feedback on Project Proposal\n",
      "\n",
      "Hi [Colleague's Name],\n",
      "\n",
      "I hope this message finds...\n",
      "\n",
      "üìù Iteration 3: Add Tone & Format\n",
      "------------------------------------------------------------\n",
      "Prompt: Write a professional email to a colleague requesting feedback on a project proposal.\n",
      "Requirements:\n",
      "- Professional but fr...\n",
      "Response length: 1175 characters\n",
      "Preview: Subject: Request for Feedback on Project Proposal\n",
      "\n",
      "Hi [Colleague's Name],\n",
      "\n",
      "I hope this message finds you well. I am reaching out to request your feedb...\n",
      "\n",
      "============================================================\n",
      "üí° Notice how each iteration improves specificity and quality!\n",
      "============================================================\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "c84fe251",
   "metadata": {},
   "source": [
    "## üé® Template-Based Prompting Examples\n",
    "\n",
    "Templates are reusable prompt structures that you can customize for different tasks.\n",
    "\n",
    "### Example Templates\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "92d15dc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T03:03:03.423932Z",
     "start_time": "2025-12-16T03:02:39.000657Z"
    }
   },
   "source": [
    "# Hands-on Example: Template-Based Prompting\n",
    "print(\"=\" * 60)\n",
    "print(\"üé® Template-Based Prompting Examples\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Template 1: Code Review Template\n",
    "print(\"\\nüìã Template 1: Code Review\")\n",
    "print(\"-\" * 60)\n",
    "code_review_template = \"\"\"You are a senior code reviewer. Review the following code:\n",
    "\n",
    "Code:\n",
    "```python\n",
    "{code}\n",
    "```\n",
    "\n",
    "Provide:\n",
    "1. Code quality assessment\n",
    "2. Potential bugs or issues\n",
    "3. Suggestions for improvement\n",
    "4. Best practices recommendations\"\"\"\n",
    "\n",
    "# Example usage\n",
    "sample_code = \"\"\"\n",
    "def calculate_total(items):\n",
    "    total = 0\n",
    "    for item in items:\n",
    "        total = total + item.price\n",
    "    return total\n",
    "\"\"\"\n",
    "\n",
    "prompt_code_review = code_review_template.format(code=sample_code)\n",
    "print(f\"Template filled with code example\")\n",
    "response_code = connector.get_completion(prompt_code_review)\n",
    "if hasattr(response_code, 'content'):\n",
    "    print(f\"Response: {response_code.content[:250]}...\")\n",
    "elif isinstance(response_code, dict):\n",
    "    print(f\"Response: {response_code.get('content', '')[:250]}...\")\n",
    "\n",
    "# Template 2: Content Generation Template\n",
    "print(\"\\nüìã Template 2: Content Generation\")\n",
    "print(\"-\" * 60)\n",
    "content_template = \"\"\"You are a {role} writing {content_type} about {topic}.\n",
    "\n",
    "Requirements:\n",
    "- Target audience: {audience}\n",
    "- Tone: {tone}\n",
    "- Length: {length}\n",
    "- Key points to cover: {key_points}\n",
    "\n",
    "Generate the {content_type}:\"\"\"\n",
    "\n",
    "# Example usage\n",
    "prompt_content = content_template.format(\n",
    "    role=\"marketing expert\",\n",
    "    content_type=\"blog post\",\n",
    "    topic=\"sustainable technology\",\n",
    "    audience=\"tech-savvy professionals\",\n",
    "    tone=\"informative and engaging\",\n",
    "    length=\"500 words\",\n",
    "    key_points=\"environmental impact, cost savings, implementation\"\n",
    ")\n",
    "print(f\"Template filled with marketing example\")\n",
    "response_content = connector.get_completion(prompt_content)\n",
    "if hasattr(response_content, 'content'):\n",
    "    print(f\"Response: {response_content.content[:200]}...\")\n",
    "elif isinstance(response_content, dict):\n",
    "    print(f\"Response: {response_content.get('content', '')[:200]}...\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üí° Templates make prompts reusable and consistent!\")\n",
    "print(\"=\" * 60)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üé® Template-Based Prompting Examples\n",
      "============================================================\n",
      "\n",
      "üìã Template 1: Code Review\n",
      "------------------------------------------------------------\n",
      "Template filled with code example\n",
      "Response: Certainly! Here's a review of the provided Python code:\n",
      "\n",
      "### 1. Code Quality Assessment\n",
      "- **Readability**: The code is quite readable, with a clear function name (`calculate_total`) that indicates its purpose.\n",
      "- **Simplicity**: The function is straig...\n",
      "\n",
      "üìã Template 2: Content Generation\n",
      "------------------------------------------------------------\n",
      "Template filled with marketing example\n",
      "Response: **Embracing Sustainable Technology: A Smart Move for Tech-Savvy Professionals**\n",
      "\n",
      "In today's fast-paced digital world, the push towards sustainability is more pronounced than ever. As tech-savvy profes...\n",
      "\n",
      "============================================================\n",
      "üí° Templates make prompts reusable and consistent!\n",
      "============================================================\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "80b3a194",
   "metadata": {},
   "source": [
    "## üîó Prompt Chaining Examples\n",
    "\n",
    "Prompt chaining breaks complex tasks into smaller, manageable steps. Each step builds on the previous one.\n",
    "\n",
    "### When to Use Chaining\n",
    "\n",
    "- Multi-step reasoning tasks\n",
    "- Tasks requiring intermediate outputs\n",
    "- Complex analysis that needs structure\n",
    "- When you need to verify intermediate steps\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "3dfbfbb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T03:03:11.945472Z",
     "start_time": "2025-12-16T03:03:03.437147Z"
    }
   },
   "source": [
    "# Hands-on Example: Prompt Chaining\n",
    "print(\"=\" * 60)\n",
    "print(\"üîó Prompt Chaining: Multi-Step Analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Sample text to analyze\n",
    "sample_text = \"\"\"\n",
    "The company reported record profits this quarter, with revenue increasing by 25% \n",
    "compared to last year. However, employee satisfaction surveys show a decline, \n",
    "and several key executives have left. The stock price has been volatile, \n",
    "dropping 10% after the earnings announcement despite positive numbers.\n",
    "\"\"\"\n",
    "\n",
    "print(f\"\\nüìÑ Sample Text:\\n{sample_text}\")\n",
    "\n",
    "# Step 1: Extract key points\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Step 1: Extract Key Points\")\n",
    "print(\"-\" * 60)\n",
    "step1_prompt = f\"\"\"Extract the key points from the following text:\n",
    "\n",
    "Text:\n",
    "---\n",
    "{sample_text}\n",
    "---\n",
    "\n",
    "List each key point as a bullet point.\"\"\"\n",
    "response_step1 = connector.get_completion(step1_prompt)\n",
    "if hasattr(response_step1, 'content'):\n",
    "    key_points = response_step1.content\n",
    "    print(f\"Key Points:\\n{key_points[:300]}...\")\n",
    "elif isinstance(response_step1, dict):\n",
    "    key_points = response_step1.get('content', '')\n",
    "    print(f\"Key Points:\\n{key_points[:300]}...\")\n",
    "\n",
    "# Step 2: Analyze sentiment\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Step 2: Analyze Sentiment\")\n",
    "print(\"-\" * 60)\n",
    "step2_prompt = f\"\"\"Analyze the sentiment of the following text. \n",
    "Identify positive and negative aspects:\n",
    "\n",
    "Text:\n",
    "---\n",
    "{sample_text}\n",
    "---\n",
    "\n",
    "Provide a sentiment analysis with specific examples.\"\"\"\n",
    "response_step2 = connector.get_completion(step2_prompt)\n",
    "if hasattr(response_step2, 'content'):\n",
    "    sentiment = response_step2.content\n",
    "    print(f\"Sentiment Analysis:\\n{sentiment[:300]}...\")\n",
    "elif isinstance(response_step2, dict):\n",
    "    sentiment = response_step2.get('content', '')\n",
    "    print(f\"Sentiment Analysis:\\n{sentiment[:300]}...\")\n",
    "\n",
    "# Step 3: Generate summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Step 3: Generate Executive Summary\")\n",
    "print(\"-\" * 60)\n",
    "step3_prompt = f\"\"\"Based on the following text, create an executive summary \n",
    "highlighting the main findings and their implications:\n",
    "\n",
    "Text:\n",
    "---\n",
    "{sample_text}\n",
    "---\n",
    "\n",
    "Format: 3-4 sentences, executive-level language.\"\"\"\n",
    "response_step3 = connector.get_completion(step3_prompt)\n",
    "if hasattr(response_step3, 'content'):\n",
    "    summary = response_step3.content\n",
    "    print(f\"Executive Summary:\\n{summary}\")\n",
    "elif isinstance(response_step3, dict):\n",
    "    summary = response_step3.get('content', '')\n",
    "    print(f\"Executive Summary:\\n{summary}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üí° Chaining breaks complex tasks into manageable steps!\")\n",
    "print(\"=\" * 60)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üîó Prompt Chaining: Multi-Step Analysis\n",
      "============================================================\n",
      "\n",
      "üìÑ Sample Text:\n",
      "\n",
      "The company reported record profits this quarter, with revenue increasing by 25% \n",
      "compared to last year. However, employee satisfaction surveys show a decline, \n",
      "and several key executives have left. The stock price has been volatile, \n",
      "dropping 10% after the earnings announcement despite positive numbers.\n",
      "\n",
      "\n",
      "============================================================\n",
      "Step 1: Extract Key Points\n",
      "------------------------------------------------------------\n",
      "Key Points:\n",
      "- The company reported record profits for the current quarter.\n",
      "- Revenue increased by 25% compared to the previous year.\n",
      "- Employee satisfaction surveys indicate a decline in satisfaction.\n",
      "- Several key executives have left the company.\n",
      "- The stock price has been volatile, experiencing a 10% drop af...\n",
      "\n",
      "============================================================\n",
      "Step 2: Analyze Sentiment\n",
      "------------------------------------------------------------\n",
      "Sentiment Analysis:\n",
      "The sentiment of the text is mixed, with both positive and negative aspects present. Here's a breakdown:\n",
      "\n",
      "**Positive Aspects:**\n",
      "1. **Record Profits:** The text mentions that the company reported record profits for the quarter. This is a positive aspect as it indicates strong financial performance.\n",
      "2...\n",
      "\n",
      "============================================================\n",
      "Step 3: Generate Executive Summary\n",
      "------------------------------------------------------------\n",
      "Executive Summary:\n",
      "The company achieved record profits this quarter, with a remarkable 25% increase in revenue compared to the previous year. Despite these financial gains, there has been a notable decline in employee satisfaction, accompanied by the departure of several key executives, which could signal underlying organizational challenges. The stock price experienced a 10% decline following the earnings announcement, indicating potential investor concerns over internal stability. Addressing employee morale and leadership continuity will be crucial to sustaining financial success and restoring investor confidence.\n",
      "\n",
      "============================================================\n",
      "üí° Chaining breaks complex tasks into manageable steps!\n",
      "============================================================\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "1e69f5aa",
   "metadata": {},
   "source": [
    "## üí∞ Cost Optimization Examples\n",
    "\n",
    "Let's see practical examples of how to optimize costs while maintaining quality.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "14bcfe8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T03:03:13.156364Z",
     "start_time": "2025-12-16T03:03:11.956632Z"
    }
   },
   "source": [
    "# Hands-on Example: Cost Optimization\n",
    "print(\"=\" * 60)\n",
    "print(\"üí∞ Cost Optimization: Token Efficiency\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Example 1: Verbose vs Concise\n",
    "print(\"\\nüìä Example 1: Verbose vs Concise Prompts\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "verbose_prompt = \"\"\"I would like you to please provide me with a comprehensive and detailed \n",
    "explanation of what machine learning is, including all the important aspects and \n",
    "key concepts that someone should know about this topic. Please make sure to \n",
    "cover everything thoroughly.\"\"\"\n",
    "\n",
    "concise_prompt = \"Explain machine learning in 3 sentences.\"\n",
    "\n",
    "print(f\"Verbose prompt length: {len(verbose_prompt)} characters\")\n",
    "print(f\"Concise prompt length: {len(concise_prompt)} characters\")\n",
    "print(f\"Savings: {len(verbose_prompt) - len(concise_prompt)} characters ({((len(verbose_prompt) - len(concise_prompt)) / len(verbose_prompt) * 100):.1f}% reduction)\")\n",
    "\n",
    "# Test both\n",
    "print(\"\\nTesting concise prompt:\")\n",
    "response_concise = connector.get_completion(concise_prompt)\n",
    "if hasattr(response_concise, 'content'):\n",
    "    print(f\"Response: {response_concise.content[:150]}...\")\n",
    "elif isinstance(response_concise, dict):\n",
    "    print(f\"Response: {response_concise.get('content', '')[:150]}...\")\n",
    "\n",
    "# Example 2: Removing unnecessary words\n",
    "print(\"\\nüìä Example 2: Removing Unnecessary Words\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "original = \"\"\"I would really appreciate it if you could possibly help me by \n",
    "writing a Python function that can calculate the factorial of a given number.\"\"\"\n",
    "\n",
    "optimized = \"Write a Python function to calculate factorial of a number.\"\n",
    "\n",
    "print(f\"Original: {len(original)} characters\")\n",
    "print(f\"Optimized: {len(optimized)} characters\")\n",
    "print(f\"Savings: {len(original) - len(optimized)} characters ({((len(original) - len(optimized)) / len(original) * 100):.1f}% reduction)\")\n",
    "\n",
    "# Example 3: Using abbreviations vs full words (when appropriate)\n",
    "print(\"\\nüìä Example 3: Strategic Abbreviations\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "full_words = \"\"\"Please provide a comprehensive analysis of the following data \n",
    "regarding customer satisfaction metrics and provide recommendations.\"\"\"\n",
    "\n",
    "abbreviated = \"\"\"Analyze customer satisfaction data and provide recommendations.\"\"\"\n",
    "\n",
    "print(f\"Full words: {len(full_words)} characters\")\n",
    "print(f\"Abbreviated: {len(abbreviated)} characters\")\n",
    "print(f\"Savings: {len(full_words) - len(abbreviated)} characters ({((len(full_words) - len(abbreviated)) / len(full_words) * 100):.1f}% reduction)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üí° Small optimizations add up to significant cost savings!\")\n",
    "print(\"=\" * 60)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üí∞ Cost Optimization: Token Efficiency\n",
      "============================================================\n",
      "\n",
      "üìä Example 1: Verbose vs Concise Prompts\n",
      "------------------------------------------------------------\n",
      "Verbose prompt length: 260 characters\n",
      "Concise prompt length: 40 characters\n",
      "Savings: 220 characters (84.6% reduction)\n",
      "\n",
      "Testing concise prompt:\n",
      "Response: Machine learning is a subset of artificial intelligence that focuses on building systems that can learn from and make decisions based on data. It invo...\n",
      "\n",
      "üìä Example 2: Removing Unnecessary Words\n",
      "------------------------------------------------------------\n",
      "Original: 140 characters\n",
      "Optimized: 59 characters\n",
      "Savings: 81 characters (57.9% reduction)\n",
      "\n",
      "üìä Example 3: Strategic Abbreviations\n",
      "------------------------------------------------------------\n",
      "Full words: 131 characters\n",
      "Abbreviated: 63 characters\n",
      "Savings: 68 characters (51.9% reduction)\n",
      "\n",
      "============================================================\n",
      "üí° Small optimizations add up to significant cost savings!\n",
      "============================================================\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "ca754565",
   "metadata": {},
   "source": [
    "## üéØ Advanced Examples: Combining Techniques\n",
    "\n",
    "The most powerful prompts combine multiple techniques. Let's see some examples:\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "4b0c01d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T03:03:17.656427Z",
     "start_time": "2025-12-16T03:03:13.164965Z"
    }
   },
   "source": [
    "# Hands-on Example: Combining Multiple Techniques\n",
    "print(\"=\" * 60)\n",
    "print(\"üéØ Advanced: Combining Multiple Techniques\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Example: Role + Chain-of-Thought + Constraints\n",
    "print(\"\\nüìã Example: Role + CoT + Constraints\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "combined_prompt = \"\"\"You are a data scientist explaining to a business executive.\n",
    "\n",
    "Task: Explain why a machine learning model's accuracy dropped from 95% to 85%.\n",
    "\n",
    "Requirements:\n",
    "1. Show your reasoning step by step\n",
    "2. Use business-friendly language (avoid technical jargon)\n",
    "3. Keep it under 150 words\n",
    "4. Include 2-3 actionable recommendations\n",
    "\n",
    "Step-by-step explanation:\"\"\"\n",
    "\n",
    "print(f\"Prompt combines: Role + Chain-of-Thought + Constraints\")\n",
    "response_combined = connector.get_completion(combined_prompt)\n",
    "if hasattr(response_combined, 'content'):\n",
    "    print(f\"\\nResponse:\\n{response_combined.content}\")\n",
    "    word_count = len(response_combined.content.split())\n",
    "    print(f\"\\nWord count: {word_count} words\")\n",
    "elif isinstance(response_combined, dict):\n",
    "    content = response_combined.get('content', '')\n",
    "    print(f\"\\nResponse:\\n{content}\")\n",
    "    word_count = len(content.split())\n",
    "    print(f\"\\nWord count: {word_count} words\")\n",
    "\n",
    "# Example: Few-shot + Delimiter + Format\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìã Example: Few-shot + Delimiter + Format\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "few_shot_delimiter = \"\"\"Convert the following dates to ISO format (YYYY-MM-DD):\n",
    "\n",
    "Examples:\n",
    "January 15, 2023 ‚Üí 2023-01-15\n",
    "March 3, 2024 ‚Üí 2024-03-03\n",
    "December 25, 2022 ‚Üí 2022-12-25\n",
    "\n",
    "Now convert:\n",
    "---\n",
    "Date: July 4, 2025\n",
    "---\n",
    "\n",
    "Format: YYYY-MM-DD only\"\"\"\n",
    "\n",
    "print(f\"Prompt combines: Few-shot + Delimiter + Format constraint\")\n",
    "response_format = connector.get_completion(few_shot_delimiter)\n",
    "if hasattr(response_format, 'content'):\n",
    "    print(f\"\\nResponse: {response_format.content}\")\n",
    "elif isinstance(response_format, dict):\n",
    "    print(f\"\\nResponse: {response_format.get('content', '')}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üí° Combining techniques creates powerful, precise prompts!\")\n",
    "print(\"=\" * 60)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üéØ Advanced: Combining Multiple Techniques\n",
      "============================================================\n",
      "\n",
      "üìã Example: Role + CoT + Constraints\n",
      "------------------------------------------------------------\n",
      "Prompt combines: Role + Chain-of-Thought + Constraints\n",
      "\n",
      "Response:\n",
      "Certainly! Let's break it down:\n",
      "\n",
      "1. **Data Changes**: The data the model was trained on might be different from the current data. For instance, customer preferences or market trends may have shifted, causing the model to perform less accurately.\n",
      "\n",
      "2. **Model Drift**: Over time, a model can become less effective as it doesn't adapt to new patterns or information, similar to a tool that becomes dull without regular maintenance.\n",
      "\n",
      "3. **External Factors**: New competitors, economic shifts, or regulatory changes might have impacted the environment in which the model operates, affecting its accuracy.\n",
      "\n",
      "**Recommendations**:\n",
      "- **Regular Updates**: Regularly update and retrain the model with fresh data to ensure it reflects the latest market conditions.\n",
      "- **Monitor Performance**: Establish a monitoring system to detect accuracy drops early, allowing for quicker responses.\n",
      "- **Investigate Changes**: Conduct regular reviews to understand any external changes impacting the model, and adjust strategies accordingly.\n",
      "\n",
      "Word count: 147 words\n",
      "\n",
      "============================================================\n",
      "üìã Example: Few-shot + Delimiter + Format\n",
      "------------------------------------------------------------\n",
      "Prompt combines: Few-shot + Delimiter + Format constraint\n",
      "\n",
      "Response: 2025-07-04\n",
      "\n",
      "============================================================\n",
      "üí° Combining techniques creates powerful, precise prompts!\n",
      "============================================================\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "4646f883",
   "metadata": {},
   "source": [
    "## üìà Real-World Use Case Examples\n",
    "\n",
    "Let's see how prompt engineering applies to common real-world scenarios:\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "5b9ef40b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T03:03:26.587235Z",
     "start_time": "2025-12-16T03:03:17.667397Z"
    }
   },
   "source": [
    "# Real-World Use Case Examples\n",
    "print(\"=\" * 60)\n",
    "print(\"üìà Real-World Use Cases\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Use Case 1: Customer Support\n",
    "print(\"\\nüí¨ Use Case 1: Customer Support Chatbot\")\n",
    "print(\"-\" * 60)\n",
    "customer_support_prompt = \"\"\"You are a helpful customer support agent for an e-commerce company.\n",
    "\n",
    "Customer inquiry: \"My order hasn't arrived yet and it's been 2 weeks. What should I do?\"\n",
    "\n",
    "Guidelines:\n",
    "- Be empathetic and professional\n",
    "- Provide clear next steps\n",
    "- Offer to help track the order\n",
    "- Keep response under 100 words\n",
    "\n",
    "Response:\"\"\"\n",
    "response_support = connector.get_completion(customer_support_prompt)\n",
    "if hasattr(response_support, 'content'):\n",
    "    print(f\"Response: {response_support.content}\")\n",
    "elif isinstance(response_support, dict):\n",
    "    print(f\"Response: {response_support.get('content', '')}\")\n",
    "\n",
    "# Use Case 2: Code Documentation\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üíª Use Case 2: Code Documentation Generator\")\n",
    "print(\"-\" * 60)\n",
    "code_doc_prompt = \"\"\"Generate documentation for this Python function:\n",
    "\n",
    "```python\n",
    "def process_payment(amount, currency='USD', payment_method='credit'):\n",
    "    if amount <= 0:\n",
    "        raise ValueError(\"Amount must be positive\")\n",
    "    if currency not in ['USD', 'EUR', 'GBP']:\n",
    "        raise ValueError(\"Unsupported currency\")\n",
    "    # Process payment logic here\n",
    "    return {\"status\": \"success\", \"transaction_id\": \"12345\"}\n",
    "```\n",
    "\n",
    "Requirements:\n",
    "- Docstring in Google style\n",
    "- Parameter descriptions\n",
    "- Return value description\n",
    "- Exception documentation\n",
    "- Usage example\"\"\"\n",
    "response_doc = connector.get_completion(code_doc_prompt)\n",
    "if hasattr(response_doc, 'content'):\n",
    "    print(f\"Documentation:\\n{response_doc.content[:400]}...\")\n",
    "elif isinstance(response_doc, dict):\n",
    "    print(f\"Documentation:\\n{response_doc.get('content', '')[:400]}...\")\n",
    "\n",
    "# Use Case 3: Content Moderation\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üõ°Ô∏è Use Case 3: Content Moderation\")\n",
    "print(\"-\" * 60)\n",
    "moderation_prompt = \"\"\"Analyze the following user comment for moderation:\n",
    "\n",
    "Comment: \"This product is terrible and the company should be ashamed!\"\n",
    "\n",
    "Task: Determine if this comment violates community guidelines.\n",
    "\n",
    "Guidelines:\n",
    "- Allow: Constructive criticism, honest reviews\n",
    "- Flag: Hate speech, personal attacks, spam\n",
    "\n",
    "Analysis format:\n",
    "1. Violation status (Yes/No)\n",
    "2. Reason\n",
    "3. Recommended action\"\"\"\n",
    "response_mod = connector.get_completion(moderation_prompt)\n",
    "if hasattr(response_mod, 'content'):\n",
    "    print(f\"Analysis:\\n{response_mod.content}\")\n",
    "elif isinstance(response_mod, dict):\n",
    "    print(f\"Analysis:\\n{response_mod.get('content', '')}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üí° These examples show practical applications of prompt engineering!\")\n",
    "print(\"=\" * 60)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üìà Real-World Use Cases\n",
      "============================================================\n",
      "\n",
      "üí¨ Use Case 1: Customer Support Chatbot\n",
      "------------------------------------------------------------\n",
      "Response: I'm really sorry to hear your order hasn't arrived yet. I understand how frustrating this can be. Let me help you track your order and find out what's going on. Could you please provide me with your order number? Once I have that, I'll look into it right away and update you with the next steps. Thank you for your patience.\n",
      "\n",
      "============================================================\n",
      "üíª Use Case 2: Code Documentation Generator\n",
      "------------------------------------------------------------\n",
      "Documentation:\n",
      "```python\n",
      "def process_payment(amount, currency='USD', payment_method='credit'):\n",
      "    \"\"\"Processes a payment with the specified amount, currency, and payment method.\n",
      "\n",
      "    Args:\n",
      "        amount (float): The amount to be processed. Must be a positive value.\n",
      "        currency (str, optional): The currency in which the amount is specified. \n",
      "            Supported currencies are 'USD', 'EUR', and 'GBP'. Def...\n",
      "\n",
      "============================================================\n",
      "üõ°Ô∏è Use Case 3: Content Moderation\n",
      "------------------------------------------------------------\n",
      "Analysis:\n",
      "1. Violation status: No\n",
      "2. Reason: The comment does not contain hate speech, personal attacks, or spam. It expresses a negative opinion about a product and the company, which falls under the category of honest reviews or constructive criticism.\n",
      "3. Recommended action: Allow the comment to remain, as it does not violate community guidelines.\n",
      "\n",
      "============================================================\n",
      "üí° These examples show practical applications of prompt engineering!\n",
      "============================================================\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "a7572486-7aa2-4e67-bf5b-0ff98c30b237",
   "metadata": {},
   "source": [
    "## üìê Prompt Design Best Practices\n",
    "\n",
    "‚úîÔ∏è Be clear and specific  \n",
    "‚úîÔ∏è Set the desired tone or style (e.g., formal, concise)  \n",
    "‚úîÔ∏è Use context to guide responses  \n",
    "‚úîÔ∏è Experiment with phrasing and ordering  \n",
    "‚úîÔ∏è Test iteratively and refine based on outputs  \n",
    "\n",
    "### üìù Example\n",
    "- ‚ùå ‚ÄúWrite a summary.‚Äù\n",
    "- ‚úÖ ‚ÄúSummarize the following news article in 3 bullet points, focusing on key facts.‚Äù"
   ]
  },
  {
   "cell_type": "code",
   "id": "4b65dbca-30c0-4342-9ad8-098c7c8b64cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T03:03:35.607938Z",
     "start_time": "2025-12-16T03:03:26.596112Z"
    }
   },
   "source": [
    "# Prompt: Provide 5 prompt design best practices with a good vs bad example for each\n",
    "prompt = (\n",
    "    \"Provide 5 best practices for designing prompts for Large Language Models. \"\n",
    "    \"For each, include a bad example and a corrected good example.\"\n",
    ")\n",
    "\n",
    "response = connector.get_completion(prompt)\n",
    "print(response['content'] if isinstance(response, dict) else response)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Designing effective prompts for Large Language Models (LLMs) is crucial for eliciting accurate and useful responses. Here are five best practices for prompt design, along with examples of both ineffective and improved prompts:\\n\\n1. **Clarity and Specificity**\\n\\n   - **Bad Example:** \"Tell me about history.\"\\n   - **Good Example:** \"Provide a summary of the key events that led to the American Revolution in the 18th century.\"\\n\\n   *Explanation:* The bad example is too vague, leading to a broad and unfocused response. The good example narrows the scope to a specific historical event, encouraging a more targeted and informative reply.\\n\\n2. **Contextual Information**\\n\\n   - **Bad Example:** \"Explain quantum mechanics.\"\\n   - **Good Example:** \"Explain quantum mechanics to someone with a basic understanding of classical physics but no knowledge of advanced mathematics.\"\\n\\n   *Explanation:* The bad example lacks context regarding the audience\\'s knowledge level. The good example provides context, allowing the model to tailor the complexity of the explanation appropriately.\\n\\n3. **Avoiding Ambiguity**\\n\\n   - **Bad Example:** \"What\\'s the best way to prepare?\"\\n   - **Good Example:** \"What are the best strategies for preparing for a job interview in the tech industry?\"\\n\\n   *Explanation:* The bad example is ambiguous and can be interpreted in many ways. The good example specifies the context and goal, which helps the model deliver a more relevant and useful response.\\n\\n4. **Explicit Instructions**\\n\\n   - **Bad Example:** \"Write a story.\"\\n   - **Good Example:** \"Write a 200-word short story about a young astronaut who discovers a new planet, focusing on their emotions during the discovery.\"\\n\\n   *Explanation:* The bad example provides no guidance on content or structure. The good example sets clear parameters, including length, theme, and focus, guiding the model to produce a coherent story.\\n\\n5. **Use of Examples**\\n\\n   - **Bad Example:** \"Give me a recipe.\"\\n   - **Good Example:** \"Provide a step-by-step recipe for making a traditional Italian Margherita pizza, including the ingredients and cooking time.\"\\n\\n   *Explanation:* The bad example is too general, potentially leading to an array of unrelated recipes. The good example specifies the type of recipe desired and requests detailed instructions, ensuring a more precise output.\\n\\nBy applying these best practices, you can enhance the effectiveness of prompts and obtain more accurate and relevant responses from LLMs.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "5af93313-500a-4117-bd37-a250f9aa31ce",
   "metadata": {},
   "source": [
    "## ‚ö° LLM Optimization Techniques\n",
    "\n",
    "Optimizing LLM usage involves balancing cost, speed, and quality. Here are key strategies:\n",
    "\n",
    "### Cost Optimization\n",
    "\n",
    "1. **üîÑ Response Caching**\n",
    "   - Cache common queries and responses\n",
    "   - **Savings**: 50-90% cost reduction for repeated queries\n",
    "   - **Example**: Cache FAQ answers, common translations\n",
    "\n",
    "2. **üìù Token Optimization**\n",
    "   - Keep prompts concise and focused\n",
    "   - Remove unnecessary words\n",
    "   - **Savings**: Each token costs money - shorter = cheaper\n",
    "   - **Example**: \"Summarize\" vs \"Please provide a comprehensive summary\"\n",
    "\n",
    "3. **üåê Model Selection**\n",
    "   - Use smaller models for simple tasks\n",
    "   - Reserve large models for complex tasks\n",
    "   - **Savings**: GPT-3.5 is 10x cheaper than GPT-4\n",
    "   - **Example**: Use GPT-3.5 for simple Q&A, GPT-4 for complex reasoning\n",
    "\n",
    "### Performance Optimization\n",
    "\n",
    "4. **üßÆ Request Batching**\n",
    "   - Process multiple requests together\n",
    "   - **Benefit**: Better throughput, lower latency per request\n",
    "   - **Example**: Batch 10 translation requests instead of 10 separate calls\n",
    "\n",
    "5. **üß† Fine-tuning**\n",
    "   - Fine-tune for specific domains/tasks\n",
    "   - **Benefit**: Better accuracy, fewer tokens needed\n",
    "   - **Example**: Fine-tune for medical terminology\n",
    "\n",
    "6. **‚ö° Streaming Responses**\n",
    "   - Stream tokens as they're generated\n",
    "   - **Benefit**: Perceived faster response time\n",
    "   - **Example**: ChatGPT shows text as it generates\n",
    "\n",
    "### Quality Optimization\n",
    "\n",
    "7. **üéØ Temperature Tuning**\n",
    "   - Lower temperature (0-0.3) for factual tasks\n",
    "   - Higher temperature (0.7-1.0) for creativity\n",
    "   - **Benefit**: Better task-specific performance\n",
    "\n",
    "8. **üìä Top-p Sampling**\n",
    "   - Control diversity of responses\n",
    "   - **Benefit**: Balance between creativity and coherence"
   ]
  },
  {
   "cell_type": "code",
   "id": "7e44fe04-cae4-4dc6-a2f1-8acf41852423",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T03:03:44.487327Z",
     "start_time": "2025-12-16T03:03:35.623094Z"
    }
   },
   "source": [
    "# Prompt: List 5 LLM optimization techniques with real-world use cases\n",
    "prompt = (\n",
    "    \"List and explain 5 optimization techniques for using Large Language Models. \"\n",
    "    \"Include a real-world example for each technique.\"\n",
    ")\n",
    "\n",
    "response = connector.get_completion(prompt)\n",
    "print(response['content'] if isinstance(response, dict) else response)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Optimizing the use of Large Language Models (LLMs) is crucial for improving performance, reducing costs, and tailoring them to specific applications. Here are five optimization techniques with real-world examples for each:\\n\\n1. **Fine-Tuning**:\\n   - **Explanation**: Fine-tuning involves taking a pre-trained LLM and further training it on a specific dataset that is relevant to a particular task or domain. This allows the model to adapt and perform better on specific tasks than a general-purpose model.\\n   - **Real-World Example**: OpenAI\\'s GPT models can be fine-tuned for customer support applications by training them on a dataset of past customer interactions, thereby improving their ability to handle specific queries related to a company\\'s products or services.\\n\\n2. **Distillation**:\\n   - **Explanation**: Model distillation is a technique where a smaller model (the \"student\") is trained to replicate the behavior of a larger model (the \"teacher\"). The smaller model can perform similar tasks with reduced computational resources.\\n   - **Real-World Example**: Google used model distillation to create smaller, more efficient versions of BERT for use in mobile applications, such as Google Search, where resource constraints are significant.\\n\\n3. **Prompt Engineering**:\\n   - **Explanation**: This involves crafting specific prompts to guide the LLM to generate the desired output more effectively. By altering the way a question is asked or the context provided, users can influence the model\\'s responses.\\n   - **Real-World Example**: In content generation, a marketing team might experiment with different prompt phrasings to get an AI to generate catchy slogans or ad copies, optimizing for creativity or tone based on campaign needs.\\n\\n4. **Ensemble Methods**:\\n   - **Explanation**: Combining multiple models to improve performance by averaging their predictions or selecting the best one based on certain criteria. This can enhance accuracy and reliability, especially in decision-making tasks.\\n   - **Real-World Example**: In financial forecasting, firms might use an ensemble of LLMs trained on various economic indicators to predict stock market trends, thereby reducing the risk associated with relying on a single model\\'s predictions.\\n\\n5. **Quantization**:\\n   - **Explanation**: This technique reduces the precision of the model\\'s weights and activations, allowing it to run more efficiently on hardware with limited computational power without significantly sacrificing performance.\\n   - **Real-World Example**: Facebook has employed quantization in deploying LLMs for real-time translation services on mobile devices, enabling faster responses and reduced battery consumption while maintaining translation quality.\\n\\nEach of these techniques helps in optimizing LLMs for specific use cases, balancing performance and resource constraints effectively.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "id": "07113c82-7d01-402b-84fe-ef3a465dbab8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Advanced Prompt Engineering Patterns\n",
    "\n",
    "### Pattern 1: Template-Based Prompts\n",
    "\n",
    "Create reusable templates for common tasks:\n",
    "\n",
    "```python\n",
    "template = \"\"\"\n",
    "You are a {role}. \n",
    "Task: {task}\n",
    "Context: {context}\n",
    "Format: {format}\n",
    "Output:\"\"\"\n",
    "```\n",
    "\n",
    "### Pattern 2: Iterative Refinement\n",
    "\n",
    "Start simple, then refine based on outputs:\n",
    "\n",
    "1. Initial prompt ‚Üí Get response\n",
    "2. Identify issues ‚Üí Refine prompt\n",
    "3. Repeat until satisfied\n",
    "\n",
    "### Pattern 3: Prompt Chaining\n",
    "\n",
    "Break complex tasks into steps:\n",
    "\n",
    "```\n",
    "Step 1: \"Extract key points from this text\"\n",
    "Step 2: \"Summarize these key points\"\n",
    "Step 3: \"Rewrite the summary for a {audience} audience\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Cost Comparison Example\n",
    "\n",
    "**Scenario**: 1 million API calls per month\n",
    "\n",
    "| Strategy | Cost per 1K tokens | Monthly Cost (est.) |\n",
    "|----------|-------------------|---------------------|\n",
    "| GPT-4, no optimization | $0.03 | $30,000 |\n",
    "| GPT-3.5, optimized prompts | $0.002 | $2,000 |\n",
    "| Cached responses (50%) | $0.002 | $1,000 |\n",
    "| **Savings**: 97% reduction! |\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Summary\n",
    "\n",
    "In this notebook, we've covered:\n",
    "\n",
    "‚úÖ **Prompt Engineering Basics** - What it is and why it matters  \n",
    "‚úÖ **Core Techniques** - Zero-shot, few-shot, chain-of-thought, role, delimiter  \n",
    "‚úÖ **Best Practices** - Clarity, specificity, structure, constraints  \n",
    "‚úÖ **Advanced Patterns** - Templates, iterative refinement, chaining  \n",
    "‚úÖ **Optimization Strategies** - Cost, performance, and quality optimization  \n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- **Good prompts** = Better results with less effort\n",
    "- **Technique choice** depends on task complexity\n",
    "- **Optimization** can reduce costs by 90%+\n",
    "- **Iterative refinement** improves prompt quality\n",
    "- **Understanding techniques** helps you choose the right approach\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- **Notebook 6**: Learn how to evaluate prompt effectiveness\n",
    "- **Notebook 8**: Explore fine-tuning as an alternative to prompt engineering\n",
    "- **Practice**: Try different techniques on your own tasks\n",
    "\n",
    "---\n",
    "\n",
    "## üéì Try It Yourself!\n",
    "\n",
    "**Exercise 1**: Write a prompt for generating product descriptions. Try zero-shot, then few-shot. Compare results.\n",
    "\n",
    "**Exercise 2**: Use chain-of-thought prompting to solve a math word problem. Compare with direct prompting.\n",
    "\n",
    "**Exercise 3**: Design a role-based prompt for a specific domain (e.g., legal, medical, technical).\n",
    "\n",
    "**Exercise 4**: Optimize a long prompt by removing unnecessary words while maintaining clarity.\n",
    "\n",
    "**Exercise 5**: Create a prompt template for a task you do frequently. Test it with different inputs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

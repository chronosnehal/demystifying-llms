{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad1d8dcc-6361-402f-9647-1d7196073419",
   "metadata": {},
   "source": [
    "# ðŸ“– Section 5: Prompt Engineering and LLM Optimization\n",
    "\n",
    "Prompt engineering is the key to unlocking the full potential of LLMs. By carefully designing input prompts, we can guide models to produce more accurate, relevant, and creative outputs.  \n",
    "\n",
    "This section explores:  \n",
    "âœ… What prompt engineering is  \n",
    "âœ… Common techniques and strategies  \n",
    "âœ… Practical examples to improve LLM outputs  \n",
    "âœ… Optimization approaches for speed and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bf4f8d9-5038-4269-916b-dac7e366be7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”‘ LLM Configuration Check:\n",
      "âœ… Azure API Details: FOUND\n",
      "âœ… Connected to Azure OpenAI (deployment: gpt-4o)\n",
      "ðŸ“¡ LLM Connector initialized and ready.\n"
     ]
    }
   ],
   "source": [
    "# =============================\n",
    "# ðŸ““ SECTION 5: PROMPT ENGINEERING AND LLM OPTIMIZATION\n",
    "# =============================\n",
    "\n",
    "%run ./utils_llm_connector.ipynb\n",
    "\n",
    "# Create a connector instance\n",
    "connector = LLMConnector()\n",
    "\n",
    "# Confirm connection\n",
    "print(\"ðŸ“¡ LLM Connector initialized and ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f2876a-a6a2-4ebb-b58a-87ca506244e9",
   "metadata": {},
   "source": [
    "## ðŸ”¥ What is Prompt Engineering?\n",
    "\n",
    "Prompt engineering involves crafting the input given to an LLM in a way that optimizes its output.  \n",
    "\n",
    "Think of it as asking a question in just the right way to get the answer you want.  \n",
    "\n",
    "### ðŸ“ Example\n",
    "- âŒ Bad Prompt: â€œWrite Python code.â€  \n",
    "- âœ… Good Prompt: â€œWrite Python code to sort a list of integers in ascending order using the bubble sort algorithm with a time complexity explanation.â€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67c1dcaf-56c1-4bb3-b2b0-5a1cdc150be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Prompt engineering is the process of designing and crafting effective inputs (prompts) to guide large language models (LLMs) like ChatGPT toward generating specific, relevant, and accurate outputs. Since LLMs interpret and respond based on the structure and content of the prompt, the way a prompt is phrased significantly affects the quality and usefulness of the model\\'s response.\\n\\nHere are three simple, real-world analogies to explain prompt engineering:\\n\\n---\\n\\n### 1. **A Recipe Card for Cooking**\\nImagine you\\'re giving instructions to a chef who can make anything. Prompt engineering is like writing a clear and detailed recipe card. If you say, \"Make something tasty,\" the chef might prepare anything, and it may not be what you want. But if you specify, \"Make a spaghetti dish with tomato sauce, garlic, and basil,\" the chef can deliver exactly what you envision. Similarly, LLMs need well-crafted prompts to \"cook up\" the desired output.\\n\\n---\\n\\n### 2. **Talking to a GPS Navigator**\\nWhen using a GPS system, you donâ€™t just say, \"Take me somewhere nice.\" Instead, you give a specific destination, like \"Take me to Central Park in New York City.\" If you provide unclear or incomplete directions, the GPS might lead you to the wrong place. In the same way, prompt engineering ensures that the \"destination\" (the model\\'s response) aligns with your goals by providing precise input.\\n\\n---\\n\\n### 3. **Survey Questions**\\nThink about a survey where you\\'re trying to gather feedback. If you ask a vague question like, \"What do you think?\" you might get answers that are all over the place. But if you ask a structured question like, \"What do you think about the new product design, specifically its color and usability?\" you\\'ll get more focused and actionable responses. Similarly, prompt engineering shapes the structure of a question or task so the model delivers a tailored and relevant output.\\n\\n---\\n\\nIn essence, prompt engineering is about communicating effectively with LLMs to get the best possible results, much like crafting clear instructions or questions in everyday interactions.', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# Prompt: Explain prompt engineering with 3 analogies\n",
    "prompt = (\n",
    "    \"Explain what prompt engineering is in Large Language Models. \"\n",
    "    \"Provide 3 simple, real-world analogies.\"\n",
    ")\n",
    "\n",
    "response = connector.get_completion(prompt)\n",
    "print(response['content'] if isinstance(response, dict) else response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2189c0-c287-4dc9-a951-af501ec9fe88",
   "metadata": {},
   "source": [
    "## ðŸ› ï¸ Common Prompt Engineering Techniques\n",
    "\n",
    "### 1ï¸âƒ£ Zero-shot prompting\n",
    "Ask the model to perform a task without examples.  \n",
    "âœ… *â€œTranslate â€˜Helloâ€™ to Spanish.â€*\n",
    "\n",
    "### 2ï¸âƒ£ Few-shot prompting\n",
    "Provide a few examples to guide the model.  \n",
    "âœ… *â€œTranslate: Hello â†’ Hola, Goodnight â†’ Buenas noches, Love â†’ [Answer]â€*\n",
    "\n",
    "### 3ï¸âƒ£ Chain-of-thought prompting\n",
    "Encourage step-by-step reasoning.  \n",
    "âœ… *â€œExplain your reasoning step by step before giving the final answer.â€*\n",
    "\n",
    "### 4ï¸âƒ£ Role prompting\n",
    "Assign the model a persona or role.  \n",
    "âœ… *â€œYou are a cybersecurity expert. Explain X.â€*\n",
    "\n",
    "### 5ï¸âƒ£ Delimiter prompting\n",
    "Use delimiters like ``` to specify sections.  \n",
    "âœ… *â€œSummarize the following text: ```{text}```â€*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e129ad29-105c-4333-9417-399be043a133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Sure! Here are five prompt engineering techniques for Large Language Models (LLMs), along with explanations and simple examples:\\n\\n---\\n\\n### 1. **Few-Shot Prompting**\\nFew-shot prompting involves providing a few examples of the desired input-output behavior within the prompt. This helps the model understand the task without explicit instructions.\\n\\n**Explanation:**  \\nBy showing examples of what you\\'re asking for, the model can infer the structure and generate relevant responses based on the given pattern.\\n\\n**Example:**  \\nPrompt:  \\n```\\nTranslate the following sentences to French:\\n1. \"Hello, how are you?\" -> \"Bonjour, comment Ã§a va ?\"\\n2. \"I love programming.\" -> \"J\\'adore la programmation.\"\\n3. \"What is your name?\" -> \\n```\\nOutput:  \\n```\\n\"Quel est votre nom ?\"\\n```\\n\\n---\\n\\n### 2. **Zero-Shot Prompting**\\nZero-shot prompting provides no examples and relies entirely on clear instructions in the prompt. The model is expected to generate output based solely on its training and understanding.\\n\\n**Explanation:**  \\nThis technique assumes that the model can generalize based on the task description without requiring examples.\\n\\n**Example:**  \\nPrompt:  \\n```\\nSummarize the following text in one sentence:  \\n\"The rapid advancements in AI technology are transforming industries and improving lives worldwide.\"  \\n```\\nOutput:  \\n```\\nAI advancements are revolutionizing industries and enhancing lives globally.\\n```\\n\\n---\\n\\n### 3. **Chain-of-Thought Prompting**\\nChain-of-thought prompting encourages the model to generate intermediate reasoning steps before producing the final output. This can improve performance for tasks requiring complex reasoning.\\n\\n**Explanation:**  \\nBy asking the model to \"think aloud,\" you can guide it to arrive at more accurate and logical conclusions.\\n\\n**Example:**  \\nPrompt:  \\n```\\nSolve this math problem step by step:  \\nIf a pencil costs $2 and a notebook costs $5, how much do 3 pencils and 2 notebooks cost?  \\n```\\nOutput:  \\n```\\nStep 1: Calculate the cost of 3 pencils: 3 x $2 = $6.  \\nStep 2: Calculate the cost of 2 notebooks: 2 x $5 = $10.  \\nStep 3: Add the two costs: $6 + $10 = $16.  \\nFinal answer: $16.\\n```\\n\\n---\\n\\n### 4. **Role-Playing**\\nRole-playing involves instructing the model to \"act as\" a specific persona or role. This technique improves contextual relevance and creates tailored responses.\\n\\n**Explanation:**  \\nBy assigning a persona, you guide the model to adopt specific behaviors, tone, or expertise.\\n\\n**Example:**  \\nPrompt:  \\n```\\nYou are a helpful math teacher. Explain the concept of fractions in simple terms.  \\n```\\nOutput:  \\n```\\nA fraction is a way to represent a part of a whole. It has two numbers: the top number, called the numerator, shows how many parts you have, and the bottom number, called the denominator, shows how many equal parts the whole is divided into. For example, 1/4 means one part out of four equal parts.\\n```\\n\\n---\\n\\n### 5. **Instruction Tuning**\\nInstruction tuning provides explicit, detailed instructions for the task at hand. This ensures that the model understands the requirements clearly.\\n\\n**Explanation:**  \\nClear instructions help align the model\\'s output with your expectations, especially for tasks requiring specific formatting or constraints.\\n\\n**Example:**  \\nPrompt:  \\n```\\nWrite a short story about a cat and a dog becoming friends. Make sure the story is no longer than 100 words.  \\n```\\nOutput:  \\n```\\nA curious cat named Mia wandered into a sunny garden and met Max, a playful dog. Max barked excitedly, scaring Mia at first. But when Max shared his favorite ball, Mia purred in delight. They spent the afternoon chasing butterflies and rolling in the grass. From that day on, Mia and Max were inseparable, proving that unlikely friendships can blossom with a little kindness.\\n```\\n\\n---\\n\\nThese techniques allow users to tailor prompts for better performance and relevance, leveraging the strengths of LLMs in various tasks!', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# Prompt: List 5 prompt engineering techniques with examples\n",
    "prompt = (\n",
    "    \"List and explain 5 prompt engineering techniques for Large Language Models \"\n",
    "    \"with a simple example for each.\"\n",
    ")\n",
    "\n",
    "response = connector.get_completion(prompt)\n",
    "print(response['content'] if isinstance(response, dict) else response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7572486-7aa2-4e67-bf5b-0ff98c30b237",
   "metadata": {},
   "source": [
    "## ðŸ“ Prompt Design Best Practices\n",
    "\n",
    "âœ”ï¸ Be clear and specific  \n",
    "âœ”ï¸ Set the desired tone or style (e.g., formal, concise)  \n",
    "âœ”ï¸ Use context to guide responses  \n",
    "âœ”ï¸ Experiment with phrasing and ordering  \n",
    "âœ”ï¸ Test iteratively and refine based on outputs  \n",
    "\n",
    "### ðŸ“ Example\n",
    "- âŒ â€œWrite a summary.â€\n",
    "- âœ… â€œSummarize the following news article in 3 bullet points, focusing on key facts.â€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b65dbca-30c0-4342-9ad8-098c7c8b64cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Here are five best practices for designing effective prompts for Large Language Models (LLMs), along with bad and corrected good examples:\\n\\n---\\n\\n### **1. Be Specific and Clear**\\n#### Explanation:\\nAmbiguity in prompts can lead to irrelevant or incomplete responses from the model. Clearly define what you want to achieve and provide necessary context.\\n\\n- **Bad Example:**\\n  ```\\n  Tell me about history.\\n  ```\\n  *Problem:* Too vague. The model wonâ€™t know which aspect of history to focus on.\\n\\n- **Good Example:**\\n  ```\\n  Provide a summary of major events during the American Civil War, including key figures and outcomes.\\n  ```\\n  *Improvement:* Specifies the topic, scope (American Civil War), and focus (major events, key figures, outcomes).\\n\\n---\\n\\n### **2. Use Constraints and Formatting Guidelines**\\n#### Explanation:\\nProviding format expectations ensures the response is structured and meets your specific needs.\\n\\n- **Bad Example:**\\n  ```\\n  Explain climate change.\\n  ```\\n  *Problem:* No constraints on length or format, leading to an unstructured or overly verbose answer.\\n\\n- **Good Example:**\\n  ```\\n  Explain climate change in 3 concise bullet points suitable for a beginner audience.\\n  ```\\n  *Improvement:* Specifies format (bullet points), length (3 points), and audience (beginner).\\n\\n---\\n\\n### **3. Avoid Overloading the Prompt**\\n#### Explanation:\\nOverly complex or multi-part prompts can confuse the model or result in incomplete answers. Break down requests if needed.\\n\\n- **Bad Example:**\\n  ```\\n  Explain the theory of relativity and quantum mechanics, then compare their applications in technology and discuss future implications.\\n  ```\\n  *Problem:* Overloaded with multiple unrelated tasks, leading to a disorganized response.\\n\\n- **Good Example:**\\n  ```\\n  Explain the theory of relativity and its applications in current technology. Afterward, provide a separate explanation of quantum mechanics and its technological applications.\\n  ```\\n  *Improvement:* Divides the request into manageable sections for clarity.\\n\\n---\\n\\n### **4. Use Examples or Context to Guide the Response**\\n#### Explanation:\\nProviding examples or context helps the model understand your expectations and generate a response aligned with your intent.\\n\\n- **Bad Example:**\\n  ```\\n  Write a poem about love.\\n  ```\\n  *Problem:* No guidance on tone, style, or format, leading to unpredictable output.\\n\\n- **Good Example:**\\n  ```\\n  Write a romantic poem about love in the style of Shakespearean sonnets, emphasizing themes of longing and devotion.\\n  ```\\n  *Improvement:* Provides style (Shakespearean sonnet), tone (romantic), and themes (longing, devotion).\\n\\n---\\n\\n### **5. Test and Refine Iteratively**\\n#### Explanation:\\nInitial prompts may not yield the desired results, so test and refine them based on the modelâ€™s response.\\n\\n- **Bad Example:**\\n  ```\\n  Summarize the book \"1984\" by George Orwell.\\n  ```\\n  *Problem:* Response may lack depth or miss key aspects of the book.\\n\\n- **Good Example (Refined Iterative Prompt):**\\n  ```\\n  Summarize the book \"1984\" by George Orwell in 5-7 sentences, focusing on the major themes of surveillance, totalitarianism, and individuality. Include key plot points while avoiding unnecessary details.\\n  ```\\n  *Improvement:* Adds constraints (length, focus on themes, inclusion of key plot points) based on iterative refinement.\\n\\n---\\n\\nBy following these best practices, you can craft prompts that produce more accurate, relevant, and structured responses from Large Language Models.', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# Prompt: Provide 5 prompt design best practices with a good vs bad example for each\n",
    "prompt = (\n",
    "    \"Provide 5 best practices for designing prompts for Large Language Models. \"\n",
    "    \"For each, include a bad example and a corrected good example.\"\n",
    ")\n",
    "\n",
    "response = connector.get_completion(prompt)\n",
    "print(response['content'] if isinstance(response, dict) else response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af93313-500a-4117-bd37-a250f9aa31ce",
   "metadata": {},
   "source": [
    "## âš¡ LLM Optimization Techniques\n",
    "\n",
    "When using LLMs, performance and cost can be improved by:\n",
    "\n",
    "1. ðŸ”„ **Caching responses** for repeated queries  \n",
    "2. ðŸ“ **Token trimming**: Keep prompts concise to save on tokens  \n",
    "3. ðŸ§® **Batching requests**: Efficient for multiple inputs  \n",
    "4. ðŸ§  **Fine-tuning models** for domain-specific tasks  \n",
    "5. ðŸŒ **Using smaller models** for non-critical tasks  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e44fe04-cae4-4dc6-a2f1-8acf41852423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Here are five optimization techniques for using Large Language Models (LLMs) effectively, along with real-world examples for each:\\n\\n---\\n\\n### 1. **Prompt Engineering**\\n   - **Explanation**: Crafting precise and structured prompts helps guide the model to produce accurate and relevant outputs. Prompts can include specific instructions, examples, or constraints to focus the model\\'s responses. Iterative refinement of prompts can significantly improve results.\\n   - **Real-World Example**: \\n     - **Customer Support Chatbots**: A company uses an LLM to handle customer inquiries. Instead of asking a vague question like, \"How can I help you?\", the prompt is optimized as: \"You are a helpful customer service assistant. Respond politely to the customer\\'s question about our product warranty policy.\"\\n     - This ensures that the bot provides focused, customer-friendly answers.\\n\\n---\\n\\n### 2. **Fine-Tuning**\\n   - **Explanation**: Fine-tuning involves training the LLM on domain-specific data to make it more specialized and accurate for a particular task. This technique reduces irrelevant or generic responses and increases relevance.\\n   - **Real-World Example**: \\n     - **Legal Document Analysis**: A law firm fine-tunes an LLM on legal documents and case law. When tasked with summarizing legal briefs, the fine-tuned model produces outputs with legal-specific jargon and contextual relevance, optimizing its performance for legal professionals.\\n\\n---\\n\\n### 3. **Few-Shot Learning**\\n   - **Explanation**: Few-shot learning leverages examples embedded in the prompt to \"teach\" the model how to respond to specific tasks without additional training. By showing the model a few examples of the desired output format, it adapts to the task within the context of the prompt.\\n   - **Real-World Example**: \\n     - **Content Moderation**: A social media platform uses an LLM to classify posts as appropriate or inappropriate. The prompt includes examples: \"Classify the following posts as \\'appropriate\\' or \\'inappropriate\\': Example 1: [Post Content] -> Appropriate, Example 2: [Post Content] -> Inappropriate.\" This helps the model follow the pattern without requiring extensive retraining.\\n\\n---\\n\\n### 4. **Model Compression**\\n   - **Explanation**: Techniques like quantization, distillation, or pruning reduce the size of an LLM while maintaining its performance. This is particularly useful for deploying models on resource-constrained devices or reducing latency in inference.\\n   - **Real-World Example**: \\n     - **Mobile Applications**: A smartphone app uses a compressed version of an LLM for real-time language translation. By employing quantization techniques, the model runs efficiently on the device without significant loss of translation quality, offering faster performance to users.\\n\\n---\\n\\n### 5. **Hybrid Architectures**\\n   - **Explanation**: Combining LLMs with other systems (e.g., rule-based systems, smaller models, or external APIs) can optimize performance by delegating specific tasks to the most suitable component. This reduces the computational load on the LLM while improving accuracy.\\n   - **Real-World Example**: \\n     - **E-Commerce Search**: An online store uses an LLM for semantic search combined with a rule-based system for filtering results. The LLM interprets vague customer queries (e.g., \"trendy shoes for summer\"), while the rule-based system ensures that results match specific inventory categories like \"summer collection\" and \"shoes.\"\\n\\n---\\n\\nThese techniques demonstrate how optimization can make LLMs more efficient, specialized, and practical for real-world applications across diverse industries.', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# Prompt: List 5 LLM optimization techniques with real-world use cases\n",
    "prompt = (\n",
    "    \"List and explain 5 optimization techniques for using Large Language Models. \"\n",
    "    \"Include a real-world example for each technique.\"\n",
    ")\n",
    "\n",
    "response = connector.get_completion(prompt)\n",
    "print(response['content'] if isinstance(response, dict) else response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07113c82-7d01-402b-84fe-ef3a465dbab8",
   "metadata": {},
   "source": [
    "## âœ… Summary\n",
    "\n",
    "In this section, we:  \n",
    "- Defined prompt engineering and its importance  \n",
    "- Explored common techniques with examples  \n",
    "- Learned best practices for effective prompt design  \n",
    "- Discussed LLM optimization strategies for cost and performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7da79261-8d8f-47c7-b36e-8260f5a2f7b9",
   "metadata": {},
   "source": [
    "# üìñ Section 3: LLM Architectures\n",
    "\n",
    "At the heart of every Large Language Model (LLM) lies an architecture designed for understanding and generating language.  \n",
    "\n",
    "This section explores:  \n",
    "‚úÖ Transformers and the ‚ÄúAttention‚Äù mechanism  \n",
    "‚úÖ Key architectural components (Embedding Layers, Encoder-Decoder, etc.)  \n",
    "‚úÖ How these enable LLMs to process vast amounts of text efficiently  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61465554-b8fa-429f-aa2d-934010df0174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîë LLM Configuration Check:\n",
      "‚úÖ Azure API Details: FOUND\n",
      "‚úÖ Connected to Azure OpenAI (deployment: gpt-4o)\n",
      "üì° LLM Connector initialized and ready.\n"
     ]
    }
   ],
   "source": [
    "# =============================\n",
    "# üìì SECTION 3: LLM ARCHITECTURES\n",
    "# =============================\n",
    "\n",
    "%run ./utils_llm_connector.ipynb\n",
    "\n",
    "# Create a connector instance\n",
    "connector = LLMConnector()\n",
    "\n",
    "# Confirm connection\n",
    "print(\"üì° LLM Connector initialized and ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9f436a-db73-4633-90a0-d0d6802aa50c",
   "metadata": {},
   "source": [
    "## üî• Transformers: The Backbone of LLMs\n",
    "\n",
    "Transformers revolutionized NLP by introducing a mechanism called **‚ÄúAttention‚Äù**, allowing models to focus on different parts of input text dynamically.  \n",
    "\n",
    "They process words **in parallel** instead of sequentially, making them fast and scalable.  \n",
    "\n",
    "### üìù Example Analogies\n",
    "- üéØ **Spotlight at a Concert**: Focuses on different performers depending on the song.  \n",
    "- üë©‚Äçüè´ **Teacher Highlighting Key Text**: Emphasizes important words in a paragraph.  \n",
    "- üß≠ **Navigator**: Pays more attention to landmarks when giving directions.  \n",
    "- üì∞ **Editor Scanning an Article**: Zeroes in on relevant sections for a summary.  \n",
    "- üõ†Ô∏è **Multi-tool**: Adapts to whatever task is needed in real time.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08265c6e-57b0-4c50-a16f-87038e067653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Sure! Transformers and the attention mechanism are at the heart of large language models (LLMs) like GPT. Let me first explain the concepts in simple terms and then provide five real-world analogies to make it relatable.\\n\\n### **What is a Transformer?**\\nA transformer is a type of model architecture designed to process sequences of data, like words in a sentence, efficiently. Its core innovation is the **attention mechanism**, which helps the model focus on relevant parts of the input while making predictions.\\n\\n### **What is the Attention Mechanism?**\\nThe attention mechanism is like a smart \"spotlight.\" Instead of treating all words in a sentence equally, it decides which words or parts of a sequence are more important to pay attention to at any given moment. This helps the model understand context better, especially for long and complex sentences.\\n\\n---\\n\\n### **Five Real-World Analogies:**\\n\\n#### 1. **Reading with a Highlighter**\\nImagine you\\'re reading a book and want to understand a paragraph. Instead of reading every word equally, you use a highlighter to mark certain key phrases that seem most relevant to the topic. The attention mechanism is like this highlighter‚Äîit picks out the most important words or ideas in a sentence to focus on when making predictions.\\n\\n---\\n\\n#### 2. **Finding Friends at a Party**\\nYou\\'re at a crowded party with lots of conversations happening around you. If your best friend calls your name, you instantly focus on their voice, tuning out the rest of the noise. Similarly, the attention mechanism helps the transformer model \"listen\" to the most relevant parts of a sentence while ignoring less important information.\\n\\n---\\n\\n#### 3. **GPS Navigation**\\nWhen planning a route on your GPS, the app doesn\\'t focus equally on all roads‚Äîit prioritizes the ones that are part of your journey. For example, it pays more attention to highways or turns you need to take. In the same way, the attention mechanism prioritizes certain words or sequences based on their relevance to the task (like predicting the next word).\\n\\n---\\n\\n#### 4. **Cooking with a Recipe**\\nImagine you\\'re cooking a complicated dish with a recipe. While following the steps, you focus on the instructions relevant to the current step (e.g., chopping vegetables) rather than reading about baking in the oven, which comes later. The attention mechanism works similarly, focusing only on the critical parts of the input at each stage to make the best decision.\\n\\n---\\n\\n#### 5. **Teacher Helping Students**\\nA teacher in a classroom doesn\\'t give equal attention to all students at all times. If one student is struggling with a question, the teacher focuses on them to provide help, while occasionally glancing at others. Similarly, the attention mechanism dynamically allocates \"focus\" to different parts of the input, depending on their importance for understanding the context and meaning.\\n\\n---\\n\\n### **Summary**\\nTransformers with attention mechanisms are like tools for prioritizing and focusing on what\\'s most important in a sequence of data. They help large language models understand language better by selectively attending to relevant words and context. These analogies illustrate how attention works in everyday situations, making it easier to grasp the concept without technical jargon.', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# Prompt: Explain transformers and attention with analogies\n",
    "prompt = (\n",
    "    \"Explain how transformers and the attention mechanism work in Large Language Models. \"\n",
    "    \"Provide 5 real-world analogies to make it simple for non-technical readers.\"\n",
    ")\n",
    "\n",
    "response = connector.get_completion(prompt)\n",
    "print(response['content'] if isinstance(response, dict) else response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70fead1-753f-459a-8e81-baab1b43ba7f",
   "metadata": {},
   "source": [
    "## üß± Key Components of Transformer Architecture\n",
    "\n",
    "Transformers consist of several core components:\n",
    "\n",
    "1. **Embedding Layer**: Converts words into numerical vectors.  \n",
    "2. **Positional Encoding**: Adds information about word order.  \n",
    "3. **Multi-head Self-Attention**: Allows the model to attend to multiple parts of input simultaneously.  \n",
    "4. **Feed-Forward Neural Networks**: Processes information after attention.  \n",
    "5. **Encoder-Decoder Layers**: (In some models) Encoders understand input, Decoders generate output.  \n",
    "\n",
    "### üìù Example Analogies\n",
    "- üì¶ **Embedding**: Like assigning unique barcodes to every word.  \n",
    "- üéº **Positional Encoding**: Adding musical notes to indicate timing in a melody.  \n",
    "- üëÄ **Multi-head Attention**: Like watching a movie from multiple camera angles at once.  \n",
    "- üç≥ **Feed-Forward Layers**: Processing ingredients in a recipe step by step.  \n",
    "- üèóÔ∏è **Encoder-Decoder**: Architect designing a blueprint, then workers building it.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d75a606-0e24-4a54-8a13-48306dbc6776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='The Transformer architecture is a powerful framework for building large language models (LLMs) like OpenAI\\'s GPT series. It consists of several key components, each playing a unique role in enabling the model to process and generate language. Here‚Äôs a breakdown of the key components, along with relatable real-world analogies to help clarify their functions:\\n\\n---\\n\\n### 1. **Self-Attention Mechanism**\\n   **What it does:**  \\n   The self-attention mechanism allows the model to focus on different parts of the input (e.g., words in a sentence) depending on their relevance to understanding the context. It computes relationships between words at every position to determine how much attention each word deserves.\\n\\n   **Analogy:**  \\n   - **Spotlight at a concert:** Imagine you\\'re at a concert with multiple performers on stage. The spotlight moves dynamically to highlight the performer who‚Äôs most relevant at any given moment, ensuring that the audience focuses on the key action.\\n   - **Reading a recipe:** When reading a recipe, you focus on different parts depending on the step you\\'re performing. For example, you might pay more attention to \"Preheat oven to 350¬∞F\" initially, and later to \"Add sugar\" while baking.\\n\\n---\\n\\n### 2. **Positional Encoding**\\n   **What it does:**  \\n   Since Transformers process input data (e.g., words in a sentence) simultaneously rather than sequentially, positional encoding helps the model understand the order of words in the sentence. It adds positional information to the input embeddings.\\n\\n   **Analogy:**  \\n   - **Train seats with seat numbers:** Passengers on a train have assigned seats with numbers to indicate their position. Even if everyone boards at the same time, seat numbers help ensure everyone knows where they belong.\\n   - **Musical notes on a sheet:** Notes on a musical sheet are marked with their positions in time. Without positional information, the melody would lose its structure.\\n\\n---\\n\\n### 3. **Feedforward Neural Network**\\n   **What it does:**  \\n   After applying self-attention, a feedforward network processes the attention outputs to extract deeper features and make transformations to the data. This is essentially a series of layers that refine the model\\'s understanding.\\n\\n   **Analogy:**  \\n   - **Chef refining a dish:** After gathering all ingredients (attention mechanism), the chef refines the dish through additional steps like cooking, seasoning, and plating to make it ready for serving.\\n   - **Assembly line:** Raw materials (attention outputs) go through multiple stages of refinement on an assembly line to produce a finished product.\\n\\n---\\n\\n### 4. **Layer Normalization**\\n   **What it does:**  \\n   Layer normalization ensures that the activations in the model remain stable and well-scaled, preventing issues like exploding or vanishing gradients. It normalizes values within each layer, promoting efficient learning.\\n\\n   **Analogy:**  \\n   - **Leveling a painting canvas:** Before starting a new painting, you ensure the canvas is smooth and even, so the colors go on properly without blotches.\\n   - **Adjusting audio levels in a podcast:** Before publishing a podcast, you normalize the audio levels to ensure all speakers sound balanced and no one‚Äôs voice is too loud or too quiet.\\n\\n---\\n\\n### 5. **Multi-Head Attention**\\n   **What it does:**  \\n   Multi-head attention allows the model to look at the input from multiple perspectives (or \"heads\") simultaneously. Each head captures different relationships or patterns, enhancing the model\\'s ability to understand complex contexts.\\n\\n   **Analogy:**  \\n   - **Team of detectives:** A group of detectives investigates a case, with each focusing on a different aspect (e.g., motive, timeline, witnesses). Collectively, they form a complete picture of the case.\\n   - **Cameras in a sports game:** Multiple cameras capture a sports game from different angles. Each camera provides unique insights, and together they create a full view of the game.\\n\\n---\\n\\n### Bonus: **Transformer Layers (Stacked Architecture)**\\n   **What it does:**  \\n   The Transformer consists of multiple layers, each building on the previous one to extract increasingly complex patterns. This stacked architecture enables the model to learn hierarchical representations.\\n\\n   **Analogy:**  \\n   - **Building a skyscraper:** Each layer of the skyscraper adds structural integrity and functionality to the building, ultimately resulting in a towering, complex structure.\\n   - **Education system:** A student progresses through grades (elementary, middle, high school, etc.), with each level building on knowledge from the previous one to develop advanced skills.\\n\\n---\\n\\nThese components together form the backbone of Transformer-based Large Language Models, enabling them to process and generate natural language with remarkable accuracy and flexibility.', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# Prompt: List and explain key components of transformer architecture with analogies\n",
    "prompt = (\n",
    "    \"List and explain the key components of transformer architecture used in Large Language Models. \"\n",
    "    \"Provide 5 real-world analogies to make each concept relatable.\"\n",
    ")\n",
    "\n",
    "response = connector.get_completion(prompt)\n",
    "print(response['content'] if isinstance(response, dict) else response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735c51e0-5438-40f3-9e15-e1129773e1a8",
   "metadata": {},
   "source": [
    "## üöÄ Why Transformers Outperform Older Architectures\n",
    "\n",
    "Compared to RNNs and LSTMs:  \n",
    "- ‚úÖ Process text **in parallel** instead of sequentially  \n",
    "- ‚úÖ Handle **long-range dependencies** better  \n",
    "- ‚úÖ Scale efficiently to billions of parameters  \n",
    "\n",
    "### üìù Example Comparisons\n",
    "| Feature                  | RNN/LSTM                | Transformer             |\n",
    "|--------------------------|--------------------------|-------------------------|\n",
    "| Processing               | Sequential               | Parallel                |\n",
    "| Long Text Handling       | Limited (vanishing gradients) | Excellent with attention |\n",
    "| Training Time            | Slower                  | Faster                  |\n",
    "| Scalability              | Hard to scale           | Scales to massive models|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4970e8c-312d-4b91-9e9f-acceca0579cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Below is a detailed comparison between Transformers, RNNs, and LSTMs presented in a tabular format, with real-world analogies to make each concept more relatable.\\n\\n| **Aspect**                     | **Transformers**                                                                                     | **RNNs**                                                                                                           | **LSTMs**                                                                                                          | **Real-World Analogy**                                                                                                   |\\n|---------------------------------|-----------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------|\\n| **Architecture**               | Attention-based model with self-attention mechanisms and parallel processing.                       | Sequential model that processes input step-by-step in order.                                                       | Enhanced RNNs with memory cells and gates for better retention of long-term dependencies.                            | Transformers: A team of experts working simultaneously on different parts of a problem. RNNs: A relay race team passing a baton. LSTMs: A relay race team with advanced memory aids to retain strategy. |\\n| **Memory**                     | Captures long-range dependencies effectively using attention mechanisms.                            | Struggles with long-range dependencies due to vanishing gradients.                                                 | Handles long-range dependencies better than RNNs via gating mechanisms.                                             | Transformers: A library categorizing books based on keywords. RNNs: A chain of people passing a message. LSTMs: A chain with smarter people remembering key points. |\\n| **Parallelism**                | Highly parallelizable, processes entire sequence at once.                                           | Sequential processing, cannot be parallelized effectively.                                                          | Sequential processing, but slightly more efficient than plain RNNs due to gating.                                    | Transformers: A group solving puzzles simultaneously. RNNs: A single file queue. LSTMs: A queue with memory-enhancing tools. |\\n| **Speed**                      | Faster training and inference due to parallelization.                                               | Slower due to sequential processing.                                                                                | Faster than RNNs but slower than Transformers.                                                                       | Transformers: Solving puzzles in parallel. RNNs: Solving puzzles one at a time. LSTMs: Solving puzzles sequentially but with shortcuts. |\\n| **Complexity**                 | More complex with attention mechanisms and additional layers like positional encoding.              | Relatively simple architecture.                                                                                    | More complex than RNNs due to gates and memory cells.                                                                | Transformers: A complex machine with multiple specialized parts. RNNs: A simple conveyor belt. LSTMs: A conveyor belt with smart filters and memory compartments. |\\n| **Input Dependency**           | Processes entire input at once, making it independent of sequence order during training.            | Requires sequential input processing, order-dependent.                                                             | Similar to RNNs, processes input sequentially but retains better context with memory gates.                          | Transformers: Reading a whole book to understand the story. RNNs: Reading one sentence at a time. LSTMs: Reading with notes for context. |\\n| **Handling Long Sequences**    | Excels at processing long sequences due to self-attention mechanism.                                | Poor at handling long sequences due to vanishing gradients.                                                        | Performs better with long sequences but still struggles with very long dependencies.                                 | Transformers: A drone scanning an entire forest. RNNs: Walking through the forest step-by-step. LSTMs: Walking through the forest with a map and memory aids. |\\n| **Applications**               | NLP tasks (translation, summarization), computer vision, recommender systems, etc.                  | Time series prediction, speech recognition, and simple NLP tasks.                                                  | Sequence-to-sequence tasks, sentiment analysis, and predictive modeling.                                             | Transformers: A versatile AI assistant. RNNs: An old-school stenographer. LSTMs: A stenographer with enhanced memory tools. |\\n| **Training Data Efficiency**   | Requires large datasets for effective training.                                                     | Can work on smaller datasets but may not generalize well.                                                          | More efficient than Transformers but requires careful tuning for small datasets.                                     | Transformers: A student needing extensive preparation. RNNs: A student okay with less practice. LSTMs: A student with memory aids for better preparation. |\\n| **Interpretability**           | Harder to interpret due to attention mechanisms being distributed across multiple heads.             | Easier to interpret (step-by-step processing).                                                                      | Intermediate interpretability due to gates offering some insight into what is retained or forgotten.                 | Transformers: A complex decision-making process with many contributors. RNNs: A clear step-by-step process. LSTMs: A process with selective memory. |\\n| **Scalability**                | Scales well to large datasets and tasks due to parallel processing.                                 | Limited scalability due to sequential nature.                                                                      | Slightly better scalability than RNNs but not as good as Transformers.                                               | Transformers: A factory with multiple assembly lines. RNNs: A single assembly line. LSTMs: A single assembly line with efficiency improvements. |\\n| **Use of Context**             | Captures global context using attention mechanisms.                                                 | Captures local context but struggles with global context.                                                          | Captures both local and global context reasonably well.                                                              | Transformers: Seeing the whole picture. RNNs: Focusing on one piece of the puzzle at a time. LSTMs: Focusing on pieces with hints of the bigger picture. |\\n\\nThis comparison highlights the strengths and weaknesses of each architecture, with real-world analogies to make technical concepts easier to understand.', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# Prompt: Compare transformers with RNNs and LSTMs in a table with examples\n",
    "prompt = (\n",
    "    \"Compare transformers with RNNs and LSTMs in a detailed tabular format. \"\n",
    "    \"Include real-world analogies for each row.\"\n",
    ")\n",
    "\n",
    "response = connector.get_completion(prompt)\n",
    "print(response['content'] if isinstance(response, dict) else response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6096b0-06e4-423a-a403-dd66993e024c",
   "metadata": {},
   "source": [
    "## ‚úÖ Summary\n",
    "\n",
    "In this section, we:  \n",
    "- Learned about transformers and the attention mechanism.  \n",
    "- Explored the core components of LLM architectures.  \n",
    "- Saw why transformers outperform older models like RNNs and LSTMs.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

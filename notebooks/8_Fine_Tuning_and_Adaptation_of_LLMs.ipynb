{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f780f52b-d481-410a-b1b2-c689fc2133f5",
   "metadata": {},
   "source": [
    "# üìñ Section 8: Fine-Tuning and Adaptation of LLMs\n",
    "\n",
    "Fine-tuning allows you to adapt pre-trained LLMs to specific domains, industries, or use cases.  \n",
    "\n",
    "This section explores:  \n",
    "‚úÖ What fine-tuning is and why it‚Äôs useful  \n",
    "‚úÖ Different approaches to adaptation  \n",
    "‚úÖ Real-world examples and demos"
   ]
  },
  {
   "cell_type": "code",
   "id": "d957b02f-a4a0-46e5-8d42-238414d8e641",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T03:01:26.041834Z",
     "start_time": "2025-12-16T03:01:25.398265Z"
    }
   },
   "source": [
    "# =============================\n",
    "# üìì SECTION 8: FINE-TUNING AND ADAPTATION OF LLMs\n",
    "# =============================\n",
    "\n",
    "%run ./utils_llm_connector.ipynb\n",
    "\n",
    "# Create a connector instance\n",
    "connector = LLMConnector()\n",
    "\n",
    "# Confirm connection\n",
    "print(\"üì° LLM Connector initialized and ready.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîë LLM Configuration Check:\n",
      "‚úÖ OpenAI API Details: FOUND\n",
      "‚úÖ Connected to OpenAI (model: gpt-4o)\n",
      "üì° LLM Connector initialized and ready.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "920c1bef-4371-4a6c-ac0d-4e9887764208",
   "metadata": {},
   "source": [
    "## üîÑ What is Fine-Tuning?\n",
    "\n",
    "**Fine-tuning** is the process of taking a pre-trained LLM and continuing its training on a smaller, task-specific or domain-specific dataset. This adapts the model to perform better on your specific use case while retaining its general knowledge.\n",
    "\n",
    "### How Fine-Tuning Works\n",
    "\n",
    "1. **Start with Pre-trained Model**: Use a model trained on general data (e.g., GPT-4)\n",
    "2. **Prepare Domain Data**: Collect or create examples for your specific task\n",
    "3. **Continue Training**: Train the model on your data with a lower learning rate\n",
    "4. **Evaluate**: Test the fine-tuned model on your task\n",
    "5. **Deploy**: Use the specialized model for your application\n",
    "\n",
    "### Why Fine-Tune?\n",
    "\n",
    "- **Better Performance**: Outperforms prompt engineering for specialized tasks\n",
    "- **Domain Expertise**: Understands domain-specific terminology and context\n",
    "- **Consistency**: More consistent outputs for your specific use case\n",
    "- **Efficiency**: May require fewer tokens per request\n",
    "- **Customization**: Tailored to your exact needs\n",
    "\n",
    "### üìù Real-World Examples\n",
    "\n",
    "Starting with GPT-4 and fine-tuning it on:\n",
    "- üìö **Legal texts** ‚Üí Legal assistant that understands case law\n",
    "- ü©∫ **Medical literature** ‚Üí Healthcare advisor with medical knowledge\n",
    "- üìà **Financial reports** ‚Üí Finance chatbot with market expertise\n",
    "- üíª **Code repositories** ‚Üí Code assistant for specific frameworks\n",
    "- üéì **Educational content** ‚Üí Tutoring system for specific subjects"
   ]
  },
  {
   "cell_type": "code",
   "id": "c0dcd3d1-90b9-465b-b568-5aee3ba61dbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T03:01:37.519908Z",
     "start_time": "2025-12-16T03:01:26.042350Z"
    }
   },
   "source": [
    "# Prompt: Explain what fine-tuning is with 5 real-world analogies\n",
    "prompt = (\n",
    "    \"Explain what fine-tuning means in Large Language Models. \"\n",
    "    \"Provide 5 real-world analogies for better understanding.\"\n",
    ")\n",
    "\n",
    "response = connector.get_completion(prompt)\n",
    "print(response['content'] if isinstance(response, dict) else response)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"Fine-tuning in the context of Large Language Models (LLMs) refers to the process of taking a pre-trained model and making small adjustments to its parameters using a smaller, task-specific dataset. This allows the model to adapt to specific tasks or domains while leveraging the vast knowledge it has already acquired during its initial pre-training phase. Fine-tuning is a crucial step for customizing LLMs to perform well on particular tasks, such as sentiment analysis, customer support, or domain-specific question answering.\\n\\nHere are five real-world analogies to help you understand fine-tuning better:\\n\\n1. **Tailoring a Suit**: Imagine buying a high-quality off-the-rack suit. It's designed to fit a wide range of body types but might not fit you perfectly. A tailor makes small adjustments to ensure it fits you just right. Similarly, a pre-trained LLM is like the off-the-rack suit, and fine-tuning is the tailoring process that customizes the model to fit specific needs or tasks.\\n\\n2. **Learning a Specialized Skill**: Consider a chef who has completed culinary school and mastered general cooking techniques. When the chef starts working at a sushi restaurant, they undergo additional training to specialize in sushi preparation. The initial culinary education is akin to the pre-training, while the sushi-specific training represents fine-tuning.\\n\\n3. **Software Updates for Specific Use Cases**: Think of a smartphone that comes with a general operating system. When you install a specific app, it might require a configuration update to run optimally on your device. The OS is the pre-trained model, and the app update is the fine-tuning process that optimizes the device for a particular application.\\n\\n4. **Language Acquisition**: Imagine someone who is fluent in English but moves to a region where a specific dialect or jargon is prevalent. They might need to learn additional words or phrases to communicate effectively in that context. The initial fluency represents the pre-training, while learning the dialect is the fine-tuning.\\n\\n5. **Driver‚Äôs License with Endorsements**: A person may obtain a general driver's license, which allows them to drive a standard car. If they want to drive a motorcycle or commercial vehicle, they need additional training and endorsements. The general driver's license is like the pre-trained model, and the endorsements are the fine-tuning that prepares them for specific types of vehicles.\\n\\nThese analogies illustrate how fine-tuning leverages the broad, foundational knowledge of a pre-trained model and tailors it to excel in specific tasks or domains.\", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "15ab9d43-017c-4465-b5cb-e4ed761694e8",
   "metadata": {},
   "source": [
    "## üîÄ Fine-Tuning vs Prompt Engineering vs Adapters\n",
    "\n",
    "Understanding when to use each approach is crucial for effective LLM adaptation.\n",
    "\n",
    "### Comparison Table\n",
    "\n",
    "| Aspect             | Prompt Engineering | Fine-Tuning | Adapters (LoRA/PEFT) |\n",
    "|-------------------|---------------------|-------------|---------------------|\n",
    "| **Model Changes** | None (prompt only)  | Updates all weights | Adds small modules |\n",
    "| **Cost**          | Low (just tokens)   | Medium-High | Low-Medium |\n",
    "| **Time**          | Minutes (iterative) | Hours-Days  | Hours |\n",
    "| **Data Needed**   | None (just examples)| Hundreds-thousands | Hundreds-thousands |\n",
    "| **Flexibility**   | High (easy to change)| Low (retrain needed) | Medium |\n",
    "| **Performance**   | Good for simple tasks | Best for complex | Good for specialized |\n",
    "| **When to Use**   | Quick prototyping | Production systems | Multiple tasks |\n",
    "\n",
    "### Detailed Comparison\n",
    "\n",
    "#### üñãÔ∏è Prompt Engineering\n",
    "\n",
    "**What**: Crafting better inputs without changing the model.\n",
    "\n",
    "**Pros**:\n",
    "- Fast and easy to iterate\n",
    "- No training required\n",
    "- Works with any model\n",
    "- Flexible - change prompts anytime\n",
    "\n",
    "**Cons**:\n",
    "- Limited by base model capabilities\n",
    "- May need long prompts (more tokens)\n",
    "- Less consistent for complex tasks\n",
    "\n",
    "**Analogy**: Like giving clearer instructions to a talented artist.\n",
    "\n",
    "**Best For**: Quick prototyping, simple tasks, when you can't retrain.\n",
    "\n",
    "---\n",
    "\n",
    "#### üéì Fine-Tuning\n",
    "\n",
    "**What**: Training the model further on your specific data.\n",
    "\n",
    "**Pros**:\n",
    "- Best performance for specialized tasks\n",
    "- Understands domain-specific context\n",
    "- More consistent outputs\n",
    "- Can reduce prompt length\n",
    "\n",
    "**Cons**:\n",
    "- Requires training data\n",
    "- Takes time and compute\n",
    "- Less flexible (need to retrain for changes)\n",
    "- More expensive\n",
    "\n",
    "**Analogy**: Like sending the artist to law school.\n",
    "\n",
    "**Best For**: Production systems, domain-specific applications, when you have data.\n",
    "\n",
    "---\n",
    "\n",
    "#### üîå Adapters (LoRA, PEFT)\n",
    "\n",
    "**What**: Adding lightweight modules to the model for specific tasks.\n",
    "\n",
    "**Pros**:\n",
    "- Efficient (only trains small modules)\n",
    "- Can have multiple adapters\n",
    "- Faster than full fine-tuning\n",
    "- Less storage needed\n",
    "\n",
    "**Cons**:\n",
    "- Still requires training\n",
    "- May not be as good as full fine-tuning\n",
    "- More complex setup\n",
    "\n",
    "**Analogy**: Like equipping the artist with specialized legal reference books.\n",
    "\n",
    "**Best For**: Multiple specialized tasks, resource-constrained environments.\n",
    "\n",
    "### Decision Framework\n",
    "\n",
    "**Use Prompt Engineering when:**\n",
    "- You need quick results\n",
    "- Task is relatively simple\n",
    "- You don't have training data\n",
    "- You want flexibility\n",
    "\n",
    "**Use Fine-Tuning when:**\n",
    "- You need best performance\n",
    "- Task is complex or domain-specific\n",
    "- You have quality training data\n",
    "- Performance is critical\n",
    "\n",
    "**Use Adapters when:**\n",
    "- You need multiple specialized models\n",
    "- Resources are limited\n",
    "- You want efficiency\n",
    "- Quick adaptation is needed"
   ]
  },
  {
   "cell_type": "code",
   "id": "caab4691-027f-47e1-bd37-7e200a57a72a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T03:01:48.160108Z",
     "start_time": "2025-12-16T03:01:37.559807Z"
    }
   },
   "source": [
    "# Prompt: Explain the difference between prompt engineering, fine-tuning, and adapters with analogies\n",
    "prompt = (\n",
    "    \"Explain the difference between prompt engineering, fine-tuning, and adapters (like LoRA) in Large Language Models. \"\n",
    "    \"Use 3 real-world analogies to illustrate the differences.\"\n",
    ")\n",
    "\n",
    "response = connector.get_completion(prompt)\n",
    "print(response['content'] if isinstance(response, dict) else response)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"Certainly! Let's explore the differences between prompt engineering, fine-tuning, and adapters (like LoRA) in the context of Large Language Models (LLMs) using three real-world analogies.\\n\\n### 1. Prompt Engineering\\n\\n**Concept:**  \\nPrompt engineering involves crafting specific inputs or questions to elicit desired outputs from a pre-trained model without altering the model's internal parameters.\\n\\n**Analogy:**  \\n*Think of prompt engineering like a skilled bartender crafting a specific cocktail using a fixed set of ingredients.*  \\n- **Bartender's Skill:** The bartender (user) doesn't change the ingredients or the bar setup (model); instead, they expertly mix and match what's available to create a desired drink (output).\\n- **Example:** If you want a sweet cocktail, you might instruct the bartender to mix more fruit juices and less alcohol, similar to how you would adjust prompts to guide the model towards a desired response.\\n\\n### 2. Fine-Tuning\\n\\n**Concept:**  \\nFine-tuning involves adjusting the internal parameters of a pre-trained model on a new, often smaller dataset to better align with specific tasks or domains.\\n\\n**Analogy:**  \\n*Imagine teaching a musician to play a new song by altering their technique slightly.*  \\n- **Musician's Training:** The musician (model) already has a broad set of skills, but for a specific song (task), you might need to tweak their finger placement or tempo.\\n- **Example:** You might give the musician sheet music and practice sessions to refine their performance, just as you provide additional data for the model to adjust its internal parameters for the task at hand.\\n\\n### 3. Adapters (e.g., LoRA)\\n\\n**Concept:**  \\nAdapters, such as LoRA (Low-Rank Adaptation), involve adding small, trainable modules to a pre-trained model to adapt it for new tasks without altering the original model weights.\\n\\n**Analogy:**  \\n*Consider adding a detachable camera lens to your smartphone to enhance its photography capabilities.*  \\n- **Lens Attachment:** Your smartphone (model) remains unchanged, but the lens (adapter) provides additional functionality for specific photography needs.\\n- **Example:** If you need to take wide-angle photos, you attach a wide-angle lens, similar to adding an adapter module to handle specific tasks without retraining the entire model.\\n\\n### Summary\\n\\n- **Prompt Engineering:** Like crafting a cocktail with existing ingredients‚Äîno change to the core model, just optimized usage.\\n- **Fine-Tuning:** Like teaching a musician a new song‚Äîaltering technique for a specific performance, requiring retraining.\\n- **Adapters (LoRA):** Like attaching a lens to a smartphone‚Äîadding components to enhance capability without altering the base device.\\n\\nThese analogies illustrate how each approach leverages the capabilities of LLMs differently to achieve specific goals.\", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "7a419df4-14c2-4213-85fe-dd1c859e8291",
   "metadata": {},
   "source": [
    "## üìå When to Use Fine-Tuning\n",
    "\n",
    "Fine-tuning is the right choice when you need specialized performance that prompt engineering can't achieve.\n",
    "\n",
    "### Key Scenarios\n",
    "\n",
    "1. **üöÄ Domain-Specific Expertise**\n",
    "   - Need deep understanding of specialized terminology\n",
    "   - **Example**: Medical diagnosis, legal case analysis, financial modeling\n",
    "   - **Why**: Base models lack domain-specific knowledge\n",
    "\n",
    "2. **üåê Cultural or Language Nuances**\n",
    "   - Need to understand cultural context or non-English languages\n",
    "   - **Example**: Localized customer support, cultural content generation\n",
    "   - **Why**: Base models may not capture cultural subtleties\n",
    "\n",
    "3. **üè¢ Enterprise Applications**\n",
    "   - Need to use proprietary data or internal knowledge\n",
    "   - **Example**: Company-specific chatbots, internal documentation\n",
    "   - **Why**: Data privacy and specificity requirements\n",
    "\n",
    "4. **üìä Consistent Output Format**\n",
    "   - Need specific output structure or style\n",
    "   - **Example**: Structured reports, formatted responses\n",
    "   - **Why**: Prompt engineering may be inconsistent\n",
    "\n",
    "5. **‚ö° Performance Requirements**\n",
    "   - Need better accuracy or lower latency\n",
    "   - **Example**: Real-time applications, critical systems\n",
    "   - **Why**: Fine-tuned models often perform better\n",
    "\n",
    "### üìù Real-World Examples\n",
    "\n",
    "1. **Banking**: Fine-tune on internal policy documents for employee chatbot\n",
    "2. **Healthcare**: Fine-tune on medical literature for diagnostic assistance\n",
    "3. **Legal**: Fine-tune on case law for legal research\n",
    "4. **E-commerce**: Fine-tune on product catalogs for customer support\n",
    "5. **Education**: Fine-tune on curriculum for tutoring systems\n",
    "\n",
    "### When NOT to Fine-Tune\n",
    "\n",
    "- Simple tasks that prompt engineering handles well\n",
    "- You don't have quality training data\n",
    "- Requirements change frequently\n",
    "- Limited compute resources\n",
    "- Quick prototyping phase"
   ]
  },
  {
   "cell_type": "code",
   "id": "6cebbf32-17ce-4c79-b481-2d02a9326fd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T03:01:55.724796Z",
     "start_time": "2025-12-16T03:01:48.170238Z"
    }
   },
   "source": [
    "# Prompt: List 3 scenarios where fine-tuning LLMs is essential with examples\n",
    "prompt = (\n",
    "    \"List 3 real-world scenarios where fine-tuning Large Language Models is essential. \"\n",
    "    \"Provide practical examples for each scenario.\"\n",
    ")\n",
    "\n",
    "response = connector.get_completion(prompt)\n",
    "print(response['content'] if isinstance(response, dict) else response)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"Fine-tuning Large Language Models (LLMs) is essential in several real-world scenarios to enhance their performance, specialize them for specific tasks, and ensure they meet particular requirements. Here are three scenarios along with practical examples:\\n\\n1. **Industry-Specific Applications:**\\n   - **Example:** In the healthcare industry, LLMs can be fine-tuned to understand medical terminology and the nuances of patient data. A hospital could fine-tune a language model on electronic health records (EHRs) and medical literature to improve the accuracy of medical record summarization, assist in diagnosing conditions by analyzing patient symptoms and history, or generate personalized healthcare recommendations. This specialized tuning ensures the model's outputs are relevant and trustworthy in a medical context.\\n\\n2. **Customer Support Automation:**\\n   - **Example:** A company can fine-tune an LLM to handle customer inquiries effectively by training it on past customer interactions, FAQs, and support documentation specific to their products or services. For instance, a telecommunications company might fine-tune a model to assist with troubleshooting common issues with mobile devices or network connectivity. This enables the LLM to provide accurate and context-aware responses, improving customer satisfaction and reducing the workload on human agents.\\n\\n3. **Legal Document Processing:**\\n   - **Example:** Legal firms or departments can fine-tune LLMs to analyze and interpret legal documents, such as contracts or case law, by training them on legal texts and precedents. For example, a law firm specializing in intellectual property might fine-tune a model to identify and highlight key clauses in patent documents or to assist in drafting legal agreements by suggesting relevant legal terminology and clauses. This fine-tuning helps in ensuring that the model understands the complexity and precision required in legal language, thus aiding lawyers and paralegals in their work. \\n\\nIn each of these scenarios, fine-tuning allows organizations to leverage the general capabilities of LLMs while tailoring them to meet their specific needs, resulting in more effective and efficient outcomes.\", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "52fc9f01-3cac-40d1-9418-cf791201c5bc",
   "metadata": {},
   "source": [
    "## üìù Example: Domain-Specific Adaptation\n",
    "\n",
    "Ask the model to behave like a legal assistant without fine-tuning. Observe how well it adapts.\n",
    "\n",
    "**Prompt:**  \n",
    "_\"You are a legal assistant. Draft a non-disclosure agreement (NDA) clause regarding data privacy.\"_"
   ]
  },
  {
   "cell_type": "code",
   "id": "318aa9a8-88d6-401d-8c3d-a0399877d750",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T03:02:04.600702Z",
     "start_time": "2025-12-16T03:01:55.735125Z"
    }
   },
   "source": [
    "# Prompt to simulate domain-specific adaptation\n",
    "prompt_domain = (\n",
    "    \"You are a legal assistant. Draft a non-disclosure agreement (NDA) clause regarding data privacy.\"\n",
    ")\n",
    "\n",
    "response_domain = connector.get_completion(prompt_domain)\n",
    "print(\"üìã Domain Adaptation Test Output:\\n\", response_domain['content'] if isinstance(response_domain, dict) else response_domain)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Domain Adaptation Test Output:\n",
      " ChatCompletionMessage(content='Certainly! Below is a sample clause for a non-disclosure agreement (NDA) that addresses data privacy:\\n\\n---\\n\\n**Data Privacy Clause**\\n\\n1. **Confidentiality Obligations**: The Receiving Party acknowledges that during the course of their engagement with the Disclosing Party, they may have access to, or receive, confidential and proprietary information, including but not limited to personal data, business strategies, client information, trade secrets, technical data, and other sensitive information (collectively referred to as \"Confidential Information\"). The Receiving Party agrees to maintain the confidentiality and integrity of such Confidential Information and to use it solely for the purpose of fulfilling their obligations under this Agreement.\\n\\n2. **Data Protection Compliance**: The Receiving Party agrees to comply with all applicable data protection and privacy laws and regulations, including but not limited to the General Data Protection Regulation (GDPR), the California Consumer Privacy Act (CCPA), and any other relevant legislation. The Receiving Party shall implement and maintain appropriate technical and organizational measures to protect the Confidential Information against unauthorized or unlawful processing, accidental loss, destruction, or damage.\\n\\n3. **Use and Disclosure**: The Receiving Party shall not use or disclose any Confidential Information for any purpose other than as expressly authorized by the Disclosing Party in writing. Disclosure of Confidential Information shall be limited to those employees, agents, or contractors who need to know such information for the purpose of carrying out their obligations under this Agreement, provided that they are bound by confidentiality obligations no less stringent than those contained herein.\\n\\n4. **Data Breach Notification**: In the event of any actual or suspected data breach involving Confidential Information, the Receiving Party shall promptly, and in any event within [insert number] hours of becoming aware of the breach, notify the Disclosing Party. The notification shall include sufficient details of the breach to enable the Disclosing Party to assess the nature and impact of the breach and to comply with any legal or regulatory obligations.\\n\\n5. **Return or Destruction of Information**: Upon termination or expiration of this Agreement, or upon the Disclosing Party\\'s written request, the Receiving Party shall promptly return, delete, or destroy all Confidential Information in their possession or control, including all copies, reproductions, and any other materials containing or derived from the Confidential Information, and shall certify in writing to the Disclosing Party that such actions have been completed.\\n\\n6. **Survival**: The obligations of confidentiality and data protection set forth in this Clause shall survive the termination or expiration of this Agreement and shall continue for a period of [insert number] years thereafter, or for as long as the Confidential Information remains confidential, whichever is longer.\\n\\n---\\n\\nPlease remember to adjust the placeholders (e.g., [insert number]) with specific details that fit the context of your agreement. Additionally, it\\'s essential to consult with a legal professional to ensure that the clause complies with applicable laws and suits the specific needs of your agreement.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "f6aa05ef-b79b-44c5-bece-d13f4ca2b14b",
   "metadata": {},
   "source": [
    "## ‚úÖ Summary\n",
    "\n",
    "In this section, we:  \n",
    "- Learned what fine-tuning is and when it‚Äôs needed.  \n",
    "- Compared fine-tuning, prompt engineering, and adapters.  \n",
    "- Explored examples of domain-specific adaptation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

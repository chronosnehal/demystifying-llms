{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f780f52b-d481-410a-b1b2-c689fc2133f5",
   "metadata": {},
   "source": [
    "# üìñ Section 8: Fine-Tuning and Adaptation of LLMs\n",
    "\n",
    "Fine-tuning allows you to adapt pre-trained LLMs to specific domains, industries, or use cases.  \n",
    "\n",
    "This section explores:  \n",
    "‚úÖ What fine-tuning is and why it‚Äôs useful  \n",
    "‚úÖ Different approaches to adaptation  \n",
    "‚úÖ Real-world examples and demos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d957b02f-a4a0-46e5-8d42-238414d8e641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîë LLM Configuration Check:\n",
      "‚úÖ Azure API Details: FOUND\n",
      "‚úÖ Connected to Azure OpenAI (deployment: gpt-4o)\n",
      "üì° LLM Connector initialized and ready.\n"
     ]
    }
   ],
   "source": [
    "# =============================\n",
    "# üìì SECTION 8: FINE-TUNING AND ADAPTATION OF LLMs\n",
    "# =============================\n",
    "\n",
    "%run ./utils_llm_connector.ipynb\n",
    "\n",
    "# Create a connector instance\n",
    "connector = LLMConnector()\n",
    "\n",
    "# Confirm connection\n",
    "print(\"üì° LLM Connector initialized and ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920c1bef-4371-4a6c-ac0d-4e9887764208",
   "metadata": {},
   "source": [
    "## üîÑ What is Fine-Tuning?\n",
    "\n",
    "Fine-tuning involves taking a pre-trained LLM (like GPT) and continuing training on a smaller, domain-specific dataset.  \n",
    "\n",
    "### üìù Example\n",
    "Starting with GPT-4 and fine-tuning it on:  \n",
    "- üìö Legal texts for a **legal assistant**  \n",
    "- ü©∫ Medical literature for a **healthcare advisor**  \n",
    "- üìà Financial reports for a **finance chatbot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0dcd3d1-90b9-465b-b568-5aee3ba61dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Fine-tuning in the context of large language models (LLMs) refers to the process of taking a pre-trained model (which has been trained on a massive amount of general data) and further training it on a specific, smaller dataset tailored to a particular use case or domain. This process adjusts the model\\'s parameters slightly to make it perform better for the desired task while retaining its general knowledge.\\n\\nHere are five real-world analogies to help understand fine-tuning:\\n\\n---\\n\\n### 1. **Customizing a Suit**\\nImagine you buy a high-quality, off-the-rack suit that fits most people reasonably well. However, to make it fit you perfectly, a tailor makes small adjustments, such as shortening the sleeves or tapering the pants. Fine-tuning a large language model is like tailoring the suit‚Äîit starts with a general-purpose foundation and tweaks it to meet specific needs.\\n\\n---\\n\\n### 2. **Teaching a Chef a New Recipe**\\nA professional chef knows many cooking techniques and recipes from around the world. If you want the chef to make your grandmother‚Äôs unique lasagna recipe, you show them the specific ingredients and steps. The chef applies their general cooking knowledge but fine-tunes their approach to match your recipe. Similarly, an LLM is trained broadly but can be refined for specific tasks.\\n\\n---\\n\\n### 3. **Adding Personalized Features to a Smartphone**\\nWhen you buy a new smartphone, it comes with default settings and pre-installed apps that work well for most users. To make it more useful to you, you personalize the settings, install apps for your specific needs, and configure shortcuts. Fine-tuning a model is like this personalization‚Äîit adapts a general-purpose tool to your unique requirements.\\n\\n---\\n\\n### 4. **Training a Dog for Specialized Tasks**\\nA dog that has been generally trained to follow basic commands (like \"sit\" or \"stay\") can be further trained for a specific purpose, such as search-and-rescue or guiding visually impaired people. The foundational training helps the dog understand basic behavior, while the specialized training fine-tunes its skills for a specific task.\\n\\n---\\n\\n### 5. **Learning a Dialect of a Language**\\nA person fluent in standard Spanish might travel to Argentina and learn specific words, phrases, and cultural nuances unique to Argentine Spanish. They don‚Äôt need to relearn the entire language but rather fine-tune their existing knowledge for the local dialect. Similarly, an LLM is refined to better understand a particular domain or application.\\n\\n---\\n\\nIn summary, fine-tuning involves taking a broadly capable system and customizing it for a specific task, domain, or audience while leveraging the model‚Äôs foundational, general-purpose capabilities.', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# Prompt: Explain what fine-tuning is with 5 real-world analogies\n",
    "prompt = (\n",
    "    \"Explain what fine-tuning means in Large Language Models. \"\n",
    "    \"Provide 5 real-world analogies for better understanding.\"\n",
    ")\n",
    "\n",
    "response = connector.get_completion(prompt)\n",
    "print(response['content'] if isinstance(response, dict) else response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ab9d43-017c-4465-b5cb-e4ed761694e8",
   "metadata": {},
   "source": [
    "## üîÄ Fine-Tuning vs Prompt Engineering vs Adapters\n",
    "\n",
    "| Approach             | Description                                      | Example                     |\n",
    "|----------------------|--------------------------------------------------|-----------------------------|\n",
    "| Prompt Engineering   | Crafting smarter inputs for the base model       | Adding context in prompts   |\n",
    "| Fine-Tuning          | Training the model further on new datasets       | GPT fine-tuned for legal use|\n",
    "| Adapters (LoRA, PEFT)| Adding lightweight modules for specific tasks    | Plug-in domain expertise    |\n",
    "\n",
    "### üìù Real-World Analogies\n",
    "1. üñãÔ∏è **Prompt Engineering**: Like giving clearer instructions to a talented artist.  \n",
    "2. üéì **Fine-Tuning**: Like sending the artist to law school.  \n",
    "3. üîå **Adapters**: Like equipping the artist with specialized legal reference books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caab4691-027f-47e1-bd37-7e200a57a72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Sure! Here\\'s an explanation of the differences between **prompt engineering**, **fine-tuning**, and **adapters (like LoRA)** in the context of large language models, accompanied by three real-world analogies for better understanding:\\n\\n---\\n\\n### **1. Prompt Engineering**\\n**What it is:**  \\nPrompt engineering involves carefully crafting the input text (or \"prompt\") to guide the model\\'s behavior and responses without modifying the model itself. It\\'s like giving the model instructions or framing the question in a way that gets the desired outcome.\\n\\n**Analogy:**  \\nImagine you\\'re asking a chef to cook a specific dish, but you don\\'t change their skills or recipes. You simply describe exactly what you want, like \"Make me a vegetarian pasta with mushrooms, no cheese, and extra garlic.\" The chef listens and adjusts their cooking process based on how specifically you describe your request.\\n\\n**Key Point:**  \\nThe model stays the same, but the way you ask influences the output.\\n\\n---\\n\\n### **2. Fine-Tuning**\\n**What it is:**  \\nFine-tuning involves retraining the model on a specific dataset so it adapts to a particular domain or task. This process updates the model‚Äôs internal parameters, making it specialized for certain types of responses.\\n\\n**Analogy:**  \\nImagine you\\'re sending the chef to culinary school to specialize in vegetarian cooking. They learn new techniques and recipes, and once they graduate, their cooking permanently reflects their new expertise. Now, they are better equipped to handle vegetarian requests without additional instructions.\\n\\n**Key Point:**  \\nThe model itself is altered and becomes permanently specialized after retraining.\\n\\n---\\n\\n### **3. Adapters (like LoRA)**\\n**What it is:**  \\nAdapters, such as LoRA (Low-Rank Adaptation), are small modules added to the model to enable specialization without retraining the entire model. These modules act like plug-and-play components that modify the model‚Äôs behavior for specific tasks while keeping the original model intact.\\n\\n**Analogy:**  \\nImagine the chef is given a specialized toolkit for vegetarian cooking, like a new set of vegetarian-friendly spices and recipes. They can use this toolkit whenever needed, but their basic cooking skills remain unchanged. If you take the toolkit away, the chef goes back to their original cooking style.\\n\\n**Key Point:**  \\nAdapters allow task-specific customization without permanently changing the base model.\\n\\n---\\n\\n### **Summary of Differences**\\n- **Prompt Engineering:** Changing how you ask the model to get the desired response (no model modification).\\n- **Fine-Tuning:** Retraining the model to specialize in new tasks (permanent modification).\\n- **Adapters (LoRA):** Adding modular components that temporarily specialize the model for a task (partial modification).\\n\\nBy thinking of these techniques in terms of chefs, you can better understand how they influence the behavior of large language models!', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# Prompt: Explain the difference between prompt engineering, fine-tuning, and adapters with analogies\n",
    "prompt = (\n",
    "    \"Explain the difference between prompt engineering, fine-tuning, and adapters (like LoRA) in Large Language Models. \"\n",
    "    \"Use 3 real-world analogies to illustrate the differences.\"\n",
    ")\n",
    "\n",
    "response = connector.get_completion(prompt)\n",
    "print(response['content'] if isinstance(response, dict) else response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a419df4-14c2-4213-85fe-dd1c859e8291",
   "metadata": {},
   "source": [
    "## üìå When to Use Fine-Tuning\n",
    "\n",
    "Fine-tuning is useful when:  \n",
    "- üöÄ You need domain-specific expertise (legal, medical, etc.)  \n",
    "- üåê The base model lacks cultural or language nuances  \n",
    "- üè¢ For enterprise applications with proprietary data  \n",
    "\n",
    "### üìù Example\n",
    "A bank fine-tunes GPT on its internal policy documents for a chatbot that assists employees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cebbf32-17ce-4c79-b481-2d02a9326fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Fine-tuning large language models (LLMs) is essential in scenarios where domain specificity, personalization, or compliance requirements demand tailored behavior from the model. Below are three real-world scenarios with practical examples:\\n\\n---\\n\\n### **1. Domain-Specific Expertise**\\nIn industries with highly specialized knowledge, fine-tuning ensures that the model understands complex terminology, workflows, and nuances that are not well-covered by general-purpose LLMs.\\n\\n**Example: Healthcare**\\n- **Scenario:** A hospital develops an AI-powered assistant for doctors and clinicians to analyze patient symptoms, suggest potential diagnoses, and recommend treatments.\\n- **Why Fine-Tuning?** Medical diagnosis involves domain-specific terminology (e.g., \"cardiomyopathy,\" \"CABG procedure\") and decision-making processes that general LLMs aren‚Äôt proficient in.\\n- **Outcome:** Fine-tuning the model on medical textbooks, research papers, and patient case studies ensures accurate and reliable recommendations while minimizing the risk of misinformation.\\n\\n---\\n\\n### **2. Personalized Customer Support**\\nFine-tuning is crucial for businesses that want to provide a tailored and branded customer experience through chatbots or virtual assistants.\\n\\n**Example: E-commerce**\\n- **Scenario:** An online retailer uses an AI chatbot to handle customer inquiries about orders, returns, and product recommendations.\\n- **Why Fine-Tuning?** The chatbot needs to understand the company\\'s specific product catalog, return policies, and branding tone to provide accurate and empathetic responses.\\n- **Outcome:** Fine-tuned on product descriptions, FAQs, and customer interaction logs, the model delivers more relevant and engaging responses, improving customer satisfaction.\\n\\n---\\n\\n### **3. Regulatory Compliance and Legal Applications**\\nFine-tuning is essential in industries where adherence to legal, ethical, or regulatory standards is non-negotiable.\\n\\n**Example: Financial Services**\\n- **Scenario:** A bank implements an AI system to assist customers in understanding mortgage options, loan terms, and regulatory disclosures.\\n- **Why Fine-Tuning?** Financial services require strict compliance with regulatory guidelines (e.g., GDPR, FDCPA) and accurate interpretation of legal jargon.\\n- **Outcome:** Fine-tuning the model on financial regulations, internal policy documents, and legal frameworks ensures it provides compliant and accurate information, reducing liability risks.\\n\\n---\\n\\nIn each of these scenarios, fine-tuning transforms a general-purpose LLM into a specialized tool that meets critical business needs, improves user experiences, and mitigates risks.', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# Prompt: List 3 scenarios where fine-tuning LLMs is essential with examples\n",
    "prompt = (\n",
    "    \"List 3 real-world scenarios where fine-tuning Large Language Models is essential. \"\n",
    "    \"Provide practical examples for each scenario.\"\n",
    ")\n",
    "\n",
    "response = connector.get_completion(prompt)\n",
    "print(response['content'] if isinstance(response, dict) else response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fc9f01-3cac-40d1-9418-cf791201c5bc",
   "metadata": {},
   "source": [
    "## üìù Example: Domain-Specific Adaptation\n",
    "\n",
    "Ask the model to behave like a legal assistant without fine-tuning. Observe how well it adapts.\n",
    "\n",
    "**Prompt:**  \n",
    "_\"You are a legal assistant. Draft a non-disclosure agreement (NDA) clause regarding data privacy.\"_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "318aa9a8-88d6-401d-8c3d-a0399877d750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Domain Adaptation Test Output:\n",
      " ChatCompletionMessage(content='Certainly! Below is a sample clause for an NDA that specifically addresses data privacy. Please note that this is a general example and may require tailoring to fit specific jurisdictions, industries, or circumstances.\\n\\n---\\n\\n### **Data Privacy Clause**\\n\\n**Confidential Data and Privacy Obligations**  \\n1. **Definition of Confidential Data**: For the purposes of this Agreement, \"Confidential Data\" includes but is not limited to all personally identifiable information (PII), sensitive personal data, financial information, health records, proprietary business data, trade secrets, and any other data or information subject to applicable data protection laws and regulations.\\n\\n2. **Compliance with Data Protection Laws**: The Receiving Party agrees to handle all Confidential Data in compliance with applicable data protection laws and regulations, including but not limited to [insert applicable laws, e.g., the General Data Protection Regulation (GDPR), California Consumer Privacy Act (CCPA), or other relevant legislation].\\n\\n3. **Use and Disclosure Restrictions**: The Receiving Party shall:\\n   - Only use Confidential Data for the specific purposes expressly permitted under this Agreement.\\n   - Not disclose, share, or transfer Confidential Data to any third party without the prior written consent of the Disclosing Party, unless required by law or regulatory authority.\\n   - Implement appropriate technical, administrative, and physical safeguards to ensure the confidentiality, integrity, and security of Confidential Data.\\n\\n4. **Security Measures**: The Receiving Party shall adopt and maintain reasonable security practices, such as encryption, access controls, and secure storage, to protect Confidential Data from unauthorized access, disclosure, alteration, or destruction.\\n\\n5. **Data Breach Notification**: In the event of a suspected or actual breach of Confidential Data, the Receiving Party shall notify the Disclosing Party promptly and provide all necessary details regarding the nature of the breach, the data affected, and the steps being taken to mitigate the breach and prevent future occurrences.\\n\\n6. **Return or Destruction of Data**: Upon termination or expiration of this Agreement, or upon the Disclosing Party‚Äôs written request, the Receiving Party shall return or securely destroy all Confidential Data in its possession, and certify in writing that such return or destruction has been completed.\\n\\n7. **Indemnification**: The Receiving Party agrees to indemnify, defend, and hold harmless the Disclosing Party from and against any claims, liabilities, damages, or costs (including reasonable attorneys\\' fees) arising out of the Receiving Party\\'s failure to comply with its obligations under this clause.\\n\\n8. **Survival**: The obligations set forth in this clause shall survive the termination or expiration of this Agreement for an indefinite period or for the duration required by applicable data protection laws.\\n\\n---\\n\\nLet me know if you\\'d like additional clauses or if you need assistance tailoring this for specific use!', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# Prompt to simulate domain-specific adaptation\n",
    "prompt_domain = (\n",
    "    \"You are a legal assistant. Draft a non-disclosure agreement (NDA) clause regarding data privacy.\"\n",
    ")\n",
    "\n",
    "response_domain = connector.get_completion(prompt_domain)\n",
    "print(\"üìã Domain Adaptation Test Output:\\n\", response_domain['content'] if isinstance(response_domain, dict) else response_domain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6aa05ef-b79b-44c5-bece-d13f4ca2b14b",
   "metadata": {},
   "source": [
    "## ‚úÖ Summary\n",
    "\n",
    "In this section, we:  \n",
    "- Learned what fine-tuning is and when it‚Äôs needed.  \n",
    "- Compared fine-tuning, prompt engineering, and adapters.  \n",
    "- Explored examples of domain-specific adaptation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
